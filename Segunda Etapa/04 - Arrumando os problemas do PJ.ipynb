{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "89c2fa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0762a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "    \"grupo-1\": [\"Adult\", \"Banknote\", \"KC2\", \"titanic\"],\n",
    "    \"grupo-2\": [\"Australian\", \"Breast Cancer Coimbra\", \"liver disorders_bupa\", \"Room Occupancy\"],\n",
    "    \"grupo-3\": [\"Compas\", \"Ionosfera\", \"Vertebral_2C\", \"Vertebral_3C\", \"GiveMeSomeCredit\"],\n",
    "    \"grupo-4\": [\"Breast Cancer Wisconsin\", \"Diabetes\", \"Phishing\", \"Horse colic\"],\n",
    "    \"grupo-5\": [\"Churn\", \"Heart\", \"mammographic_masses\", \"wine\"],\n",
    "    \"grupo-6\": [\"Credit default\", \"Hill\", \"Mobile Price Classification\", \"Monk_1\"],\n",
    "    \"grupo-7\": [\"EEg\", \"German\", \"Monk_2\", \"Heart_2\"],\n",
    "    \"grupo-8\": [\"HELOC\", \"Mushrooms \", \"Biodeg\", \"Sonar\"],\n",
    "    \"grupo-9\": [\"Monk_3\", \"Musk\", \"Spambase\", \"Student\"],\n",
    "    \"grupo-10\": [\"OnlineNewsPopularity\", \"Tokyo\", \"twonorm\", \"Votes_Congressional\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a0b984",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult</td>\n",
       "      <td>adult/adult_processada.csv</td>\n",
       "      <td>Above/Below 50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australian</td>\n",
       "      <td>Australian/Credit_Card_Applications.csv</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Banknote</td>\n",
       "      <td>Banknote/BankNote_Authentication.csv</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biodeg</td>\n",
       "      <td>Biodeg/qsar-biodeg.csv</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Coimbra</td>\n",
       "      <td>Breast Cancer Coimbra/breast_coimbra.csv</td>\n",
       "      <td>Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Breast Cancer Wisconsin</td>\n",
       "      <td>Breast Cancer Wisconsin/breast-cancer.csv</td>\n",
       "      <td>diagnosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Churn</td>\n",
       "      <td>Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...</td>\n",
       "      <td>Churn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Compas</td>\n",
       "      <td>Compas/compas-scores-two-years.csv</td>\n",
       "      <td>two_year_recid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit default</td>\n",
       "      <td>Credit default/UCI_Credit_Card.csv</td>\n",
       "      <td>default.payment.next.month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Diabetes/diabetes.csv</td>\n",
       "      <td>Outcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Driving Behavior</td>\n",
       "      <td>['Driving Behavior/train_motion_data.csv', 'Dr...</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EEg</td>\n",
       "      <td>EEg/EEG Eye State.csv</td>\n",
       "      <td>Column15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>German</td>\n",
       "      <td>German/german_credit.csv</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GiveMeSomeCredit</td>\n",
       "      <td>GiveMeSomeCredit/GiveMeSomeCredit_processada.csv</td>\n",
       "      <td>SeriousDlqin2yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Heart</td>\n",
       "      <td>Heart/heart.csv</td>\n",
       "      <td>output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Heart_2</td>\n",
       "      <td>Heart/heart2.csv</td>\n",
       "      <td>num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Heart Failure Prediction</td>\n",
       "      <td>Heart Failure Prediction/heart_failure_clinica...</td>\n",
       "      <td>DEATH_EVENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HELOC</td>\n",
       "      <td>HELOC/heloc_dataset_v1.csv</td>\n",
       "      <td>RiskPerformance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Hill</td>\n",
       "      <td>['Hill/Hill_Valley_with_noise_Training.csv', '...</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Horse colic</td>\n",
       "      <td>Horse colic/horseV2_processada.csv</td>\n",
       "      <td>surgery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Indian Liver Patient Dataset</td>\n",
       "      <td>Indian Liver Patient Dataset/Indian Liver Pati...</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ionosfera</td>\n",
       "      <td>Ionosfera/ionosphere.csv</td>\n",
       "      <td>target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>IRIS</td>\n",
       "      <td>IRIS/Iris.csv</td>\n",
       "      <td>Species</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>KC2</td>\n",
       "      <td>KC2/KC2.csv</td>\n",
       "      <td>defects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>liver disorders_bupa</td>\n",
       "      <td>liver disorders_bupa/bupa.csv</td>\n",
       "      <td>selector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Magic</td>\n",
       "      <td>Magic/telescope_data.csv</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mammographic_masses</td>\n",
       "      <td>mammographic_masses/mammographic_masses_cleane...</td>\n",
       "      <td>Severity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Mobile Price Classification</td>\n",
       "      <td>Mobile Price Classification/train_mobile_proce...</td>\n",
       "      <td>range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Monk_1</td>\n",
       "      <td>['Monk/monks-1_train.csv', 'Monk/monks-1_test....</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Monk_2</td>\n",
       "      <td>['Monk/monks-2_train.csv', 'Monk/monks-2_test....</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Monk_3</td>\n",
       "      <td>['Monk/monks-3_train.csv', 'Monk/monks-3_test....</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Mushrooms</td>\n",
       "      <td>Mushrooms/mushrooms_processada.csv</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Musk</td>\n",
       "      <td>Musk/clean1.csv</td>\n",
       "      <td>Column169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>News popularity</td>\n",
       "      <td>News popularity/OnlineNewsPopularity.csv</td>\n",
       "      <td>shares</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>no2</td>\n",
       "      <td>no2/no2.csv</td>\n",
       "      <td>Column1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>OnlineNewsPopularity</td>\n",
       "      <td>OnlineNewsPopularity/OnlineNewsPopularity_proc...</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>optdigits_csv</td>\n",
       "      <td>optdigits_csv/optdigits_csv.csv</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>pc1</td>\n",
       "      <td>pc1/pc1.csv</td>\n",
       "      <td>defects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Phishing</td>\n",
       "      <td>Phishing/Phishing.csv</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Phoneme</td>\n",
       "      <td>Phoneme/phoneme.csv</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Plasma</td>\n",
       "      <td>Plasma/plasma.csv</td>\n",
       "      <td>Column14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>post-operative</td>\n",
       "      <td>post-operative/post-operative-data.csv</td>\n",
       "      <td>decision ADM-DECS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>price</td>\n",
       "      <td>['price/train.csv', 'price/test.csv']</td>\n",
       "      <td>price_range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Room Occupancy</td>\n",
       "      <td>Room Occupancy/Room Occupancy.csv</td>\n",
       "      <td>Occupancy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>seismic</td>\n",
       "      <td>seismic/seismic_processada.csv</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Shopping</td>\n",
       "      <td>Shopping/e-shop clothing 2008.csv</td>\n",
       "      <td>page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Sky Survey</td>\n",
       "      <td>Sky Survey/Skyserver_SQL2_27_2018 6_51_39 PM.csv</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Sonar</td>\n",
       "      <td>Sonar/sonar.all-data.csv</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Spambase</td>\n",
       "      <td>Spambase/Spambase.csv</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Student</td>\n",
       "      <td>Student/Students-Performance-MAT_processada.csv</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Tic-Tac-Toe</td>\n",
       "      <td>Tic-Tac-Toe/tic-tac-toe-endgame.csv</td>\n",
       "      <td>V10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>titanic</td>\n",
       "      <td>titanic/titanic_processada.csv</td>\n",
       "      <td>Survived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo/Tokyo.csv</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>twonorm</td>\n",
       "      <td>twonorm/twonorm.csv</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Vertebral_2C</td>\n",
       "      <td>Vertebral/column_2C.csv</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Vertebral_3C</td>\n",
       "      <td>Vertebral/column_3C.csv</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Votes_Congressional</td>\n",
       "      <td>Votes_Congressional/house-votes-84_processada.csv</td>\n",
       "      <td>Class Name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>wine</td>\n",
       "      <td>wine/WineQT.csv</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>xd6</td>\n",
       "      <td>xd6/xd6_dataset_csv.csv</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  \\\n",
       "0                          Adult   \n",
       "1                     Australian   \n",
       "2                       Banknote   \n",
       "3                         Biodeg   \n",
       "4          Breast Cancer Coimbra   \n",
       "5        Breast Cancer Wisconsin   \n",
       "6                          Churn   \n",
       "7                         Compas   \n",
       "8                 Credit default   \n",
       "9                       Diabetes   \n",
       "10              Driving Behavior   \n",
       "11                           EEg   \n",
       "12                        German   \n",
       "13              GiveMeSomeCredit   \n",
       "14                         Heart   \n",
       "15                       Heart_2   \n",
       "16      Heart Failure Prediction   \n",
       "17                         HELOC   \n",
       "18                          Hill   \n",
       "19                   Horse colic   \n",
       "20  Indian Liver Patient Dataset   \n",
       "21                     Ionosfera   \n",
       "22                          IRIS   \n",
       "23                           KC2   \n",
       "24          liver disorders_bupa   \n",
       "25                         Magic   \n",
       "26           mammographic_masses   \n",
       "27   Mobile Price Classification   \n",
       "28                        Monk_1   \n",
       "29                        Monk_2   \n",
       "30                        Monk_3   \n",
       "31                     Mushrooms   \n",
       "32                          Musk   \n",
       "33               News popularity   \n",
       "34                           no2   \n",
       "35          OnlineNewsPopularity   \n",
       "36                 optdigits_csv   \n",
       "37                           pc1   \n",
       "38                      Phishing   \n",
       "39                       Phoneme   \n",
       "40                        Plasma   \n",
       "41                post-operative   \n",
       "42                         price   \n",
       "43                Room Occupancy   \n",
       "44                       seismic   \n",
       "45                      Shopping   \n",
       "46                    Sky Survey   \n",
       "47                         Sonar   \n",
       "48                      Spambase   \n",
       "49                       Student   \n",
       "50                   Tic-Tac-Toe   \n",
       "51                       titanic   \n",
       "52                         Tokyo   \n",
       "53                       twonorm   \n",
       "54                  Vertebral_2C   \n",
       "55                  Vertebral_3C   \n",
       "56           Votes_Congressional   \n",
       "57                          wine   \n",
       "58                           xd6   \n",
       "\n",
       "                                                 path  \\\n",
       "0                          adult/adult_processada.csv   \n",
       "1             Australian/Credit_Card_Applications.csv   \n",
       "2                Banknote/BankNote_Authentication.csv   \n",
       "3                              Biodeg/qsar-biodeg.csv   \n",
       "4            Breast Cancer Coimbra/breast_coimbra.csv   \n",
       "5           Breast Cancer Wisconsin/breast-cancer.csv   \n",
       "6   Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...   \n",
       "7                  Compas/compas-scores-two-years.csv   \n",
       "8                  Credit default/UCI_Credit_Card.csv   \n",
       "9                               Diabetes/diabetes.csv   \n",
       "10  ['Driving Behavior/train_motion_data.csv', 'Dr...   \n",
       "11                              EEg/EEG Eye State.csv   \n",
       "12                           German/german_credit.csv   \n",
       "13   GiveMeSomeCredit/GiveMeSomeCredit_processada.csv   \n",
       "14                                    Heart/heart.csv   \n",
       "15                                   Heart/heart2.csv   \n",
       "16  Heart Failure Prediction/heart_failure_clinica...   \n",
       "17                         HELOC/heloc_dataset_v1.csv   \n",
       "18  ['Hill/Hill_Valley_with_noise_Training.csv', '...   \n",
       "19                 Horse colic/horseV2_processada.csv   \n",
       "20  Indian Liver Patient Dataset/Indian Liver Pati...   \n",
       "21                           Ionosfera/ionosphere.csv   \n",
       "22                                      IRIS/Iris.csv   \n",
       "23                                        KC2/KC2.csv   \n",
       "24                      liver disorders_bupa/bupa.csv   \n",
       "25                           Magic/telescope_data.csv   \n",
       "26  mammographic_masses/mammographic_masses_cleane...   \n",
       "27  Mobile Price Classification/train_mobile_proce...   \n",
       "28  ['Monk/monks-1_train.csv', 'Monk/monks-1_test....   \n",
       "29  ['Monk/monks-2_train.csv', 'Monk/monks-2_test....   \n",
       "30  ['Monk/monks-3_train.csv', 'Monk/monks-3_test....   \n",
       "31                 Mushrooms/mushrooms_processada.csv   \n",
       "32                                    Musk/clean1.csv   \n",
       "33           News popularity/OnlineNewsPopularity.csv   \n",
       "34                                        no2/no2.csv   \n",
       "35  OnlineNewsPopularity/OnlineNewsPopularity_proc...   \n",
       "36                    optdigits_csv/optdigits_csv.csv   \n",
       "37                                        pc1/pc1.csv   \n",
       "38                              Phishing/Phishing.csv   \n",
       "39                                Phoneme/phoneme.csv   \n",
       "40                                  Plasma/plasma.csv   \n",
       "41             post-operative/post-operative-data.csv   \n",
       "42              ['price/train.csv', 'price/test.csv']   \n",
       "43                  Room Occupancy/Room Occupancy.csv   \n",
       "44                     seismic/seismic_processada.csv   \n",
       "45                  Shopping/e-shop clothing 2008.csv   \n",
       "46   Sky Survey/Skyserver_SQL2_27_2018 6_51_39 PM.csv   \n",
       "47                           Sonar/sonar.all-data.csv   \n",
       "48                              Spambase/Spambase.csv   \n",
       "49    Student/Students-Performance-MAT_processada.csv   \n",
       "50                Tic-Tac-Toe/tic-tac-toe-endgame.csv   \n",
       "51                     titanic/titanic_processada.csv   \n",
       "52                                    Tokyo/Tokyo.csv   \n",
       "53                                twonorm/twonorm.csv   \n",
       "54                            Vertebral/column_2C.csv   \n",
       "55                            Vertebral/column_3C.csv   \n",
       "56  Votes_Congressional/house-votes-84_processada.csv   \n",
       "57                                    wine/WineQT.csv   \n",
       "58                            xd6/xd6_dataset_csv.csv   \n",
       "\n",
       "                        classe  \n",
       "0              Above/Below 50K  \n",
       "1                        Class  \n",
       "2                        class  \n",
       "3                        Class  \n",
       "4               Classification  \n",
       "5                    diagnosis  \n",
       "6                        Churn  \n",
       "7               two_year_recid  \n",
       "8   default.payment.next.month  \n",
       "9                      Outcome  \n",
       "10                       Class  \n",
       "11                    Column15  \n",
       "12                     default  \n",
       "13            SeriousDlqin2yrs  \n",
       "14                      output  \n",
       "15                         num  \n",
       "16                 DEATH_EVENT  \n",
       "17             RiskPerformance  \n",
       "18                       class  \n",
       "19                     surgery  \n",
       "20                       class  \n",
       "21                      target  \n",
       "22                     Species  \n",
       "23                     defects  \n",
       "24                    selector  \n",
       "25                       class  \n",
       "26                    Severity  \n",
       "27                       range  \n",
       "28                       Class  \n",
       "29                       Class  \n",
       "30                       Class  \n",
       "31                       class  \n",
       "32                   Column169  \n",
       "33                      shares  \n",
       "34                     Column1  \n",
       "35                       class  \n",
       "36                       class  \n",
       "37                     defects  \n",
       "38                       Class  \n",
       "39                       class  \n",
       "40                    Column14  \n",
       "41           decision ADM-DECS  \n",
       "42                 price_range  \n",
       "43                   Occupancy  \n",
       "44                       class  \n",
       "45                        page  \n",
       "46                       class  \n",
       "47                       class  \n",
       "48                       Class  \n",
       "49                       Class  \n",
       "50                         V10  \n",
       "51                    Survived  \n",
       "52                       class  \n",
       "53                       class  \n",
       "54                       class  \n",
       "55                       class  \n",
       "56                  Class Name  \n",
       "57                     quality  \n",
       "58                       class  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_map_inference_datasets = pd.read_parquet(f\"s3://omar-testes-gerais/artigos/artifacts/df_map_inference_datasets.parquet\")\n",
    "df_map_inference_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "449c1bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map_inference_datasets.loc[32, 'classe'] = 'Column167'\n",
    "df_map_inference_datasets\n",
    "df_map_inference_datasets.to_parquet(f\"s3://omar-testes-gerais/artigos/artifacts/df_map_inference_datasets.parquet\", engine = 'pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbf02eed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult</td>\n",
       "      <td>adult/adult_processada.csv</td>\n",
       "      <td>Above/Below 50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australian</td>\n",
       "      <td>Australian/Credit_Card_Applications.csv</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Banknote</td>\n",
       "      <td>Banknote/BankNote_Authentication.csv</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biodeg</td>\n",
       "      <td>Biodeg/qsar-biodeg.csv</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Coimbra</td>\n",
       "      <td>Breast Cancer Coimbra/breast_coimbra.csv</td>\n",
       "      <td>Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Breast Cancer Wisconsin</td>\n",
       "      <td>Breast Cancer Wisconsin/breast-cancer.csv</td>\n",
       "      <td>diagnosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Churn</td>\n",
       "      <td>Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...</td>\n",
       "      <td>Churn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Compas</td>\n",
       "      <td>Compas/compas-scores-two-years.csv</td>\n",
       "      <td>two_year_recid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit default</td>\n",
       "      <td>Credit default/UCI_Credit_Card.csv</td>\n",
       "      <td>default.payment.next.month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Diabetes/diabetes.csv</td>\n",
       "      <td>Outcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EEg</td>\n",
       "      <td>EEg/EEG Eye State.csv</td>\n",
       "      <td>Column15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>German</td>\n",
       "      <td>German/german_credit.csv</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GiveMeSomeCredit</td>\n",
       "      <td>GiveMeSomeCredit/GiveMeSomeCredit_processada.csv</td>\n",
       "      <td>SeriousDlqin2yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Heart</td>\n",
       "      <td>Heart/heart.csv</td>\n",
       "      <td>output</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Heart_2</td>\n",
       "      <td>Heart/heart2.csv</td>\n",
       "      <td>num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HELOC</td>\n",
       "      <td>HELOC/heloc_dataset_v1.csv</td>\n",
       "      <td>RiskPerformance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Horse colic</td>\n",
       "      <td>Horse colic/horseV2_processada.csv</td>\n",
       "      <td>surgery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ionosfera</td>\n",
       "      <td>Ionosfera/ionosphere.csv</td>\n",
       "      <td>target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KC2</td>\n",
       "      <td>KC2/KC2.csv</td>\n",
       "      <td>defects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>liver disorders_bupa</td>\n",
       "      <td>liver disorders_bupa/bupa.csv</td>\n",
       "      <td>selector</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mammographic_masses</td>\n",
       "      <td>mammographic_masses/mammographic_masses_cleane...</td>\n",
       "      <td>Severity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mobile Price Classification</td>\n",
       "      <td>Mobile Price Classification/train_mobile_proce...</td>\n",
       "      <td>range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Monk_1</td>\n",
       "      <td>['Monk/monks-1_train.csv', 'Monk/monks-1_test....</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Monk_2</td>\n",
       "      <td>['Monk/monks-2_train.csv', 'Monk/monks-2_test....</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Monk_3</td>\n",
       "      <td>['Monk/monks-3_train.csv', 'Monk/monks-3_test....</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Musk</td>\n",
       "      <td>Musk/clean1.csv</td>\n",
       "      <td>Column169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>OnlineNewsPopularity</td>\n",
       "      <td>OnlineNewsPopularity/OnlineNewsPopularity_proc...</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Phishing</td>\n",
       "      <td>Phishing/Phishing.csv</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Room Occupancy</td>\n",
       "      <td>Room Occupancy/Room Occupancy.csv</td>\n",
       "      <td>Occupancy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sonar</td>\n",
       "      <td>Sonar/sonar.all-data.csv</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Spambase</td>\n",
       "      <td>Spambase/Spambase.csv</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Student</td>\n",
       "      <td>Student/Students-Performance-MAT_processada.csv</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>titanic</td>\n",
       "      <td>titanic/titanic_processada.csv</td>\n",
       "      <td>Survived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo/Tokyo.csv</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>twonorm</td>\n",
       "      <td>twonorm/twonorm.csv</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Vertebral_2C</td>\n",
       "      <td>Vertebral/column_2C.csv</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Vertebral_3C</td>\n",
       "      <td>Vertebral/column_3C.csv</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Votes_Congressional</td>\n",
       "      <td>Votes_Congressional/house-votes-84_processada.csv</td>\n",
       "      <td>Class Name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>wine</td>\n",
       "      <td>wine/WineQT.csv</td>\n",
       "      <td>quality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  \\\n",
       "0                         Adult   \n",
       "1                    Australian   \n",
       "2                      Banknote   \n",
       "3                        Biodeg   \n",
       "4         Breast Cancer Coimbra   \n",
       "5       Breast Cancer Wisconsin   \n",
       "6                         Churn   \n",
       "7                        Compas   \n",
       "8                Credit default   \n",
       "9                      Diabetes   \n",
       "10                          EEg   \n",
       "11                       German   \n",
       "12             GiveMeSomeCredit   \n",
       "13                        Heart   \n",
       "14                      Heart_2   \n",
       "15                        HELOC   \n",
       "16                  Horse colic   \n",
       "17                    Ionosfera   \n",
       "18                          KC2   \n",
       "19         liver disorders_bupa   \n",
       "20          mammographic_masses   \n",
       "21  Mobile Price Classification   \n",
       "22                       Monk_1   \n",
       "23                       Monk_2   \n",
       "24                       Monk_3   \n",
       "25                         Musk   \n",
       "26         OnlineNewsPopularity   \n",
       "27                     Phishing   \n",
       "28               Room Occupancy   \n",
       "29                        Sonar   \n",
       "30                     Spambase   \n",
       "31                      Student   \n",
       "32                      titanic   \n",
       "33                        Tokyo   \n",
       "34                      twonorm   \n",
       "35                 Vertebral_2C   \n",
       "36                 Vertebral_3C   \n",
       "37          Votes_Congressional   \n",
       "38                         wine   \n",
       "\n",
       "                                                 path  \\\n",
       "0                          adult/adult_processada.csv   \n",
       "1             Australian/Credit_Card_Applications.csv   \n",
       "2                Banknote/BankNote_Authentication.csv   \n",
       "3                              Biodeg/qsar-biodeg.csv   \n",
       "4            Breast Cancer Coimbra/breast_coimbra.csv   \n",
       "5           Breast Cancer Wisconsin/breast-cancer.csv   \n",
       "6   Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...   \n",
       "7                  Compas/compas-scores-two-years.csv   \n",
       "8                  Credit default/UCI_Credit_Card.csv   \n",
       "9                               Diabetes/diabetes.csv   \n",
       "10                              EEg/EEG Eye State.csv   \n",
       "11                           German/german_credit.csv   \n",
       "12   GiveMeSomeCredit/GiveMeSomeCredit_processada.csv   \n",
       "13                                    Heart/heart.csv   \n",
       "14                                   Heart/heart2.csv   \n",
       "15                         HELOC/heloc_dataset_v1.csv   \n",
       "16                 Horse colic/horseV2_processada.csv   \n",
       "17                           Ionosfera/ionosphere.csv   \n",
       "18                                        KC2/KC2.csv   \n",
       "19                      liver disorders_bupa/bupa.csv   \n",
       "20  mammographic_masses/mammographic_masses_cleane...   \n",
       "21  Mobile Price Classification/train_mobile_proce...   \n",
       "22  ['Monk/monks-1_train.csv', 'Monk/monks-1_test....   \n",
       "23  ['Monk/monks-2_train.csv', 'Monk/monks-2_test....   \n",
       "24  ['Monk/monks-3_train.csv', 'Monk/monks-3_test....   \n",
       "25                                    Musk/clean1.csv   \n",
       "26  OnlineNewsPopularity/OnlineNewsPopularity_proc...   \n",
       "27                              Phishing/Phishing.csv   \n",
       "28                  Room Occupancy/Room Occupancy.csv   \n",
       "29                           Sonar/sonar.all-data.csv   \n",
       "30                              Spambase/Spambase.csv   \n",
       "31    Student/Students-Performance-MAT_processada.csv   \n",
       "32                     titanic/titanic_processada.csv   \n",
       "33                                    Tokyo/Tokyo.csv   \n",
       "34                                twonorm/twonorm.csv   \n",
       "35                            Vertebral/column_2C.csv   \n",
       "36                            Vertebral/column_3C.csv   \n",
       "37  Votes_Congressional/house-votes-84_processada.csv   \n",
       "38                                    wine/WineQT.csv   \n",
       "\n",
       "                        classe  \n",
       "0              Above/Below 50K  \n",
       "1                        Class  \n",
       "2                        class  \n",
       "3                        Class  \n",
       "4               Classification  \n",
       "5                    diagnosis  \n",
       "6                        Churn  \n",
       "7               two_year_recid  \n",
       "8   default.payment.next.month  \n",
       "9                      Outcome  \n",
       "10                    Column15  \n",
       "11                     default  \n",
       "12            SeriousDlqin2yrs  \n",
       "13                      output  \n",
       "14                         num  \n",
       "15             RiskPerformance  \n",
       "16                     surgery  \n",
       "17                      target  \n",
       "18                     defects  \n",
       "19                    selector  \n",
       "20                    Severity  \n",
       "21                       range  \n",
       "22                       Class  \n",
       "23                       Class  \n",
       "24                       Class  \n",
       "25                   Column169  \n",
       "26                       class  \n",
       "27                       Class  \n",
       "28                   Occupancy  \n",
       "29                       class  \n",
       "30                       Class  \n",
       "31                       Class  \n",
       "32                    Survived  \n",
       "33                       class  \n",
       "34                       class  \n",
       "35                       class  \n",
       "36                       class  \n",
       "37                  Class Name  \n",
       "38                     quality  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valores_para_filtrar = [valor for sublista in groups.values() for valor in sublista]\n",
    "dfm_use = df_map_inference_datasets[df_map_inference_datasets['name'].isin(valores_para_filtrar)]\n",
    "dfm_use.reset_index(drop = True, inplace = True)\n",
    "dfm_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1a998f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>classe</th>\n",
       "      <th>metrica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult</td>\n",
       "      <td>adult/adult_processada.csv</td>\n",
       "      <td>Above/Below 50K</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australian</td>\n",
       "      <td>Australian/Credit_Card_Applications.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Banknote</td>\n",
       "      <td>Banknote/BankNote_Authentication.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biodeg</td>\n",
       "      <td>Biodeg/qsar-biodeg.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Coimbra</td>\n",
       "      <td>Breast Cancer Coimbra/breast_coimbra.csv</td>\n",
       "      <td>Classification</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Breast Cancer Wisconsin</td>\n",
       "      <td>Breast Cancer Wisconsin/breast-cancer.csv</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Churn</td>\n",
       "      <td>Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...</td>\n",
       "      <td>Churn</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Compas</td>\n",
       "      <td>Compas/compas-scores-two-years.csv</td>\n",
       "      <td>two_year_recid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit default</td>\n",
       "      <td>Credit default/UCI_Credit_Card.csv</td>\n",
       "      <td>default.payment.next.month</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Diabetes/diabetes.csv</td>\n",
       "      <td>Outcome</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EEg</td>\n",
       "      <td>EEg/EEG Eye State.csv</td>\n",
       "      <td>Column15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>German</td>\n",
       "      <td>German/german_credit.csv</td>\n",
       "      <td>default</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GiveMeSomeCredit</td>\n",
       "      <td>GiveMeSomeCredit/GiveMeSomeCredit_processada.csv</td>\n",
       "      <td>SeriousDlqin2yrs</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Heart</td>\n",
       "      <td>Heart/heart.csv</td>\n",
       "      <td>output</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Heart_2</td>\n",
       "      <td>Heart/heart2.csv</td>\n",
       "      <td>num</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HELOC</td>\n",
       "      <td>HELOC/heloc_dataset_v1.csv</td>\n",
       "      <td>RiskPerformance</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Horse colic</td>\n",
       "      <td>Horse colic/horseV2_processada.csv</td>\n",
       "      <td>surgery</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ionosfera</td>\n",
       "      <td>Ionosfera/ionosphere.csv</td>\n",
       "      <td>target</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KC2</td>\n",
       "      <td>KC2/KC2.csv</td>\n",
       "      <td>defects</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>liver disorders_bupa</td>\n",
       "      <td>liver disorders_bupa/bupa.csv</td>\n",
       "      <td>selector</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mammographic_masses</td>\n",
       "      <td>mammographic_masses/mammographic_masses_cleane...</td>\n",
       "      <td>Severity</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mobile Price Classification</td>\n",
       "      <td>Mobile Price Classification/train_mobile_proce...</td>\n",
       "      <td>range</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Monk_1</td>\n",
       "      <td>['Monk/monks-1_train.csv', 'Monk/monks-1_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Monk_2</td>\n",
       "      <td>['Monk/monks-2_train.csv', 'Monk/monks-2_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Monk_3</td>\n",
       "      <td>['Monk/monks-3_train.csv', 'Monk/monks-3_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Musk</td>\n",
       "      <td>Musk/clean1.csv</td>\n",
       "      <td>Column169</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>OnlineNewsPopularity</td>\n",
       "      <td>OnlineNewsPopularity/OnlineNewsPopularity_proc...</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Phishing</td>\n",
       "      <td>Phishing/Phishing.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Room Occupancy</td>\n",
       "      <td>Room Occupancy/Room Occupancy.csv</td>\n",
       "      <td>Occupancy</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sonar</td>\n",
       "      <td>Sonar/sonar.all-data.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Spambase</td>\n",
       "      <td>Spambase/Spambase.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Student</td>\n",
       "      <td>Student/Students-Performance-MAT_processada.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>titanic</td>\n",
       "      <td>titanic/titanic_processada.csv</td>\n",
       "      <td>Survived</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo/Tokyo.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>twonorm</td>\n",
       "      <td>twonorm/twonorm.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Vertebral_2C</td>\n",
       "      <td>Vertebral/column_2C.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Vertebral_3C</td>\n",
       "      <td>Vertebral/column_3C.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Votes_Congressional</td>\n",
       "      <td>Votes_Congressional/house-votes-84_processada.csv</td>\n",
       "      <td>Class Name</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>wine</td>\n",
       "      <td>wine/WineQT.csv</td>\n",
       "      <td>quality</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  \\\n",
       "0                         Adult   \n",
       "1                    Australian   \n",
       "2                      Banknote   \n",
       "3                        Biodeg   \n",
       "4         Breast Cancer Coimbra   \n",
       "5       Breast Cancer Wisconsin   \n",
       "6                         Churn   \n",
       "7                        Compas   \n",
       "8                Credit default   \n",
       "9                      Diabetes   \n",
       "10                          EEg   \n",
       "11                       German   \n",
       "12             GiveMeSomeCredit   \n",
       "13                        Heart   \n",
       "14                      Heart_2   \n",
       "15                        HELOC   \n",
       "16                  Horse colic   \n",
       "17                    Ionosfera   \n",
       "18                          KC2   \n",
       "19         liver disorders_bupa   \n",
       "20          mammographic_masses   \n",
       "21  Mobile Price Classification   \n",
       "22                       Monk_1   \n",
       "23                       Monk_2   \n",
       "24                       Monk_3   \n",
       "25                         Musk   \n",
       "26         OnlineNewsPopularity   \n",
       "27                     Phishing   \n",
       "28               Room Occupancy   \n",
       "29                        Sonar   \n",
       "30                     Spambase   \n",
       "31                      Student   \n",
       "32                      titanic   \n",
       "33                        Tokyo   \n",
       "34                      twonorm   \n",
       "35                 Vertebral_2C   \n",
       "36                 Vertebral_3C   \n",
       "37          Votes_Congressional   \n",
       "38                         wine   \n",
       "\n",
       "                                                 path  \\\n",
       "0                          adult/adult_processada.csv   \n",
       "1             Australian/Credit_Card_Applications.csv   \n",
       "2                Banknote/BankNote_Authentication.csv   \n",
       "3                              Biodeg/qsar-biodeg.csv   \n",
       "4            Breast Cancer Coimbra/breast_coimbra.csv   \n",
       "5           Breast Cancer Wisconsin/breast-cancer.csv   \n",
       "6   Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...   \n",
       "7                  Compas/compas-scores-two-years.csv   \n",
       "8                  Credit default/UCI_Credit_Card.csv   \n",
       "9                               Diabetes/diabetes.csv   \n",
       "10                              EEg/EEG Eye State.csv   \n",
       "11                           German/german_credit.csv   \n",
       "12   GiveMeSomeCredit/GiveMeSomeCredit_processada.csv   \n",
       "13                                    Heart/heart.csv   \n",
       "14                                   Heart/heart2.csv   \n",
       "15                         HELOC/heloc_dataset_v1.csv   \n",
       "16                 Horse colic/horseV2_processada.csv   \n",
       "17                           Ionosfera/ionosphere.csv   \n",
       "18                                        KC2/KC2.csv   \n",
       "19                      liver disorders_bupa/bupa.csv   \n",
       "20  mammographic_masses/mammographic_masses_cleane...   \n",
       "21  Mobile Price Classification/train_mobile_proce...   \n",
       "22  ['Monk/monks-1_train.csv', 'Monk/monks-1_test....   \n",
       "23  ['Monk/monks-2_train.csv', 'Monk/monks-2_test....   \n",
       "24  ['Monk/monks-3_train.csv', 'Monk/monks-3_test....   \n",
       "25                                    Musk/clean1.csv   \n",
       "26  OnlineNewsPopularity/OnlineNewsPopularity_proc...   \n",
       "27                              Phishing/Phishing.csv   \n",
       "28                  Room Occupancy/Room Occupancy.csv   \n",
       "29                           Sonar/sonar.all-data.csv   \n",
       "30                              Spambase/Spambase.csv   \n",
       "31    Student/Students-Performance-MAT_processada.csv   \n",
       "32                     titanic/titanic_processada.csv   \n",
       "33                                    Tokyo/Tokyo.csv   \n",
       "34                                twonorm/twonorm.csv   \n",
       "35                            Vertebral/column_2C.csv   \n",
       "36                            Vertebral/column_3C.csv   \n",
       "37  Votes_Congressional/house-votes-84_processada.csv   \n",
       "38                                    wine/WineQT.csv   \n",
       "\n",
       "                        classe  \\\n",
       "0              Above/Below 50K   \n",
       "1                        Class   \n",
       "2                        class   \n",
       "3                        Class   \n",
       "4               Classification   \n",
       "5                    diagnosis   \n",
       "6                        Churn   \n",
       "7               two_year_recid   \n",
       "8   default.payment.next.month   \n",
       "9                      Outcome   \n",
       "10                    Column15   \n",
       "11                     default   \n",
       "12            SeriousDlqin2yrs   \n",
       "13                      output   \n",
       "14                         num   \n",
       "15             RiskPerformance   \n",
       "16                     surgery   \n",
       "17                      target   \n",
       "18                     defects   \n",
       "19                    selector   \n",
       "20                    Severity   \n",
       "21                       range   \n",
       "22                       Class   \n",
       "23                       Class   \n",
       "24                       Class   \n",
       "25                   Column169   \n",
       "26                       class   \n",
       "27                       Class   \n",
       "28                   Occupancy   \n",
       "29                       class   \n",
       "30                       Class   \n",
       "31                       Class   \n",
       "32                    Survived   \n",
       "33                       class   \n",
       "34                       class   \n",
       "35                       class   \n",
       "36                       class   \n",
       "37                  Class Name   \n",
       "38                     quality   \n",
       "\n",
       "                                              metrica  \n",
       "0                                                 NaN  \n",
       "1   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "2   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "3                                                 NaN  \n",
       "4   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "5   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8                                                 NaN  \n",
       "9   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "10                                                NaN  \n",
       "11  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "12                                                NaN  \n",
       "13  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "14  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "15  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "16                                                NaN  \n",
       "17                                                NaN  \n",
       "18  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "19  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "20  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "21                                                NaN  \n",
       "22                                                NaN  \n",
       "23                                                NaN  \n",
       "24                                                NaN  \n",
       "25                                                NaN  \n",
       "26                                                NaN  \n",
       "27  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "28  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "29  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "30  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "31                                                NaN  \n",
       "32                                                NaN  \n",
       "33  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "34  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "35  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "36                                                NaN  \n",
       "37  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "38                                                NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Configurações do S3\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'omar-testes-gerais'\n",
    "pasta_s3 = 'artigos/causal_csse/bateria_metricas/outputs/metricas_1/rf/'\n",
    "\n",
    "# Função para ler um JSON do S3 e convertê-lo em um dicionário\n",
    "def ler_json_do_s3(bucket, caminho):\n",
    "    response = s3_client.get_object(Bucket=bucket, Key=caminho)\n",
    "    conteudo = response['Body'].read().decode('utf-8')\n",
    "    return json.loads(conteudo)\n",
    "\n",
    "# Lista os objetos na pasta S3\n",
    "objetos = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=pasta_s3)\n",
    "\n",
    "# Itera sobre os arquivos na pasta S3\n",
    "for objeto in objetos.get('Contents', []):\n",
    "    caminho_arquivo = objeto['Key']\n",
    "    nome_arquivo = caminho_arquivo.split('/')[-1].replace('.json', '')  # Extrai o nome do arquivo sem a extensão\n",
    "\n",
    "    # Verifica se o nome do arquivo está no DataFrame\n",
    "    if nome_arquivo in dfm_use['name'].values:\n",
    "        # Lê o JSON e adiciona o conteúdo como uma nova coluna no DataFrame\n",
    "        conteudo_json = ler_json_do_s3(bucket_name, caminho_arquivo)\n",
    "        dfm_use.loc[dfm_use['name'] == nome_arquivo, 'metrica'] = [conteudo_json]\n",
    "\n",
    "dfm_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d12d8bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Biodeg/qsar-biodeg.csv'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm_use.iloc[3]['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "390b405c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>a4</th>\n",
       "      <th>a5</th>\n",
       "      <th>a6</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>data_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>data_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>data_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>data_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>data_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>data_428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>data_429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>data_430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>data_431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>data_432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>432 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  a1  a2  a3  a4  a5  a6        Id\n",
       "0        1   1   1   1   1   1   1    data_1\n",
       "1        1   1   1   1   1   1   2    data_2\n",
       "2        1   1   1   1   1   2   1    data_3\n",
       "3        1   1   1   1   1   2   2    data_4\n",
       "4        1   1   1   1   1   3   1    data_5\n",
       "..     ...  ..  ..  ..  ..  ..  ..       ...\n",
       "427      1   3   3   2   3   2   2  data_428\n",
       "428      1   3   3   2   3   3   1  data_429\n",
       "429      1   3   3   2   3   3   2  data_430\n",
       "430      1   3   3   2   3   4   1  data_431\n",
       "431      1   3   3   2   3   4   2  data_432\n",
       "\n",
       "[432 rows x 8 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"s3://omar-testes-gerais/artigos/artifacts/datasets/Monk/monks-1_test.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "632a43e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>classe</th>\n",
       "      <th>metrica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult</td>\n",
       "      <td>adult/adult_processada.csv</td>\n",
       "      <td>Above/Below 50K</td>\n",
       "      <td>memoria 18gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australian</td>\n",
       "      <td>Australian/Credit_Card_Applications.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Banknote</td>\n",
       "      <td>Banknote/BankNote_Authentication.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biodeg</td>\n",
       "      <td>Biodeg/qsar-biodeg.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>valor da coluna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Coimbra</td>\n",
       "      <td>Breast Cancer Coimbra/breast_coimbra.csv</td>\n",
       "      <td>Classification</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Breast Cancer Wisconsin</td>\n",
       "      <td>Breast Cancer Wisconsin/breast-cancer.csv</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Churn</td>\n",
       "      <td>Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...</td>\n",
       "      <td>Churn</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Compas</td>\n",
       "      <td>Compas/compas-scores-two-years.csv</td>\n",
       "      <td>two_year_recid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit default</td>\n",
       "      <td>Credit default/UCI_Credit_Card.csv</td>\n",
       "      <td>default.payment.next.month</td>\n",
       "      <td>memoria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Diabetes/diabetes.csv</td>\n",
       "      <td>Outcome</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EEg</td>\n",
       "      <td>EEg/EEG Eye State.csv</td>\n",
       "      <td>Column15</td>\n",
       "      <td>list.remove(x): x not in list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>German</td>\n",
       "      <td>German/german_credit.csv</td>\n",
       "      <td>default</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GiveMeSomeCredit</td>\n",
       "      <td>GiveMeSomeCredit/GiveMeSomeCredit_processada.csv</td>\n",
       "      <td>SeriousDlqin2yrs</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Heart</td>\n",
       "      <td>Heart/heart.csv</td>\n",
       "      <td>output</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Heart_2</td>\n",
       "      <td>Heart/heart2.csv</td>\n",
       "      <td>num</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HELOC</td>\n",
       "      <td>HELOC/heloc_dataset_v1.csv</td>\n",
       "      <td>RiskPerformance</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Horse colic</td>\n",
       "      <td>Horse colic/horseV2_processada.csv</td>\n",
       "      <td>surgery</td>\n",
       "      <td>could not convert string to float: '3.816.861....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ionosfera</td>\n",
       "      <td>Ionosfera/ionosphere.csv</td>\n",
       "      <td>target</td>\n",
       "      <td>valor da coluna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KC2</td>\n",
       "      <td>KC2/KC2.csv</td>\n",
       "      <td>defects</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>liver disorders_bupa</td>\n",
       "      <td>liver disorders_bupa/bupa.csv</td>\n",
       "      <td>selector</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mammographic_masses</td>\n",
       "      <td>mammographic_masses/mammographic_masses_cleane...</td>\n",
       "      <td>Severity</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mobile Price Classification</td>\n",
       "      <td>Mobile Price Classification/train_mobile_proce...</td>\n",
       "      <td>range</td>\n",
       "      <td>[{'Quantidade de instâncias contrafactuais': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Monk_1</td>\n",
       "      <td>['Monk/monks-1_train.csv', 'Monk/monks-1_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Monk_2</td>\n",
       "      <td>['Monk/monks-2_train.csv', 'Monk/monks-2_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>class name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Monk_3</td>\n",
       "      <td>['Monk/monks-3_train.csv', 'Monk/monks-3_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>class name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Musk</td>\n",
       "      <td>Musk/clean1.csv</td>\n",
       "      <td>Column169</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>OnlineNewsPopularity</td>\n",
       "      <td>OnlineNewsPopularity/OnlineNewsPopularity_proc...</td>\n",
       "      <td>class</td>\n",
       "      <td>could not convert string to float: '457.260.92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Phishing</td>\n",
       "      <td>Phishing/Phishing.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Room Occupancy</td>\n",
       "      <td>Room Occupancy/Room Occupancy.csv</td>\n",
       "      <td>Occupancy</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sonar</td>\n",
       "      <td>Sonar/sonar.all-data.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Spambase</td>\n",
       "      <td>Spambase/Spambase.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Student</td>\n",
       "      <td>Student/Students-Performance-MAT_processada.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>Input contains NaN, infinity or a value too la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>titanic</td>\n",
       "      <td>titanic/titanic_processada.csv</td>\n",
       "      <td>Survived</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo/Tokyo.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>twonorm</td>\n",
       "      <td>twonorm/twonorm.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Vertebral_2C</td>\n",
       "      <td>Vertebral/column_2C.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Vertebral_3C</td>\n",
       "      <td>Vertebral/column_3C.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Votes_Congressional</td>\n",
       "      <td>Votes_Congressional/house-votes-84_processada.csv</td>\n",
       "      <td>Class Name</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>wine</td>\n",
       "      <td>wine/WineQT.csv</td>\n",
       "      <td>quality</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Hill</td>\n",
       "      <td>['Hill/Hill_Valley_with_noise_Training.csv', '...</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  \\\n",
       "0                         Adult   \n",
       "1                    Australian   \n",
       "2                      Banknote   \n",
       "3                        Biodeg   \n",
       "4         Breast Cancer Coimbra   \n",
       "5       Breast Cancer Wisconsin   \n",
       "6                         Churn   \n",
       "7                        Compas   \n",
       "8                Credit default   \n",
       "9                      Diabetes   \n",
       "10                          EEg   \n",
       "11                       German   \n",
       "12             GiveMeSomeCredit   \n",
       "13                        Heart   \n",
       "14                      Heart_2   \n",
       "15                        HELOC   \n",
       "16                  Horse colic   \n",
       "17                    Ionosfera   \n",
       "18                          KC2   \n",
       "19         liver disorders_bupa   \n",
       "20          mammographic_masses   \n",
       "21  Mobile Price Classification   \n",
       "22                       Monk_1   \n",
       "23                       Monk_2   \n",
       "24                       Monk_3   \n",
       "25                         Musk   \n",
       "26         OnlineNewsPopularity   \n",
       "27                     Phishing   \n",
       "28               Room Occupancy   \n",
       "29                        Sonar   \n",
       "30                     Spambase   \n",
       "31                      Student   \n",
       "32                      titanic   \n",
       "33                        Tokyo   \n",
       "34                      twonorm   \n",
       "35                 Vertebral_2C   \n",
       "36                 Vertebral_3C   \n",
       "37          Votes_Congressional   \n",
       "38                         wine   \n",
       "39                         Hill   \n",
       "\n",
       "                                                 path  \\\n",
       "0                          adult/adult_processada.csv   \n",
       "1             Australian/Credit_Card_Applications.csv   \n",
       "2                Banknote/BankNote_Authentication.csv   \n",
       "3                              Biodeg/qsar-biodeg.csv   \n",
       "4            Breast Cancer Coimbra/breast_coimbra.csv   \n",
       "5           Breast Cancer Wisconsin/breast-cancer.csv   \n",
       "6   Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...   \n",
       "7                  Compas/compas-scores-two-years.csv   \n",
       "8                  Credit default/UCI_Credit_Card.csv   \n",
       "9                               Diabetes/diabetes.csv   \n",
       "10                              EEg/EEG Eye State.csv   \n",
       "11                           German/german_credit.csv   \n",
       "12   GiveMeSomeCredit/GiveMeSomeCredit_processada.csv   \n",
       "13                                    Heart/heart.csv   \n",
       "14                                   Heart/heart2.csv   \n",
       "15                         HELOC/heloc_dataset_v1.csv   \n",
       "16                 Horse colic/horseV2_processada.csv   \n",
       "17                           Ionosfera/ionosphere.csv   \n",
       "18                                        KC2/KC2.csv   \n",
       "19                      liver disorders_bupa/bupa.csv   \n",
       "20  mammographic_masses/mammographic_masses_cleane...   \n",
       "21  Mobile Price Classification/train_mobile_proce...   \n",
       "22  ['Monk/monks-1_train.csv', 'Monk/monks-1_test....   \n",
       "23  ['Monk/monks-2_train.csv', 'Monk/monks-2_test....   \n",
       "24  ['Monk/monks-3_train.csv', 'Monk/monks-3_test....   \n",
       "25                                    Musk/clean1.csv   \n",
       "26  OnlineNewsPopularity/OnlineNewsPopularity_proc...   \n",
       "27                              Phishing/Phishing.csv   \n",
       "28                  Room Occupancy/Room Occupancy.csv   \n",
       "29                           Sonar/sonar.all-data.csv   \n",
       "30                              Spambase/Spambase.csv   \n",
       "31    Student/Students-Performance-MAT_processada.csv   \n",
       "32                     titanic/titanic_processada.csv   \n",
       "33                                    Tokyo/Tokyo.csv   \n",
       "34                                twonorm/twonorm.csv   \n",
       "35                            Vertebral/column_2C.csv   \n",
       "36                            Vertebral/column_3C.csv   \n",
       "37  Votes_Congressional/house-votes-84_processada.csv   \n",
       "38                                    wine/WineQT.csv   \n",
       "39  ['Hill/Hill_Valley_with_noise_Training.csv', '...   \n",
       "\n",
       "                        classe  \\\n",
       "0              Above/Below 50K   \n",
       "1                        Class   \n",
       "2                        class   \n",
       "3                        Class   \n",
       "4               Classification   \n",
       "5                    diagnosis   \n",
       "6                        Churn   \n",
       "7               two_year_recid   \n",
       "8   default.payment.next.month   \n",
       "9                      Outcome   \n",
       "10                    Column15   \n",
       "11                     default   \n",
       "12            SeriousDlqin2yrs   \n",
       "13                      output   \n",
       "14                         num   \n",
       "15             RiskPerformance   \n",
       "16                     surgery   \n",
       "17                      target   \n",
       "18                     defects   \n",
       "19                    selector   \n",
       "20                    Severity   \n",
       "21                       range   \n",
       "22                       Class   \n",
       "23                       Class   \n",
       "24                       Class   \n",
       "25                   Column169   \n",
       "26                       class   \n",
       "27                       Class   \n",
       "28                   Occupancy   \n",
       "29                       class   \n",
       "30                       Class   \n",
       "31                       Class   \n",
       "32                    Survived   \n",
       "33                       class   \n",
       "34                       class   \n",
       "35                       class   \n",
       "36                       class   \n",
       "37                  Class Name   \n",
       "38                     quality   \n",
       "39                       class   \n",
       "\n",
       "                                              metrica  \n",
       "0                                        memoria 18gb  \n",
       "1   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "2   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "3                                     valor da coluna  \n",
       "4   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "5   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8                                             memoria  \n",
       "9   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "10                      list.remove(x): x not in list  \n",
       "11  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "12                                                NaN  \n",
       "13  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "14  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "15  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "16  could not convert string to float: '3.816.861....  \n",
       "17                                    valor da coluna  \n",
       "18  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "19  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "20  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "21  [{'Quantidade de instâncias contrafactuais': 1...  \n",
       "22                                                NaN  \n",
       "23                                         class name  \n",
       "24                                         class name  \n",
       "25                                                NaN  \n",
       "26  could not convert string to float: '457.260.92...  \n",
       "27  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "28  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "29  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "30  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "31  Input contains NaN, infinity or a value too la...  \n",
       "32                                                NaN  \n",
       "33  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "34  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "35  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "36                                                NaN  \n",
       "37  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "38                                                NaN  \n",
       "39                                                NaN  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a88d7fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Churn/WA_Fn-UseC_-Telco-Customer-Churn_processada.csv'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm_use.iloc[6]['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "da6ee1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>...</th>\n",
       "      <th>A26</th>\n",
       "      <th>A27</th>\n",
       "      <th>A28</th>\n",
       "      <th>A29</th>\n",
       "      <th>A30</th>\n",
       "      <th>A31</th>\n",
       "      <th>A32</th>\n",
       "      <th>A33</th>\n",
       "      <th>A34</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83508</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.73739</td>\n",
       "      <td>-0.14706</td>\n",
       "      <td>0.84349</td>\n",
       "      <td>-0.05567</td>\n",
       "      <td>0.90441</td>\n",
       "      <td>-0.04622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.04202</td>\n",
       "      <td>0.83479</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.12815</td>\n",
       "      <td>0.86660</td>\n",
       "      <td>-0.10714</td>\n",
       "      <td>0.90546</td>\n",
       "      <td>-0.04307</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95113</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>0.95183</td>\n",
       "      <td>-0.02723</td>\n",
       "      <td>0.93438</td>\n",
       "      <td>-0.01920</td>\n",
       "      <td>0.94590</td>\n",
       "      <td>0.01606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01361</td>\n",
       "      <td>0.93522</td>\n",
       "      <td>0.04925</td>\n",
       "      <td>0.93159</td>\n",
       "      <td>0.08168</td>\n",
       "      <td>0.94066</td>\n",
       "      <td>-0.00035</td>\n",
       "      <td>0.91483</td>\n",
       "      <td>0.04712</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94701</td>\n",
       "      <td>-0.00034</td>\n",
       "      <td>0.93207</td>\n",
       "      <td>-0.03227</td>\n",
       "      <td>0.95177</td>\n",
       "      <td>-0.03431</td>\n",
       "      <td>0.95584</td>\n",
       "      <td>0.02446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03193</td>\n",
       "      <td>0.92489</td>\n",
       "      <td>0.02542</td>\n",
       "      <td>0.92120</td>\n",
       "      <td>0.02242</td>\n",
       "      <td>0.92459</td>\n",
       "      <td>0.00442</td>\n",
       "      <td>0.92697</td>\n",
       "      <td>-0.00577</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90608</td>\n",
       "      <td>-0.01657</td>\n",
       "      <td>0.98122</td>\n",
       "      <td>-0.01989</td>\n",
       "      <td>0.95691</td>\n",
       "      <td>-0.03646</td>\n",
       "      <td>0.85746</td>\n",
       "      <td>0.00110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02099</td>\n",
       "      <td>0.89147</td>\n",
       "      <td>-0.07760</td>\n",
       "      <td>0.82983</td>\n",
       "      <td>-0.17238</td>\n",
       "      <td>0.96022</td>\n",
       "      <td>-0.03757</td>\n",
       "      <td>0.87403</td>\n",
       "      <td>-0.16243</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84710</td>\n",
       "      <td>0.13533</td>\n",
       "      <td>0.73638</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>0.87873</td>\n",
       "      <td>0.08260</td>\n",
       "      <td>0.88928</td>\n",
       "      <td>-0.09139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15114</td>\n",
       "      <td>0.81147</td>\n",
       "      <td>-0.04822</td>\n",
       "      <td>0.78207</td>\n",
       "      <td>-0.00703</td>\n",
       "      <td>0.75747</td>\n",
       "      <td>-0.06678</td>\n",
       "      <td>0.85764</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A1  A2       A3       A4       A5       A6       A7       A8       A9  \\\n",
       "0     1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
       "1     1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "2     1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "3     1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
       "4     1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
       "..   ..  ..      ...      ...      ...      ...      ...      ...      ...   \n",
       "346   1   0  0.83508  0.08298  0.73739 -0.14706  0.84349 -0.05567  0.90441   \n",
       "347   1   0  0.95113  0.00419  0.95183 -0.02723  0.93438 -0.01920  0.94590   \n",
       "348   1   0  0.94701 -0.00034  0.93207 -0.03227  0.95177 -0.03431  0.95584   \n",
       "349   1   0  0.90608 -0.01657  0.98122 -0.01989  0.95691 -0.03646  0.85746   \n",
       "350   1   0  0.84710  0.13533  0.73638 -0.06151  0.87873  0.08260  0.88928   \n",
       "\n",
       "         A10  ...      A26      A27      A28      A29      A30      A31  \\\n",
       "0    0.03760  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
       "1   -0.04549  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
       "2    0.01198  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
       "3    0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
       "4   -0.16399  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
       "..       ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "346 -0.04622  ... -0.04202  0.83479  0.00123  1.00000  0.12815  0.86660   \n",
       "347  0.01606  ...  0.01361  0.93522  0.04925  0.93159  0.08168  0.94066   \n",
       "348  0.02446  ...  0.03193  0.92489  0.02542  0.92120  0.02242  0.92459   \n",
       "349  0.00110  ... -0.02099  0.89147 -0.07760  0.82983 -0.17238  0.96022   \n",
       "350 -0.09139  ... -0.15114  0.81147 -0.04822  0.78207 -0.00703  0.75747   \n",
       "\n",
       "         A32      A33      A34  target  \n",
       "0   -0.54487  0.18641 -0.45300       g  \n",
       "1   -0.06288 -0.13738 -0.02447       b  \n",
       "2   -0.24180  0.56045 -0.38238       g  \n",
       "3    1.00000 -0.32382  1.00000       b  \n",
       "4   -0.59573 -0.04608 -0.65697       g  \n",
       "..       ...      ...      ...     ...  \n",
       "346 -0.10714  0.90546 -0.04307       g  \n",
       "347 -0.00035  0.91483  0.04712       g  \n",
       "348  0.00442  0.92697 -0.00577       g  \n",
       "349 -0.03757  0.87403 -0.16243       g  \n",
       "350 -0.06678  0.85764 -0.06151       g  \n",
       "\n",
       "[351 rows x 35 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"s3://omar-testes-gerais/artigos/artifacts/datasets/Ionosfera/ionosphere.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e744df4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O DataFrame não contém valores NaN.\n",
      "O DataFrame não contém valores infinitos (inf).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Suponha que df seja o seu DataFrame\n",
    "# Verificar se há valores NaN\n",
    "has_nans = df.isna().any().any()\n",
    "\n",
    "# Verificar se há valores infinitos (positivos ou negativos)\n",
    "has_infs = np.isinf(df).any().any()\n",
    "\n",
    "# Exibir os resultados\n",
    "if has_nans:\n",
    "    print(\"O DataFrame contém valores NaN.\")\n",
    "else:\n",
    "    print(\"O DataFrame não contém valores NaN.\")\n",
    "\n",
    "if has_infs:\n",
    "    print(\"O DataFrame contém valores infinitos (inf).\")\n",
    "else:\n",
    "    print(\"O DataFrame não contém valores infinitos (inf).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43fae56",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9212839",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "    \"grupo-1\": [\"Adult\", \"Banknote\", \"KC2\", \"titanic\"],\n",
    "    \"grupo-2\": [\"Australian\", \"Breast Cancer Coimbra\", \"liver disorders_bupa\", \"Room Occupancy\"],\n",
    "    \"grupo-3\": [\"Compas\", \"Ionosfera\", \"Vertebral_2C\", \"Vertebral_3C\", \"GiveMeSomeCredit\"],\n",
    "    \"grupo-4\": [\"Breast Cancer Wisconsin\", \"Diabetes\", \"Phishing\", \"Horse colic\"],\n",
    "    \"grupo-5\": [\"Churn\", \"Heart\", \"mammographic_masses\", \"wine\"],\n",
    "    \"grupo-6\": [\"Credit default\", \"Hill \", \"Mobile Price Classification\", \"Monk_1\"],\n",
    "    \"grupo-7\": [\"EEg\", \"German\", \"Monk_2\", \"Heart_2\"],\n",
    "    \"grupo-8\": [\"HELOC\", \"Mushrooms \", \"Biodeg\", \"Sonar\"],\n",
    "    \"grupo-9\": [\"Monk_3\", \"Musk\", \"Spambase\", \"Student\"],\n",
    "    \"grupo-10\": [\"OnlineNewsPopularity\", \"Tokyo\", \"twonorm\", \"Votes_Congressional\"]\n",
    "}\n",
    "\n",
    "groups = {\n",
    "    \"grupo-memoria\": [\"Adult\", \"Credit default\", ],\n",
    "    \"grupo-nulo\": ['Biodeg'],\n",
    "    \"memoria\": ['wine', 'Vertebral_3C',],\n",
    "    'falta': ['EEg', \"Hill\", \"Mobile Price Classification\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4463db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5ad5780c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>classe</th>\n",
       "      <th>metrica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult</td>\n",
       "      <td>adult/adult_processada.csv</td>\n",
       "      <td>Above/Below 50K</td>\n",
       "      <td>memoria 18gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australian</td>\n",
       "      <td>Australian/Credit_Card_Applications.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Banknote</td>\n",
       "      <td>Banknote/BankNote_Authentication.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biodeg</td>\n",
       "      <td>Biodeg/qsar-biodeg.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>valor da coluna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Coimbra</td>\n",
       "      <td>Breast Cancer Coimbra/breast_coimbra.csv</td>\n",
       "      <td>Classification</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Breast Cancer Wisconsin</td>\n",
       "      <td>Breast Cancer Wisconsin/breast-cancer.csv</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Churn</td>\n",
       "      <td>Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...</td>\n",
       "      <td>Churn</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Compas</td>\n",
       "      <td>Compas/compas-scores-two-years.csv</td>\n",
       "      <td>two_year_recid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit default</td>\n",
       "      <td>Credit default/UCI_Credit_Card.csv</td>\n",
       "      <td>default.payment.next.month</td>\n",
       "      <td>memoria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Diabetes/diabetes.csv</td>\n",
       "      <td>Outcome</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EEg</td>\n",
       "      <td>EEg/EEG Eye State.csv</td>\n",
       "      <td>Column15</td>\n",
       "      <td>list.remove(x): x not in list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>German</td>\n",
       "      <td>German/german_credit.csv</td>\n",
       "      <td>default</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GiveMeSomeCredit</td>\n",
       "      <td>GiveMeSomeCredit/GiveMeSomeCredit_processada.csv</td>\n",
       "      <td>SeriousDlqin2yrs</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Heart</td>\n",
       "      <td>Heart/heart.csv</td>\n",
       "      <td>output</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Heart_2</td>\n",
       "      <td>Heart/heart2.csv</td>\n",
       "      <td>num</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HELOC</td>\n",
       "      <td>HELOC/heloc_dataset_v1.csv</td>\n",
       "      <td>RiskPerformance</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Horse colic</td>\n",
       "      <td>Horse colic/horseV2_processada.csv</td>\n",
       "      <td>surgery</td>\n",
       "      <td>could not convert string to float: '3.816.861....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ionosfera</td>\n",
       "      <td>Ionosfera/ionosphere.csv</td>\n",
       "      <td>target</td>\n",
       "      <td>valor da coluna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KC2</td>\n",
       "      <td>KC2/KC2.csv</td>\n",
       "      <td>defects</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>liver disorders_bupa</td>\n",
       "      <td>liver disorders_bupa/bupa.csv</td>\n",
       "      <td>selector</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mammographic_masses</td>\n",
       "      <td>mammographic_masses/mammographic_masses_cleane...</td>\n",
       "      <td>Severity</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mobile Price Classification</td>\n",
       "      <td>Mobile Price Classification/train_mobile_proce...</td>\n",
       "      <td>range</td>\n",
       "      <td>[{'Quantidade de instâncias contrafactuais': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Monk_1</td>\n",
       "      <td>['Monk/monks-1_train.csv', 'Monk/monks-1_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Monk_2</td>\n",
       "      <td>['Monk/monks-2_train.csv', 'Monk/monks-2_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>class name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Monk_3</td>\n",
       "      <td>['Monk/monks-3_train.csv', 'Monk/monks-3_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>class name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Musk</td>\n",
       "      <td>Musk/clean1.csv</td>\n",
       "      <td>Column169</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>OnlineNewsPopularity</td>\n",
       "      <td>OnlineNewsPopularity/OnlineNewsPopularity_proc...</td>\n",
       "      <td>class</td>\n",
       "      <td>could not convert string to float: '457.260.92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Phishing</td>\n",
       "      <td>Phishing/Phishing.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Room Occupancy</td>\n",
       "      <td>Room Occupancy/Room Occupancy.csv</td>\n",
       "      <td>Occupancy</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sonar</td>\n",
       "      <td>Sonar/sonar.all-data.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Spambase</td>\n",
       "      <td>Spambase/Spambase.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Student</td>\n",
       "      <td>Student/Students-Performance-MAT_processada.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>Input contains NaN, infinity or a value too la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>titanic</td>\n",
       "      <td>titanic/titanic_processada.csv</td>\n",
       "      <td>Survived</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo/Tokyo.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>twonorm</td>\n",
       "      <td>twonorm/twonorm.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Vertebral_2C</td>\n",
       "      <td>Vertebral/column_2C.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Vertebral_3C</td>\n",
       "      <td>Vertebral/column_3C.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Votes_Congressional</td>\n",
       "      <td>Votes_Congressional/house-votes-84_processada.csv</td>\n",
       "      <td>Class Name</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>wine</td>\n",
       "      <td>wine/WineQT.csv</td>\n",
       "      <td>quality</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Hill</td>\n",
       "      <td>['Hill/Hill_Valley_with_noise_Training.csv', '...</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  \\\n",
       "0                         Adult   \n",
       "1                    Australian   \n",
       "2                      Banknote   \n",
       "3                        Biodeg   \n",
       "4         Breast Cancer Coimbra   \n",
       "5       Breast Cancer Wisconsin   \n",
       "6                         Churn   \n",
       "7                        Compas   \n",
       "8                Credit default   \n",
       "9                      Diabetes   \n",
       "10                          EEg   \n",
       "11                       German   \n",
       "12             GiveMeSomeCredit   \n",
       "13                        Heart   \n",
       "14                      Heart_2   \n",
       "15                        HELOC   \n",
       "16                  Horse colic   \n",
       "17                    Ionosfera   \n",
       "18                          KC2   \n",
       "19         liver disorders_bupa   \n",
       "20          mammographic_masses   \n",
       "21  Mobile Price Classification   \n",
       "22                       Monk_1   \n",
       "23                       Monk_2   \n",
       "24                       Monk_3   \n",
       "25                         Musk   \n",
       "26         OnlineNewsPopularity   \n",
       "27                     Phishing   \n",
       "28               Room Occupancy   \n",
       "29                        Sonar   \n",
       "30                     Spambase   \n",
       "31                      Student   \n",
       "32                      titanic   \n",
       "33                        Tokyo   \n",
       "34                      twonorm   \n",
       "35                 Vertebral_2C   \n",
       "36                 Vertebral_3C   \n",
       "37          Votes_Congressional   \n",
       "38                         wine   \n",
       "39                         Hill   \n",
       "\n",
       "                                                 path  \\\n",
       "0                          adult/adult_processada.csv   \n",
       "1             Australian/Credit_Card_Applications.csv   \n",
       "2                Banknote/BankNote_Authentication.csv   \n",
       "3                              Biodeg/qsar-biodeg.csv   \n",
       "4            Breast Cancer Coimbra/breast_coimbra.csv   \n",
       "5           Breast Cancer Wisconsin/breast-cancer.csv   \n",
       "6   Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...   \n",
       "7                  Compas/compas-scores-two-years.csv   \n",
       "8                  Credit default/UCI_Credit_Card.csv   \n",
       "9                               Diabetes/diabetes.csv   \n",
       "10                              EEg/EEG Eye State.csv   \n",
       "11                           German/german_credit.csv   \n",
       "12   GiveMeSomeCredit/GiveMeSomeCredit_processada.csv   \n",
       "13                                    Heart/heart.csv   \n",
       "14                                   Heart/heart2.csv   \n",
       "15                         HELOC/heloc_dataset_v1.csv   \n",
       "16                 Horse colic/horseV2_processada.csv   \n",
       "17                           Ionosfera/ionosphere.csv   \n",
       "18                                        KC2/KC2.csv   \n",
       "19                      liver disorders_bupa/bupa.csv   \n",
       "20  mammographic_masses/mammographic_masses_cleane...   \n",
       "21  Mobile Price Classification/train_mobile_proce...   \n",
       "22  ['Monk/monks-1_train.csv', 'Monk/monks-1_test....   \n",
       "23  ['Monk/monks-2_train.csv', 'Monk/monks-2_test....   \n",
       "24  ['Monk/monks-3_train.csv', 'Monk/monks-3_test....   \n",
       "25                                    Musk/clean1.csv   \n",
       "26  OnlineNewsPopularity/OnlineNewsPopularity_proc...   \n",
       "27                              Phishing/Phishing.csv   \n",
       "28                  Room Occupancy/Room Occupancy.csv   \n",
       "29                           Sonar/sonar.all-data.csv   \n",
       "30                              Spambase/Spambase.csv   \n",
       "31    Student/Students-Performance-MAT_processada.csv   \n",
       "32                     titanic/titanic_processada.csv   \n",
       "33                                    Tokyo/Tokyo.csv   \n",
       "34                                twonorm/twonorm.csv   \n",
       "35                            Vertebral/column_2C.csv   \n",
       "36                            Vertebral/column_3C.csv   \n",
       "37  Votes_Congressional/house-votes-84_processada.csv   \n",
       "38                                    wine/WineQT.csv   \n",
       "39  ['Hill/Hill_Valley_with_noise_Training.csv', '...   \n",
       "\n",
       "                        classe  \\\n",
       "0              Above/Below 50K   \n",
       "1                        Class   \n",
       "2                        class   \n",
       "3                        Class   \n",
       "4               Classification   \n",
       "5                    diagnosis   \n",
       "6                        Churn   \n",
       "7               two_year_recid   \n",
       "8   default.payment.next.month   \n",
       "9                      Outcome   \n",
       "10                    Column15   \n",
       "11                     default   \n",
       "12            SeriousDlqin2yrs   \n",
       "13                      output   \n",
       "14                         num   \n",
       "15             RiskPerformance   \n",
       "16                     surgery   \n",
       "17                      target   \n",
       "18                     defects   \n",
       "19                    selector   \n",
       "20                    Severity   \n",
       "21                       range   \n",
       "22                       Class   \n",
       "23                       Class   \n",
       "24                       Class   \n",
       "25                   Column169   \n",
       "26                       class   \n",
       "27                       Class   \n",
       "28                   Occupancy   \n",
       "29                       class   \n",
       "30                       Class   \n",
       "31                       Class   \n",
       "32                    Survived   \n",
       "33                       class   \n",
       "34                       class   \n",
       "35                       class   \n",
       "36                       class   \n",
       "37                  Class Name   \n",
       "38                     quality   \n",
       "39                       class   \n",
       "\n",
       "                                              metrica  \n",
       "0                                        memoria 18gb  \n",
       "1   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "2   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "3                                     valor da coluna  \n",
       "4   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "5   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8                                             memoria  \n",
       "9   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "10                      list.remove(x): x not in list  \n",
       "11  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "12                                                NaN  \n",
       "13  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "14  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "15  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "16  could not convert string to float: '3.816.861....  \n",
       "17                                    valor da coluna  \n",
       "18  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "19  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "20  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "21  [{'Quantidade de instâncias contrafactuais': 1...  \n",
       "22                                                NaN  \n",
       "23                                         class name  \n",
       "24                                         class name  \n",
       "25                                                NaN  \n",
       "26  could not convert string to float: '457.260.92...  \n",
       "27  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "28  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "29  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "30  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "31  Input contains NaN, infinity or a value too la...  \n",
       "32                                                NaN  \n",
       "33  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "34  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "35  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "36                                                NaN  \n",
       "37  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "38                                                NaN  \n",
       "39                                                NaN  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2c23380d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>classe</th>\n",
       "      <th>metrica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult</td>\n",
       "      <td>adult/adult_processada.csv</td>\n",
       "      <td>Above/Below 50K</td>\n",
       "      <td>memoria 18gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australian</td>\n",
       "      <td>Australian/Credit_Card_Applications.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Banknote</td>\n",
       "      <td>Banknote/BankNote_Authentication.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biodeg</td>\n",
       "      <td>Biodeg/qsar-biodeg.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>valor da coluna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Coimbra</td>\n",
       "      <td>Breast Cancer Coimbra/breast_coimbra.csv</td>\n",
       "      <td>Classification</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Breast Cancer Wisconsin</td>\n",
       "      <td>Breast Cancer Wisconsin/breast-cancer.csv</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Churn</td>\n",
       "      <td>Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...</td>\n",
       "      <td>Churn</td>\n",
       "      <td>could not convert string to float: '22.833.004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Compas</td>\n",
       "      <td>Compas/compas-scores-two-years.csv</td>\n",
       "      <td>two_year_recid</td>\n",
       "      <td>could not convert string to float: 'walter mei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit default</td>\n",
       "      <td>Credit default/UCI_Credit_Card.csv</td>\n",
       "      <td>default.payment.next.month</td>\n",
       "      <td>memoria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Diabetes/diabetes.csv</td>\n",
       "      <td>Outcome</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EEg</td>\n",
       "      <td>EEg/EEG Eye State.csv</td>\n",
       "      <td>Column15</td>\n",
       "      <td>list.remove(x): x not in list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>German</td>\n",
       "      <td>German/german_credit.csv</td>\n",
       "      <td>default</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GiveMeSomeCredit</td>\n",
       "      <td>GiveMeSomeCredit/GiveMeSomeCredit_processada.csv</td>\n",
       "      <td>SeriousDlqin2yrs</td>\n",
       "      <td>could not convert string to float: '6.670.221....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Heart</td>\n",
       "      <td>Heart/heart.csv</td>\n",
       "      <td>output</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Heart_2</td>\n",
       "      <td>Heart/heart2.csv</td>\n",
       "      <td>num</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HELOC</td>\n",
       "      <td>HELOC/heloc_dataset_v1.csv</td>\n",
       "      <td>RiskPerformance</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Horse colic</td>\n",
       "      <td>Horse colic/horseV2_processada.csv</td>\n",
       "      <td>surgery</td>\n",
       "      <td>could not convert string to float: '3.816.861....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ionosfera</td>\n",
       "      <td>Ionosfera/ionosphere.csv</td>\n",
       "      <td>target</td>\n",
       "      <td>Input contains NaN, infinity or a value too la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KC2</td>\n",
       "      <td>KC2/KC2.csv</td>\n",
       "      <td>defects</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>liver disorders_bupa</td>\n",
       "      <td>liver disorders_bupa/bupa.csv</td>\n",
       "      <td>selector</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mammographic_masses</td>\n",
       "      <td>mammographic_masses/mammographic_masses_cleane...</td>\n",
       "      <td>Severity</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mobile Price Classification</td>\n",
       "      <td>Mobile Price Classification/train_mobile_proce...</td>\n",
       "      <td>range</td>\n",
       "      <td>[{'Quantidade de instâncias contrafactuais': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Monk_1</td>\n",
       "      <td>['Monk/monks-1_train.csv', 'Monk/monks-1_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>[{'Quantidade de instâncias contrafactuais': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Monk_2</td>\n",
       "      <td>['Monk/monks-2_train.csv', 'Monk/monks-2_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>[{'Quantidade de instâncias contrafactuais': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Monk_3</td>\n",
       "      <td>['Monk/monks-3_train.csv', 'Monk/monks-3_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>[{'Quantidade de instâncias contrafactuais': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Musk</td>\n",
       "      <td>Musk/clean1.csv</td>\n",
       "      <td>Column169</td>\n",
       "      <td>list.remove(x): x not in list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>OnlineNewsPopularity</td>\n",
       "      <td>OnlineNewsPopularity/OnlineNewsPopularity_proc...</td>\n",
       "      <td>class</td>\n",
       "      <td>could not convert string to float: '457.260.92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Phishing</td>\n",
       "      <td>Phishing/Phishing.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Room Occupancy</td>\n",
       "      <td>Room Occupancy/Room Occupancy.csv</td>\n",
       "      <td>Occupancy</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sonar</td>\n",
       "      <td>Sonar/sonar.all-data.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Spambase</td>\n",
       "      <td>Spambase/Spambase.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Student</td>\n",
       "      <td>Student/Students-Performance-MAT_processada.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>Input contains NaN, infinity or a value too la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>titanic</td>\n",
       "      <td>titanic/titanic_processada.csv</td>\n",
       "      <td>Survived</td>\n",
       "      <td>Input contains NaN, infinity or a value too la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo/Tokyo.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>twonorm</td>\n",
       "      <td>twonorm/twonorm.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Vertebral_2C</td>\n",
       "      <td>Vertebral/column_2C.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Vertebral_3C</td>\n",
       "      <td>Vertebral/column_3C.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Votes_Congressional</td>\n",
       "      <td>Votes_Congressional/house-votes-84_processada.csv</td>\n",
       "      <td>Class Name</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>wine</td>\n",
       "      <td>wine/WineQT.csv</td>\n",
       "      <td>quality</td>\n",
       "      <td>demorou demais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Hill</td>\n",
       "      <td>['Hill/Hill_Valley_with_noise_Training.csv', '...</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  \\\n",
       "0                         Adult   \n",
       "1                    Australian   \n",
       "2                      Banknote   \n",
       "3                        Biodeg   \n",
       "4         Breast Cancer Coimbra   \n",
       "5       Breast Cancer Wisconsin   \n",
       "6                         Churn   \n",
       "7                        Compas   \n",
       "8                Credit default   \n",
       "9                      Diabetes   \n",
       "10                          EEg   \n",
       "11                       German   \n",
       "12             GiveMeSomeCredit   \n",
       "13                        Heart   \n",
       "14                      Heart_2   \n",
       "15                        HELOC   \n",
       "16                  Horse colic   \n",
       "17                    Ionosfera   \n",
       "18                          KC2   \n",
       "19         liver disorders_bupa   \n",
       "20          mammographic_masses   \n",
       "21  Mobile Price Classification   \n",
       "22                       Monk_1   \n",
       "23                       Monk_2   \n",
       "24                       Monk_3   \n",
       "25                         Musk   \n",
       "26         OnlineNewsPopularity   \n",
       "27                     Phishing   \n",
       "28               Room Occupancy   \n",
       "29                        Sonar   \n",
       "30                     Spambase   \n",
       "31                      Student   \n",
       "32                      titanic   \n",
       "33                        Tokyo   \n",
       "34                      twonorm   \n",
       "35                 Vertebral_2C   \n",
       "36                 Vertebral_3C   \n",
       "37          Votes_Congressional   \n",
       "38                         wine   \n",
       "39                         Hill   \n",
       "\n",
       "                                                 path  \\\n",
       "0                          adult/adult_processada.csv   \n",
       "1             Australian/Credit_Card_Applications.csv   \n",
       "2                Banknote/BankNote_Authentication.csv   \n",
       "3                              Biodeg/qsar-biodeg.csv   \n",
       "4            Breast Cancer Coimbra/breast_coimbra.csv   \n",
       "5           Breast Cancer Wisconsin/breast-cancer.csv   \n",
       "6   Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...   \n",
       "7                  Compas/compas-scores-two-years.csv   \n",
       "8                  Credit default/UCI_Credit_Card.csv   \n",
       "9                               Diabetes/diabetes.csv   \n",
       "10                              EEg/EEG Eye State.csv   \n",
       "11                           German/german_credit.csv   \n",
       "12   GiveMeSomeCredit/GiveMeSomeCredit_processada.csv   \n",
       "13                                    Heart/heart.csv   \n",
       "14                                   Heart/heart2.csv   \n",
       "15                         HELOC/heloc_dataset_v1.csv   \n",
       "16                 Horse colic/horseV2_processada.csv   \n",
       "17                           Ionosfera/ionosphere.csv   \n",
       "18                                        KC2/KC2.csv   \n",
       "19                      liver disorders_bupa/bupa.csv   \n",
       "20  mammographic_masses/mammographic_masses_cleane...   \n",
       "21  Mobile Price Classification/train_mobile_proce...   \n",
       "22  ['Monk/monks-1_train.csv', 'Monk/monks-1_test....   \n",
       "23  ['Monk/monks-2_train.csv', 'Monk/monks-2_test....   \n",
       "24  ['Monk/monks-3_train.csv', 'Monk/monks-3_test....   \n",
       "25                                    Musk/clean1.csv   \n",
       "26  OnlineNewsPopularity/OnlineNewsPopularity_proc...   \n",
       "27                              Phishing/Phishing.csv   \n",
       "28                  Room Occupancy/Room Occupancy.csv   \n",
       "29                           Sonar/sonar.all-data.csv   \n",
       "30                              Spambase/Spambase.csv   \n",
       "31    Student/Students-Performance-MAT_processada.csv   \n",
       "32                     titanic/titanic_processada.csv   \n",
       "33                                    Tokyo/Tokyo.csv   \n",
       "34                                twonorm/twonorm.csv   \n",
       "35                            Vertebral/column_2C.csv   \n",
       "36                            Vertebral/column_3C.csv   \n",
       "37  Votes_Congressional/house-votes-84_processada.csv   \n",
       "38                                    wine/WineQT.csv   \n",
       "39  ['Hill/Hill_Valley_with_noise_Training.csv', '...   \n",
       "\n",
       "                        classe  \\\n",
       "0              Above/Below 50K   \n",
       "1                        Class   \n",
       "2                        class   \n",
       "3                        Class   \n",
       "4               Classification   \n",
       "5                    diagnosis   \n",
       "6                        Churn   \n",
       "7               two_year_recid   \n",
       "8   default.payment.next.month   \n",
       "9                      Outcome   \n",
       "10                    Column15   \n",
       "11                     default   \n",
       "12            SeriousDlqin2yrs   \n",
       "13                      output   \n",
       "14                         num   \n",
       "15             RiskPerformance   \n",
       "16                     surgery   \n",
       "17                      target   \n",
       "18                     defects   \n",
       "19                    selector   \n",
       "20                    Severity   \n",
       "21                       range   \n",
       "22                       Class   \n",
       "23                       Class   \n",
       "24                       Class   \n",
       "25                   Column169   \n",
       "26                       class   \n",
       "27                       Class   \n",
       "28                   Occupancy   \n",
       "29                       class   \n",
       "30                       Class   \n",
       "31                       Class   \n",
       "32                    Survived   \n",
       "33                       class   \n",
       "34                       class   \n",
       "35                       class   \n",
       "36                       class   \n",
       "37                  Class Name   \n",
       "38                     quality   \n",
       "39                       class   \n",
       "\n",
       "                                              metrica  \n",
       "0                                        memoria 18gb  \n",
       "1   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "2   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "3                                     valor da coluna  \n",
       "4   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "5   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "6   could not convert string to float: '22.833.004...  \n",
       "7   could not convert string to float: 'walter mei...  \n",
       "8                                             memoria  \n",
       "9   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "10                      list.remove(x): x not in list  \n",
       "11  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "12  could not convert string to float: '6.670.221....  \n",
       "13  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "14  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "15  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "16  could not convert string to float: '3.816.861....  \n",
       "17  Input contains NaN, infinity or a value too la...  \n",
       "18  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "19  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "20  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "21  [{'Quantidade de instâncias contrafactuais': 1...  \n",
       "22  [{'Quantidade de instâncias contrafactuais': 1...  \n",
       "23  [{'Quantidade de instâncias contrafactuais': 1...  \n",
       "24  [{'Quantidade de instâncias contrafactuais': 1...  \n",
       "25                      list.remove(x): x not in list  \n",
       "26  could not convert string to float: '457.260.92...  \n",
       "27  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "28  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "29  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "30  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "31  Input contains NaN, infinity or a value too la...  \n",
       "32  Input contains NaN, infinity or a value too la...  \n",
       "33  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "34  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "35  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "36                                                NaN  \n",
       "37  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "38                                     demorou demais  \n",
       "39                                                NaN  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm_use.loc[21, 'metrica'] = [{\n",
    "  \"Quantidade de instâncias contrafactuais\": 110,\n",
    "  \"Quantidade de relações causais na base de dados\": 4,\n",
    "  \"Quantidade de atributos modificados\": 62,\n",
    "  \"Quantidade de instâncias contrafactuais causais\": 31,\n",
    "  \"Quantidade de relações causais analisadas\": 6,\n",
    "  \"Quantidade de relações causais satisfeitas\": 6,\n",
    "  \"Quantidade de instâncias contrafactuais com um único atributo modificado\": 26,\n",
    "  \"Tempo de execução\": 105.8550853729248\n",
    "}\n",
    "]\n",
    "dfm_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3edabdf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>classe</th>\n",
       "      <th>metrica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult</td>\n",
       "      <td>adult/adult_processada.csv</td>\n",
       "      <td>Above/Below 50K</td>\n",
       "      <td>memoria 18gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australian</td>\n",
       "      <td>Australian/Credit_Card_Applications.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Banknote</td>\n",
       "      <td>Banknote/BankNote_Authentication.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biodeg</td>\n",
       "      <td>Biodeg/qsar-biodeg.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>valor da coluna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Coimbra</td>\n",
       "      <td>Breast Cancer Coimbra/breast_coimbra.csv</td>\n",
       "      <td>Classification</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Breast Cancer Wisconsin</td>\n",
       "      <td>Breast Cancer Wisconsin/breast-cancer.csv</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Churn</td>\n",
       "      <td>Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...</td>\n",
       "      <td>Churn</td>\n",
       "      <td>could not convert string to float: '22.833.004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Compas</td>\n",
       "      <td>Compas/compas-scores-two-years.csv</td>\n",
       "      <td>two_year_recid</td>\n",
       "      <td>could not convert string to float: 'walter mei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit default</td>\n",
       "      <td>Credit default/UCI_Credit_Card.csv</td>\n",
       "      <td>default.payment.next.month</td>\n",
       "      <td>memoria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Diabetes/diabetes.csv</td>\n",
       "      <td>Outcome</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EEg</td>\n",
       "      <td>EEg/EEG Eye State.csv</td>\n",
       "      <td>Column15</td>\n",
       "      <td>list.remove(x): x not in list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>German</td>\n",
       "      <td>German/german_credit.csv</td>\n",
       "      <td>default</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GiveMeSomeCredit</td>\n",
       "      <td>GiveMeSomeCredit/GiveMeSomeCredit_processada.csv</td>\n",
       "      <td>SeriousDlqin2yrs</td>\n",
       "      <td>could not convert string to float: '6.670.221....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Heart</td>\n",
       "      <td>Heart/heart.csv</td>\n",
       "      <td>output</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Heart_2</td>\n",
       "      <td>Heart/heart2.csv</td>\n",
       "      <td>num</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HELOC</td>\n",
       "      <td>HELOC/heloc_dataset_v1.csv</td>\n",
       "      <td>RiskPerformance</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Horse colic</td>\n",
       "      <td>Horse colic/horseV2_processada.csv</td>\n",
       "      <td>surgery</td>\n",
       "      <td>could not convert string to float: '3.816.861....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ionosfera</td>\n",
       "      <td>Ionosfera/ionosphere.csv</td>\n",
       "      <td>target</td>\n",
       "      <td>Input contains NaN, infinity or a value too la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KC2</td>\n",
       "      <td>KC2/KC2.csv</td>\n",
       "      <td>defects</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>liver disorders_bupa</td>\n",
       "      <td>liver disorders_bupa/bupa.csv</td>\n",
       "      <td>selector</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mammographic_masses</td>\n",
       "      <td>mammographic_masses/mammographic_masses_cleane...</td>\n",
       "      <td>Severity</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mobile Price Classification</td>\n",
       "      <td>Mobile Price Classification/train_mobile_proce...</td>\n",
       "      <td>range</td>\n",
       "      <td>[{'Quantidade de instâncias contrafactuais': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Monk_1</td>\n",
       "      <td>['Monk/monks-1_train.csv', 'Monk/monks-1_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>[{'Quantidade de instâncias contrafactuais': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Monk_2</td>\n",
       "      <td>['Monk/monks-2_train.csv', 'Monk/monks-2_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>[{'Quantidade de instâncias contrafactuais': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Monk_3</td>\n",
       "      <td>['Monk/monks-3_train.csv', 'Monk/monks-3_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>[{'Quantidade de instâncias contrafactuais': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Musk</td>\n",
       "      <td>Musk/clean1.csv</td>\n",
       "      <td>Column169</td>\n",
       "      <td>list.remove(x): x not in list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>OnlineNewsPopularity</td>\n",
       "      <td>OnlineNewsPopularity/OnlineNewsPopularity_proc...</td>\n",
       "      <td>class</td>\n",
       "      <td>could not convert string to float: '457.260.92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Phishing</td>\n",
       "      <td>Phishing/Phishing.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Room Occupancy</td>\n",
       "      <td>Room Occupancy/Room Occupancy.csv</td>\n",
       "      <td>Occupancy</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sonar</td>\n",
       "      <td>Sonar/sonar.all-data.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Spambase</td>\n",
       "      <td>Spambase/Spambase.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Student</td>\n",
       "      <td>Student/Students-Performance-MAT_processada.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>Input contains NaN, infinity or a value too la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>titanic</td>\n",
       "      <td>titanic/titanic_processada.csv</td>\n",
       "      <td>Survived</td>\n",
       "      <td>Input contains NaN, infinity or a value too la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo/Tokyo.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>twonorm</td>\n",
       "      <td>twonorm/twonorm.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Vertebral_2C</td>\n",
       "      <td>Vertebral/column_2C.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Vertebral_3C</td>\n",
       "      <td>Vertebral/column_3C.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Votes_Congressional</td>\n",
       "      <td>Votes_Congressional/house-votes-84_processada.csv</td>\n",
       "      <td>Class Name</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>wine</td>\n",
       "      <td>wine/WineQT.csv</td>\n",
       "      <td>quality</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Hill</td>\n",
       "      <td>['Hill/Hill_Valley_with_noise_Training.csv', '...</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  \\\n",
       "0                         Adult   \n",
       "1                    Australian   \n",
       "2                      Banknote   \n",
       "3                        Biodeg   \n",
       "4         Breast Cancer Coimbra   \n",
       "5       Breast Cancer Wisconsin   \n",
       "6                         Churn   \n",
       "7                        Compas   \n",
       "8                Credit default   \n",
       "9                      Diabetes   \n",
       "10                          EEg   \n",
       "11                       German   \n",
       "12             GiveMeSomeCredit   \n",
       "13                        Heart   \n",
       "14                      Heart_2   \n",
       "15                        HELOC   \n",
       "16                  Horse colic   \n",
       "17                    Ionosfera   \n",
       "18                          KC2   \n",
       "19         liver disorders_bupa   \n",
       "20          mammographic_masses   \n",
       "21  Mobile Price Classification   \n",
       "22                       Monk_1   \n",
       "23                       Monk_2   \n",
       "24                       Monk_3   \n",
       "25                         Musk   \n",
       "26         OnlineNewsPopularity   \n",
       "27                     Phishing   \n",
       "28               Room Occupancy   \n",
       "29                        Sonar   \n",
       "30                     Spambase   \n",
       "31                      Student   \n",
       "32                      titanic   \n",
       "33                        Tokyo   \n",
       "34                      twonorm   \n",
       "35                 Vertebral_2C   \n",
       "36                 Vertebral_3C   \n",
       "37          Votes_Congressional   \n",
       "38                         wine   \n",
       "39                         Hill   \n",
       "\n",
       "                                                 path  \\\n",
       "0                          adult/adult_processada.csv   \n",
       "1             Australian/Credit_Card_Applications.csv   \n",
       "2                Banknote/BankNote_Authentication.csv   \n",
       "3                              Biodeg/qsar-biodeg.csv   \n",
       "4            Breast Cancer Coimbra/breast_coimbra.csv   \n",
       "5           Breast Cancer Wisconsin/breast-cancer.csv   \n",
       "6   Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...   \n",
       "7                  Compas/compas-scores-two-years.csv   \n",
       "8                  Credit default/UCI_Credit_Card.csv   \n",
       "9                               Diabetes/diabetes.csv   \n",
       "10                              EEg/EEG Eye State.csv   \n",
       "11                           German/german_credit.csv   \n",
       "12   GiveMeSomeCredit/GiveMeSomeCredit_processada.csv   \n",
       "13                                    Heart/heart.csv   \n",
       "14                                   Heart/heart2.csv   \n",
       "15                         HELOC/heloc_dataset_v1.csv   \n",
       "16                 Horse colic/horseV2_processada.csv   \n",
       "17                           Ionosfera/ionosphere.csv   \n",
       "18                                        KC2/KC2.csv   \n",
       "19                      liver disorders_bupa/bupa.csv   \n",
       "20  mammographic_masses/mammographic_masses_cleane...   \n",
       "21  Mobile Price Classification/train_mobile_proce...   \n",
       "22  ['Monk/monks-1_train.csv', 'Monk/monks-1_test....   \n",
       "23  ['Monk/monks-2_train.csv', 'Monk/monks-2_test....   \n",
       "24  ['Monk/monks-3_train.csv', 'Monk/monks-3_test....   \n",
       "25                                    Musk/clean1.csv   \n",
       "26  OnlineNewsPopularity/OnlineNewsPopularity_proc...   \n",
       "27                              Phishing/Phishing.csv   \n",
       "28                  Room Occupancy/Room Occupancy.csv   \n",
       "29                           Sonar/sonar.all-data.csv   \n",
       "30                              Spambase/Spambase.csv   \n",
       "31    Student/Students-Performance-MAT_processada.csv   \n",
       "32                     titanic/titanic_processada.csv   \n",
       "33                                    Tokyo/Tokyo.csv   \n",
       "34                                twonorm/twonorm.csv   \n",
       "35                            Vertebral/column_2C.csv   \n",
       "36                            Vertebral/column_3C.csv   \n",
       "37  Votes_Congressional/house-votes-84_processada.csv   \n",
       "38                                    wine/WineQT.csv   \n",
       "39  ['Hill/Hill_Valley_with_noise_Training.csv', '...   \n",
       "\n",
       "                        classe  \\\n",
       "0              Above/Below 50K   \n",
       "1                        Class   \n",
       "2                        class   \n",
       "3                        Class   \n",
       "4               Classification   \n",
       "5                    diagnosis   \n",
       "6                        Churn   \n",
       "7               two_year_recid   \n",
       "8   default.payment.next.month   \n",
       "9                      Outcome   \n",
       "10                    Column15   \n",
       "11                     default   \n",
       "12            SeriousDlqin2yrs   \n",
       "13                      output   \n",
       "14                         num   \n",
       "15             RiskPerformance   \n",
       "16                     surgery   \n",
       "17                      target   \n",
       "18                     defects   \n",
       "19                    selector   \n",
       "20                    Severity   \n",
       "21                       range   \n",
       "22                       Class   \n",
       "23                       Class   \n",
       "24                       Class   \n",
       "25                   Column169   \n",
       "26                       class   \n",
       "27                       Class   \n",
       "28                   Occupancy   \n",
       "29                       class   \n",
       "30                       Class   \n",
       "31                       Class   \n",
       "32                    Survived   \n",
       "33                       class   \n",
       "34                       class   \n",
       "35                       class   \n",
       "36                       class   \n",
       "37                  Class Name   \n",
       "38                     quality   \n",
       "39                       class   \n",
       "\n",
       "                                              metrica  \n",
       "0                                        memoria 18gb  \n",
       "1   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "2   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "3                                     valor da coluna  \n",
       "4   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "5   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "6   could not convert string to float: '22.833.004...  \n",
       "7   could not convert string to float: 'walter mei...  \n",
       "8                                             memoria  \n",
       "9   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "10                      list.remove(x): x not in list  \n",
       "11  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "12  could not convert string to float: '6.670.221....  \n",
       "13  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "14  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "15  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "16  could not convert string to float: '3.816.861....  \n",
       "17  Input contains NaN, infinity or a value too la...  \n",
       "18  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "19  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "20  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "21  [{'Quantidade de instâncias contrafactuais': 1...  \n",
       "22  [{'Quantidade de instâncias contrafactuais': 1...  \n",
       "23  [{'Quantidade de instâncias contrafactuais': 1...  \n",
       "24  [{'Quantidade de instâncias contrafactuais': 1...  \n",
       "25                      list.remove(x): x not in list  \n",
       "26  could not convert string to float: '457.260.92...  \n",
       "27  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "28  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "29  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "30  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "31  Input contains NaN, infinity or a value too la...  \n",
       "32  Input contains NaN, infinity or a value too la...  \n",
       "33  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "34  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "35  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "36                                                NaN  \n",
       "37  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "38                                                NaN  \n",
       "39                                                NaN  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ac64a66d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>classe</th>\n",
       "      <th>metrica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult</td>\n",
       "      <td>adult/adult_processada.csv</td>\n",
       "      <td>Above/Below 50K</td>\n",
       "      <td>memoria 18gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australian</td>\n",
       "      <td>Australian/Credit_Card_Applications.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Banknote</td>\n",
       "      <td>Banknote/BankNote_Authentication.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biodeg</td>\n",
       "      <td>Biodeg/qsar-biodeg.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>valor da coluna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Coimbra</td>\n",
       "      <td>Breast Cancer Coimbra/breast_coimbra.csv</td>\n",
       "      <td>Classification</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Breast Cancer Wisconsin</td>\n",
       "      <td>Breast Cancer Wisconsin/breast-cancer.csv</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Churn</td>\n",
       "      <td>Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...</td>\n",
       "      <td>Churn</td>\n",
       "      <td>could not convert string to float: '22.833.004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Compas</td>\n",
       "      <td>Compas/compas-scores-two-years.csv</td>\n",
       "      <td>two_year_recid</td>\n",
       "      <td>could not convert string to float: 'walter mei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit default</td>\n",
       "      <td>Credit default/UCI_Credit_Card.csv</td>\n",
       "      <td>default.payment.next.month</td>\n",
       "      <td>memoria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Diabetes/diabetes.csv</td>\n",
       "      <td>Outcome</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EEg</td>\n",
       "      <td>EEg/EEG Eye State.csv</td>\n",
       "      <td>Column15</td>\n",
       "      <td>list.remove(x): x not in list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>German</td>\n",
       "      <td>German/german_credit.csv</td>\n",
       "      <td>default</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GiveMeSomeCredit</td>\n",
       "      <td>GiveMeSomeCredit/GiveMeSomeCredit_processada.csv</td>\n",
       "      <td>SeriousDlqin2yrs</td>\n",
       "      <td>could not convert string to float: '6.670.221....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Heart</td>\n",
       "      <td>Heart/heart.csv</td>\n",
       "      <td>output</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Heart_2</td>\n",
       "      <td>Heart/heart2.csv</td>\n",
       "      <td>num</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HELOC</td>\n",
       "      <td>HELOC/heloc_dataset_v1.csv</td>\n",
       "      <td>RiskPerformance</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Horse colic</td>\n",
       "      <td>Horse colic/horseV2_processada.csv</td>\n",
       "      <td>surgery</td>\n",
       "      <td>could not convert string to float: '3.816.861....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ionosfera</td>\n",
       "      <td>Ionosfera/ionosphere.csv</td>\n",
       "      <td>target</td>\n",
       "      <td>Input contains NaN, infinity or a value too la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KC2</td>\n",
       "      <td>KC2/KC2.csv</td>\n",
       "      <td>defects</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>liver disorders_bupa</td>\n",
       "      <td>liver disorders_bupa/bupa.csv</td>\n",
       "      <td>selector</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mammographic_masses</td>\n",
       "      <td>mammographic_masses/mammographic_masses_cleane...</td>\n",
       "      <td>Severity</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mobile Price Classification</td>\n",
       "      <td>Mobile Price Classification/train_mobile_proce...</td>\n",
       "      <td>range</td>\n",
       "      <td>[{'Quantidade de instâncias contrafactuais': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Monk_1</td>\n",
       "      <td>['Monk/monks-1_train.csv', 'Monk/monks-1_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>[{'Quantidade de instâncias contrafactuais': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Monk_2</td>\n",
       "      <td>['Monk/monks-2_train.csv', 'Monk/monks-2_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>[{'Quantidade de instâncias contrafactuais': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Monk_3</td>\n",
       "      <td>['Monk/monks-3_train.csv', 'Monk/monks-3_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>[{'Quantidade de instâncias contrafactuais': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Musk</td>\n",
       "      <td>Musk/clean1.csv</td>\n",
       "      <td>Column167</td>\n",
       "      <td>list.remove(x): x not in list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>OnlineNewsPopularity</td>\n",
       "      <td>OnlineNewsPopularity/OnlineNewsPopularity_proc...</td>\n",
       "      <td>class</td>\n",
       "      <td>could not convert string to float: '457.260.92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Phishing</td>\n",
       "      <td>Phishing/Phishing.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Room Occupancy</td>\n",
       "      <td>Room Occupancy/Room Occupancy.csv</td>\n",
       "      <td>Occupancy</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sonar</td>\n",
       "      <td>Sonar/sonar.all-data.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Spambase</td>\n",
       "      <td>Spambase/Spambase.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Student</td>\n",
       "      <td>Student/Students-Performance-MAT_processada.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>Input contains NaN, infinity or a value too la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>titanic</td>\n",
       "      <td>titanic/titanic_processada.csv</td>\n",
       "      <td>Survived</td>\n",
       "      <td>Input contains NaN, infinity or a value too la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo/Tokyo.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>twonorm</td>\n",
       "      <td>twonorm/twonorm.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Vertebral_2C</td>\n",
       "      <td>Vertebral/column_2C.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Vertebral_3C</td>\n",
       "      <td>Vertebral/column_3C.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Votes_Congressional</td>\n",
       "      <td>Votes_Congressional/house-votes-84_processada.csv</td>\n",
       "      <td>Class Name</td>\n",
       "      <td>{'Quantidade de instâncias contrafactuais': 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>wine</td>\n",
       "      <td>wine/WineQT.csv</td>\n",
       "      <td>quality</td>\n",
       "      <td>demorou demais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Hill</td>\n",
       "      <td>['Hill/Hill_Valley_with_noise_Training.csv', '...</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  \\\n",
       "0                         Adult   \n",
       "1                    Australian   \n",
       "2                      Banknote   \n",
       "3                        Biodeg   \n",
       "4         Breast Cancer Coimbra   \n",
       "5       Breast Cancer Wisconsin   \n",
       "6                         Churn   \n",
       "7                        Compas   \n",
       "8                Credit default   \n",
       "9                      Diabetes   \n",
       "10                          EEg   \n",
       "11                       German   \n",
       "12             GiveMeSomeCredit   \n",
       "13                        Heart   \n",
       "14                      Heart_2   \n",
       "15                        HELOC   \n",
       "16                  Horse colic   \n",
       "17                    Ionosfera   \n",
       "18                          KC2   \n",
       "19         liver disorders_bupa   \n",
       "20          mammographic_masses   \n",
       "21  Mobile Price Classification   \n",
       "22                       Monk_1   \n",
       "23                       Monk_2   \n",
       "24                       Monk_3   \n",
       "25                         Musk   \n",
       "26         OnlineNewsPopularity   \n",
       "27                     Phishing   \n",
       "28               Room Occupancy   \n",
       "29                        Sonar   \n",
       "30                     Spambase   \n",
       "31                      Student   \n",
       "32                      titanic   \n",
       "33                        Tokyo   \n",
       "34                      twonorm   \n",
       "35                 Vertebral_2C   \n",
       "36                 Vertebral_3C   \n",
       "37          Votes_Congressional   \n",
       "38                         wine   \n",
       "39                         Hill   \n",
       "\n",
       "                                                 path  \\\n",
       "0                          adult/adult_processada.csv   \n",
       "1             Australian/Credit_Card_Applications.csv   \n",
       "2                Banknote/BankNote_Authentication.csv   \n",
       "3                              Biodeg/qsar-biodeg.csv   \n",
       "4            Breast Cancer Coimbra/breast_coimbra.csv   \n",
       "5           Breast Cancer Wisconsin/breast-cancer.csv   \n",
       "6   Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...   \n",
       "7                  Compas/compas-scores-two-years.csv   \n",
       "8                  Credit default/UCI_Credit_Card.csv   \n",
       "9                               Diabetes/diabetes.csv   \n",
       "10                              EEg/EEG Eye State.csv   \n",
       "11                           German/german_credit.csv   \n",
       "12   GiveMeSomeCredit/GiveMeSomeCredit_processada.csv   \n",
       "13                                    Heart/heart.csv   \n",
       "14                                   Heart/heart2.csv   \n",
       "15                         HELOC/heloc_dataset_v1.csv   \n",
       "16                 Horse colic/horseV2_processada.csv   \n",
       "17                           Ionosfera/ionosphere.csv   \n",
       "18                                        KC2/KC2.csv   \n",
       "19                      liver disorders_bupa/bupa.csv   \n",
       "20  mammographic_masses/mammographic_masses_cleane...   \n",
       "21  Mobile Price Classification/train_mobile_proce...   \n",
       "22  ['Monk/monks-1_train.csv', 'Monk/monks-1_test....   \n",
       "23  ['Monk/monks-2_train.csv', 'Monk/monks-2_test....   \n",
       "24  ['Monk/monks-3_train.csv', 'Monk/monks-3_test....   \n",
       "25                                    Musk/clean1.csv   \n",
       "26  OnlineNewsPopularity/OnlineNewsPopularity_proc...   \n",
       "27                              Phishing/Phishing.csv   \n",
       "28                  Room Occupancy/Room Occupancy.csv   \n",
       "29                           Sonar/sonar.all-data.csv   \n",
       "30                              Spambase/Spambase.csv   \n",
       "31    Student/Students-Performance-MAT_processada.csv   \n",
       "32                     titanic/titanic_processada.csv   \n",
       "33                                    Tokyo/Tokyo.csv   \n",
       "34                                twonorm/twonorm.csv   \n",
       "35                            Vertebral/column_2C.csv   \n",
       "36                            Vertebral/column_3C.csv   \n",
       "37  Votes_Congressional/house-votes-84_processada.csv   \n",
       "38                                    wine/WineQT.csv   \n",
       "39  ['Hill/Hill_Valley_with_noise_Training.csv', '...   \n",
       "\n",
       "                        classe  \\\n",
       "0              Above/Below 50K   \n",
       "1                        Class   \n",
       "2                        class   \n",
       "3                        Class   \n",
       "4               Classification   \n",
       "5                    diagnosis   \n",
       "6                        Churn   \n",
       "7               two_year_recid   \n",
       "8   default.payment.next.month   \n",
       "9                      Outcome   \n",
       "10                    Column15   \n",
       "11                     default   \n",
       "12            SeriousDlqin2yrs   \n",
       "13                      output   \n",
       "14                         num   \n",
       "15             RiskPerformance   \n",
       "16                     surgery   \n",
       "17                      target   \n",
       "18                     defects   \n",
       "19                    selector   \n",
       "20                    Severity   \n",
       "21                       range   \n",
       "22                       Class   \n",
       "23                       Class   \n",
       "24                       Class   \n",
       "25                   Column167   \n",
       "26                       class   \n",
       "27                       Class   \n",
       "28                   Occupancy   \n",
       "29                       class   \n",
       "30                       Class   \n",
       "31                       Class   \n",
       "32                    Survived   \n",
       "33                       class   \n",
       "34                       class   \n",
       "35                       class   \n",
       "36                       class   \n",
       "37                  Class Name   \n",
       "38                     quality   \n",
       "39                       class   \n",
       "\n",
       "                                              metrica  \n",
       "0                                        memoria 18gb  \n",
       "1   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "2   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "3                                     valor da coluna  \n",
       "4   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "5   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "6   could not convert string to float: '22.833.004...  \n",
       "7   could not convert string to float: 'walter mei...  \n",
       "8                                             memoria  \n",
       "9   {'Quantidade de instâncias contrafactuais': 11...  \n",
       "10                      list.remove(x): x not in list  \n",
       "11  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "12  could not convert string to float: '6.670.221....  \n",
       "13  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "14  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "15  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "16  could not convert string to float: '3.816.861....  \n",
       "17  Input contains NaN, infinity or a value too la...  \n",
       "18  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "19  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "20  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "21  [{'Quantidade de instâncias contrafactuais': 1...  \n",
       "22  [{'Quantidade de instâncias contrafactuais': 1...  \n",
       "23  [{'Quantidade de instâncias contrafactuais': 1...  \n",
       "24  [{'Quantidade de instâncias contrafactuais': 1...  \n",
       "25                      list.remove(x): x not in list  \n",
       "26  could not convert string to float: '457.260.92...  \n",
       "27  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "28  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "29  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "30  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "31  Input contains NaN, infinity or a value too la...  \n",
       "32  Input contains NaN, infinity or a value too la...  \n",
       "33  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "34  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "35  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "36                                                NaN  \n",
       "37  {'Quantidade de instâncias contrafactuais': 11...  \n",
       "38                                     demorou demais  \n",
       "39                                                NaN  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm_use.loc[25, 'classe'] = \"Column167\"\n",
    "dfm_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5332db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm_use.loc[10, 'metrica'] = json.dumps({'Quantidade de instâncias contrafactuais': 110,\n",
    " 'Quantidade de relações causais na base de dados': 84,\n",
    " 'Quantidade de atributos modificados': 0,\n",
    " 'Quantidade de instâncias contrafactuais causais': 0,\n",
    " 'Quantidade de relações causais analisadas': 0,\n",
    " 'Quantidade de relações causais satisfeitas': 0,\n",
    " 'Quantidade de instâncias contrafactuais com um único atributo modificado': 0,\n",
    " 'Tempo de execução': 5.401427745819092})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d9f57a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfm_use' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdfm_use\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfm_use' is not defined"
     ]
    }
   ],
   "source": [
    "dfm_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6a8716a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfm_use.to_parquet(f\"s3://omar-testes-gerais/artigos/artifacts/dfm_use.parquet\", engine = 'pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69ebc06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7524c66c",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6732931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "    \"memoria\": [\"Adult\", \"Credit default\", 'wine', 'Vertebral_3C'],\n",
    "    'falta': ['EEg', \"Hill\", \"Mobile Price Classification\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45698a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "b3ef12ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>classe</th>\n",
       "      <th>metrica</th>\n",
       "      <th>metrica_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult</td>\n",
       "      <td>adult/adult_processada.csv</td>\n",
       "      <td>Above/Below 50K</td>\n",
       "      <td>memoria 18gb</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australian</td>\n",
       "      <td>Australian/Credit_Card_Applications.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Banknote</td>\n",
       "      <td>Banknote/BankNote_Authentication.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biodeg</td>\n",
       "      <td>Biodeg/qsar-biodeg.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\\n    \"Quantidade de instâncias contrafactuai...</td>\n",
       "      <td>zero metricas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Coimbra</td>\n",
       "      <td>Breast Cancer Coimbra/breast_coimbra.csv</td>\n",
       "      <td>Classification</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Breast Cancer Wisconsin</td>\n",
       "      <td>Breast Cancer Wisconsin/breast-cancer.csv</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Churn</td>\n",
       "      <td>Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...</td>\n",
       "      <td>Churn</td>\n",
       "      <td>Input contains NaN, infinity or a value too la...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Compas</td>\n",
       "      <td>Compas/compas-scores-two-years.csv</td>\n",
       "      <td>two_year_recid</td>\n",
       "      <td>base de dados nao processada</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit default</td>\n",
       "      <td>Credit default/UCI_Credit_Card.csv</td>\n",
       "      <td>default.payment.next.month</td>\n",
       "      <td>memoria</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Diabetes/diabetes.csv</td>\n",
       "      <td>Outcome</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EEg</td>\n",
       "      <td>EEg/EEG Eye State.csv</td>\n",
       "      <td>Column15</td>\n",
       "      <td>memoria</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>German</td>\n",
       "      <td>German/german_credit.csv</td>\n",
       "      <td>default</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GiveMeSomeCredit</td>\n",
       "      <td>GiveMeSomeCredit/GiveMeSomeCredit_processada.csv</td>\n",
       "      <td>SeriousDlqin2yrs</td>\n",
       "      <td>memoria</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Heart</td>\n",
       "      <td>Heart/heart.csv</td>\n",
       "      <td>output</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Heart_2</td>\n",
       "      <td>Heart/heart2.csv</td>\n",
       "      <td>num</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HELOC</td>\n",
       "      <td>HELOC/heloc_dataset_v1.csv</td>\n",
       "      <td>RiskPerformance</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Horse colic</td>\n",
       "      <td>Horse colic/horseV2_processada.csv</td>\n",
       "      <td>surgery</td>\n",
       "      <td>array must not contain infs or NaNs</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ionosfera</td>\n",
       "      <td>Ionosfera/ionosphere.csv</td>\n",
       "      <td>target</td>\n",
       "      <td>array must not contain infs or NaNs</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KC2</td>\n",
       "      <td>KC2/KC2.csv</td>\n",
       "      <td>defects</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>liver disorders_bupa</td>\n",
       "      <td>liver disorders_bupa/bupa.csv</td>\n",
       "      <td>selector</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mammographic_masses</td>\n",
       "      <td>mammographic_masses/mammographic_masses_cleane...</td>\n",
       "      <td>Severity</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mobile Price Classification</td>\n",
       "      <td>Mobile Price Classification/train_mobile_proce...</td>\n",
       "      <td>range</td>\n",
       "      <td>{\\n    \"Quantidade de instâncias contrafactuai...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Monk_1</td>\n",
       "      <td>['Monk/monks-1_train.csv', 'Monk/monks-1_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Monk_2</td>\n",
       "      <td>['Monk/monks-2_train.csv', 'Monk/monks-2_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Monk_3</td>\n",
       "      <td>['Monk/monks-3_train.csv', 'Monk/monks-3_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Musk</td>\n",
       "      <td>Musk/clean1.csv</td>\n",
       "      <td>Column165</td>\n",
       "      <td>fica dando erro de coluna</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>OnlineNewsPopularity</td>\n",
       "      <td>OnlineNewsPopularity/OnlineNewsPopularity_proc...</td>\n",
       "      <td>class</td>\n",
       "      <td>memoria</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Phishing</td>\n",
       "      <td>Phishing/Phishing.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Room Occupancy</td>\n",
       "      <td>Room Occupancy/Room Occupancy.csv</td>\n",
       "      <td>Occupancy</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sonar</td>\n",
       "      <td>Sonar/sonar.all-data.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Spambase</td>\n",
       "      <td>Spambase/Spambase.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Student</td>\n",
       "      <td>Student/Students-Performance-MAT_processada.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>array must not contain infs or NaNs</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>titanic</td>\n",
       "      <td>titanic/titanic_processada.csv</td>\n",
       "      <td>Survived</td>\n",
       "      <td>Input contains NaN, infinity or a value too la...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo/Tokyo.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>twonorm</td>\n",
       "      <td>twonorm/twonorm.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Vertebral_2C</td>\n",
       "      <td>Vertebral/column_2C.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Vertebral_3C</td>\n",
       "      <td>Vertebral/column_3C.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Votes_Congressional</td>\n",
       "      <td>Votes_Congressional/house-votes-84_processada.csv</td>\n",
       "      <td>Class Name</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>wine</td>\n",
       "      <td>wine/WineQT.csv</td>\n",
       "      <td>quality</td>\n",
       "      <td>demorou demais</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Hill</td>\n",
       "      <td>['Hill/Hill_Valley_with_noise_Training.csv', '...</td>\n",
       "      <td>class</td>\n",
       "      <td>{\\n    \"Quantidade de instâncias contrafactuai...</td>\n",
       "      <td>zero metricas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  \\\n",
       "0                         Adult   \n",
       "1                    Australian   \n",
       "2                      Banknote   \n",
       "3                        Biodeg   \n",
       "4         Breast Cancer Coimbra   \n",
       "5       Breast Cancer Wisconsin   \n",
       "6                         Churn   \n",
       "7                        Compas   \n",
       "8                Credit default   \n",
       "9                      Diabetes   \n",
       "10                          EEg   \n",
       "11                       German   \n",
       "12             GiveMeSomeCredit   \n",
       "13                        Heart   \n",
       "14                      Heart_2   \n",
       "15                        HELOC   \n",
       "16                  Horse colic   \n",
       "17                    Ionosfera   \n",
       "18                          KC2   \n",
       "19         liver disorders_bupa   \n",
       "20          mammographic_masses   \n",
       "21  Mobile Price Classification   \n",
       "22                       Monk_1   \n",
       "23                       Monk_2   \n",
       "24                       Monk_3   \n",
       "25                         Musk   \n",
       "26         OnlineNewsPopularity   \n",
       "27                     Phishing   \n",
       "28               Room Occupancy   \n",
       "29                        Sonar   \n",
       "30                     Spambase   \n",
       "31                      Student   \n",
       "32                      titanic   \n",
       "33                        Tokyo   \n",
       "34                      twonorm   \n",
       "35                 Vertebral_2C   \n",
       "36                 Vertebral_3C   \n",
       "37          Votes_Congressional   \n",
       "38                         wine   \n",
       "39                         Hill   \n",
       "\n",
       "                                                 path  \\\n",
       "0                          adult/adult_processada.csv   \n",
       "1             Australian/Credit_Card_Applications.csv   \n",
       "2                Banknote/BankNote_Authentication.csv   \n",
       "3                              Biodeg/qsar-biodeg.csv   \n",
       "4            Breast Cancer Coimbra/breast_coimbra.csv   \n",
       "5           Breast Cancer Wisconsin/breast-cancer.csv   \n",
       "6   Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...   \n",
       "7                  Compas/compas-scores-two-years.csv   \n",
       "8                  Credit default/UCI_Credit_Card.csv   \n",
       "9                               Diabetes/diabetes.csv   \n",
       "10                              EEg/EEG Eye State.csv   \n",
       "11                           German/german_credit.csv   \n",
       "12   GiveMeSomeCredit/GiveMeSomeCredit_processada.csv   \n",
       "13                                    Heart/heart.csv   \n",
       "14                                   Heart/heart2.csv   \n",
       "15                         HELOC/heloc_dataset_v1.csv   \n",
       "16                 Horse colic/horseV2_processada.csv   \n",
       "17                           Ionosfera/ionosphere.csv   \n",
       "18                                        KC2/KC2.csv   \n",
       "19                      liver disorders_bupa/bupa.csv   \n",
       "20  mammographic_masses/mammographic_masses_cleane...   \n",
       "21  Mobile Price Classification/train_mobile_proce...   \n",
       "22  ['Monk/monks-1_train.csv', 'Monk/monks-1_test....   \n",
       "23  ['Monk/monks-2_train.csv', 'Monk/monks-2_test....   \n",
       "24  ['Monk/monks-3_train.csv', 'Monk/monks-3_test....   \n",
       "25                                    Musk/clean1.csv   \n",
       "26  OnlineNewsPopularity/OnlineNewsPopularity_proc...   \n",
       "27                              Phishing/Phishing.csv   \n",
       "28                  Room Occupancy/Room Occupancy.csv   \n",
       "29                           Sonar/sonar.all-data.csv   \n",
       "30                              Spambase/Spambase.csv   \n",
       "31    Student/Students-Performance-MAT_processada.csv   \n",
       "32                     titanic/titanic_processada.csv   \n",
       "33                                    Tokyo/Tokyo.csv   \n",
       "34                                twonorm/twonorm.csv   \n",
       "35                            Vertebral/column_2C.csv   \n",
       "36                            Vertebral/column_3C.csv   \n",
       "37  Votes_Congressional/house-votes-84_processada.csv   \n",
       "38                                    wine/WineQT.csv   \n",
       "39  ['Hill/Hill_Valley_with_noise_Training.csv', '...   \n",
       "\n",
       "                        classe  \\\n",
       "0              Above/Below 50K   \n",
       "1                        Class   \n",
       "2                        class   \n",
       "3                        Class   \n",
       "4               Classification   \n",
       "5                    diagnosis   \n",
       "6                        Churn   \n",
       "7               two_year_recid   \n",
       "8   default.payment.next.month   \n",
       "9                      Outcome   \n",
       "10                    Column15   \n",
       "11                     default   \n",
       "12            SeriousDlqin2yrs   \n",
       "13                      output   \n",
       "14                         num   \n",
       "15             RiskPerformance   \n",
       "16                     surgery   \n",
       "17                      target   \n",
       "18                     defects   \n",
       "19                    selector   \n",
       "20                    Severity   \n",
       "21                       range   \n",
       "22                       Class   \n",
       "23                       Class   \n",
       "24                       Class   \n",
       "25                   Column165   \n",
       "26                       class   \n",
       "27                       Class   \n",
       "28                   Occupancy   \n",
       "29                       class   \n",
       "30                       Class   \n",
       "31                       Class   \n",
       "32                    Survived   \n",
       "33                       class   \n",
       "34                       class   \n",
       "35                       class   \n",
       "36                       class   \n",
       "37                  Class Name   \n",
       "38                     quality   \n",
       "39                       class   \n",
       "\n",
       "                                              metrica     metrica_v2  \n",
       "0                                        memoria 18gb           None  \n",
       "1   {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "2   {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "3   {\\n    \"Quantidade de instâncias contrafactuai...  zero metricas  \n",
       "4   {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "5   {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "6   Input contains NaN, infinity or a value too la...           None  \n",
       "7                        base de dados nao processada           None  \n",
       "8                                             memoria           None  \n",
       "9   {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "10                                            memoria           None  \n",
       "11  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "12                                            memoria           None  \n",
       "13  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "14  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "15  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "16                array must not contain infs or NaNs           None  \n",
       "17                array must not contain infs or NaNs           None  \n",
       "18  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "19  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "20  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "21  {\\n    \"Quantidade de instâncias contrafactuai...           None  \n",
       "22  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "23  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "24  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "25                          fica dando erro de coluna           None  \n",
       "26                                            memoria           None  \n",
       "27  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "28  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "29  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "30  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "31                array must not contain infs or NaNs           None  \n",
       "32  Input contains NaN, infinity or a value too la...           None  \n",
       "33  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "34  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "35  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "36                                                 {}           None  \n",
       "37  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "38                                     demorou demais           None  \n",
       "39  {\\n    \"Quantidade de instâncias contrafactuai...  zero metricas  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfz = pd.read_parquet(f\"s3://omar-testes-gerais/artigos/artifacts/dfm_use.parquet\")\n",
    "dfz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "81428d85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>classe</th>\n",
       "      <th>metrica</th>\n",
       "      <th>metrica_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult</td>\n",
       "      <td>adult/adult_processada.csv</td>\n",
       "      <td>Above/Below 50K</td>\n",
       "      <td>memoria 18gb</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australian</td>\n",
       "      <td>Australian/Credit_Card_Applications.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Banknote</td>\n",
       "      <td>Banknote/BankNote_Authentication.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biodeg</td>\n",
       "      <td>Biodeg/qsar-biodeg.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\\n    \"Quantidade de instâncias contrafactuai...</td>\n",
       "      <td>zero metricas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Coimbra</td>\n",
       "      <td>Breast Cancer Coimbra/breast_coimbra.csv</td>\n",
       "      <td>Classification</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Breast Cancer Wisconsin</td>\n",
       "      <td>Breast Cancer Wisconsin/breast-cancer.csv</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Churn</td>\n",
       "      <td>Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...</td>\n",
       "      <td>Churn</td>\n",
       "      <td>Input contains NaN, infinity or a value too la...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Compas</td>\n",
       "      <td>Compas/compas-scores-two-years.csv</td>\n",
       "      <td>two_year_recid</td>\n",
       "      <td>base de dados nao processada</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit default</td>\n",
       "      <td>Credit default/UCI_Credit_Card.csv</td>\n",
       "      <td>default.payment.next.month</td>\n",
       "      <td>memoria</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Diabetes/diabetes.csv</td>\n",
       "      <td>Outcome</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EEg</td>\n",
       "      <td>EEg/EEG Eye State.csv</td>\n",
       "      <td>Column15</td>\n",
       "      <td>memoria</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>German</td>\n",
       "      <td>German/german_credit.csv</td>\n",
       "      <td>default</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GiveMeSomeCredit</td>\n",
       "      <td>GiveMeSomeCredit/GiveMeSomeCredit_processada.csv</td>\n",
       "      <td>SeriousDlqin2yrs</td>\n",
       "      <td>memoria</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Heart</td>\n",
       "      <td>Heart/heart.csv</td>\n",
       "      <td>output</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Heart_2</td>\n",
       "      <td>Heart/heart2.csv</td>\n",
       "      <td>num</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HELOC</td>\n",
       "      <td>HELOC/heloc_dataset_v1.csv</td>\n",
       "      <td>RiskPerformance</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Horse colic</td>\n",
       "      <td>Horse colic/horseV2_processada.csv</td>\n",
       "      <td>surgery</td>\n",
       "      <td>array must not contain infs or NaNs</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ionosfera</td>\n",
       "      <td>Ionosfera/ionosphere.csv</td>\n",
       "      <td>target</td>\n",
       "      <td>array must not contain infs or NaNs</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KC2</td>\n",
       "      <td>KC2/KC2.csv</td>\n",
       "      <td>defects</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>liver disorders_bupa</td>\n",
       "      <td>liver disorders_bupa/bupa.csv</td>\n",
       "      <td>selector</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mammographic_masses</td>\n",
       "      <td>mammographic_masses/mammographic_masses_cleane...</td>\n",
       "      <td>Severity</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mobile Price Classification</td>\n",
       "      <td>Mobile Price Classification/train_mobile_proce...</td>\n",
       "      <td>range</td>\n",
       "      <td>{\\n    \"Quantidade de instâncias contrafactuai...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Monk_1</td>\n",
       "      <td>['Monk/monks-1_train.csv', 'Monk/monks-1_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Monk_2</td>\n",
       "      <td>['Monk/monks-2_train.csv', 'Monk/monks-2_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Monk_3</td>\n",
       "      <td>['Monk/monks-3_train.csv', 'Monk/monks-3_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Musk</td>\n",
       "      <td>Musk/clean1.csv</td>\n",
       "      <td>Column165</td>\n",
       "      <td>fica dando erro de coluna</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>OnlineNewsPopularity</td>\n",
       "      <td>OnlineNewsPopularity/OnlineNewsPopularity_proc...</td>\n",
       "      <td>class</td>\n",
       "      <td>memoria</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Phishing</td>\n",
       "      <td>Phishing/Phishing.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Room Occupancy</td>\n",
       "      <td>Room Occupancy/Room Occupancy.csv</td>\n",
       "      <td>Occupancy</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sonar</td>\n",
       "      <td>Sonar/sonar.all-data.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Spambase</td>\n",
       "      <td>Spambase/Spambase.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Student</td>\n",
       "      <td>Student/Students-Performance-MAT_processada.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>array must not contain infs or NaNs</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>titanic</td>\n",
       "      <td>titanic/titanic_processada.csv</td>\n",
       "      <td>Survived</td>\n",
       "      <td>Input contains NaN, infinity or a value too la...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo/Tokyo.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>twonorm</td>\n",
       "      <td>twonorm/twonorm.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Vertebral_2C</td>\n",
       "      <td>Vertebral/column_2C.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Vertebral_3C</td>\n",
       "      <td>Vertebral/column_3C.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Votes_Congressional</td>\n",
       "      <td>Votes_Congressional/house-votes-84_processada.csv</td>\n",
       "      <td>Class Name</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>wine</td>\n",
       "      <td>wine/WineQT.csv</td>\n",
       "      <td>quality</td>\n",
       "      <td>demorou demais</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Hill</td>\n",
       "      <td>['Hill/Hill_Valley_with_noise_Training.csv', '...</td>\n",
       "      <td>class</td>\n",
       "      <td>{\\n    \"Quantidade de instâncias contrafactuai...</td>\n",
       "      <td>zero metricas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  \\\n",
       "0                         Adult   \n",
       "1                    Australian   \n",
       "2                      Banknote   \n",
       "3                        Biodeg   \n",
       "4         Breast Cancer Coimbra   \n",
       "5       Breast Cancer Wisconsin   \n",
       "6                         Churn   \n",
       "7                        Compas   \n",
       "8                Credit default   \n",
       "9                      Diabetes   \n",
       "10                          EEg   \n",
       "11                       German   \n",
       "12             GiveMeSomeCredit   \n",
       "13                        Heart   \n",
       "14                      Heart_2   \n",
       "15                        HELOC   \n",
       "16                  Horse colic   \n",
       "17                    Ionosfera   \n",
       "18                          KC2   \n",
       "19         liver disorders_bupa   \n",
       "20          mammographic_masses   \n",
       "21  Mobile Price Classification   \n",
       "22                       Monk_1   \n",
       "23                       Monk_2   \n",
       "24                       Monk_3   \n",
       "25                         Musk   \n",
       "26         OnlineNewsPopularity   \n",
       "27                     Phishing   \n",
       "28               Room Occupancy   \n",
       "29                        Sonar   \n",
       "30                     Spambase   \n",
       "31                      Student   \n",
       "32                      titanic   \n",
       "33                        Tokyo   \n",
       "34                      twonorm   \n",
       "35                 Vertebral_2C   \n",
       "36                 Vertebral_3C   \n",
       "37          Votes_Congressional   \n",
       "38                         wine   \n",
       "39                         Hill   \n",
       "\n",
       "                                                 path  \\\n",
       "0                          adult/adult_processada.csv   \n",
       "1             Australian/Credit_Card_Applications.csv   \n",
       "2                Banknote/BankNote_Authentication.csv   \n",
       "3                              Biodeg/qsar-biodeg.csv   \n",
       "4            Breast Cancer Coimbra/breast_coimbra.csv   \n",
       "5           Breast Cancer Wisconsin/breast-cancer.csv   \n",
       "6   Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...   \n",
       "7                  Compas/compas-scores-two-years.csv   \n",
       "8                  Credit default/UCI_Credit_Card.csv   \n",
       "9                               Diabetes/diabetes.csv   \n",
       "10                              EEg/EEG Eye State.csv   \n",
       "11                           German/german_credit.csv   \n",
       "12   GiveMeSomeCredit/GiveMeSomeCredit_processada.csv   \n",
       "13                                    Heart/heart.csv   \n",
       "14                                   Heart/heart2.csv   \n",
       "15                         HELOC/heloc_dataset_v1.csv   \n",
       "16                 Horse colic/horseV2_processada.csv   \n",
       "17                           Ionosfera/ionosphere.csv   \n",
       "18                                        KC2/KC2.csv   \n",
       "19                      liver disorders_bupa/bupa.csv   \n",
       "20  mammographic_masses/mammographic_masses_cleane...   \n",
       "21  Mobile Price Classification/train_mobile_proce...   \n",
       "22  ['Monk/monks-1_train.csv', 'Monk/monks-1_test....   \n",
       "23  ['Monk/monks-2_train.csv', 'Monk/monks-2_test....   \n",
       "24  ['Monk/monks-3_train.csv', 'Monk/monks-3_test....   \n",
       "25                                    Musk/clean1.csv   \n",
       "26  OnlineNewsPopularity/OnlineNewsPopularity_proc...   \n",
       "27                              Phishing/Phishing.csv   \n",
       "28                  Room Occupancy/Room Occupancy.csv   \n",
       "29                           Sonar/sonar.all-data.csv   \n",
       "30                              Spambase/Spambase.csv   \n",
       "31    Student/Students-Performance-MAT_processada.csv   \n",
       "32                     titanic/titanic_processada.csv   \n",
       "33                                    Tokyo/Tokyo.csv   \n",
       "34                                twonorm/twonorm.csv   \n",
       "35                            Vertebral/column_2C.csv   \n",
       "36                            Vertebral/column_3C.csv   \n",
       "37  Votes_Congressional/house-votes-84_processada.csv   \n",
       "38                                    wine/WineQT.csv   \n",
       "39  ['Hill/Hill_Valley_with_noise_Training.csv', '...   \n",
       "\n",
       "                        classe  \\\n",
       "0              Above/Below 50K   \n",
       "1                        Class   \n",
       "2                        class   \n",
       "3                        Class   \n",
       "4               Classification   \n",
       "5                    diagnosis   \n",
       "6                        Churn   \n",
       "7               two_year_recid   \n",
       "8   default.payment.next.month   \n",
       "9                      Outcome   \n",
       "10                    Column15   \n",
       "11                     default   \n",
       "12            SeriousDlqin2yrs   \n",
       "13                      output   \n",
       "14                         num   \n",
       "15             RiskPerformance   \n",
       "16                     surgery   \n",
       "17                      target   \n",
       "18                     defects   \n",
       "19                    selector   \n",
       "20                    Severity   \n",
       "21                       range   \n",
       "22                       Class   \n",
       "23                       Class   \n",
       "24                       Class   \n",
       "25                   Column165   \n",
       "26                       class   \n",
       "27                       Class   \n",
       "28                   Occupancy   \n",
       "29                       class   \n",
       "30                       Class   \n",
       "31                       Class   \n",
       "32                    Survived   \n",
       "33                       class   \n",
       "34                       class   \n",
       "35                       class   \n",
       "36                       class   \n",
       "37                  Class Name   \n",
       "38                     quality   \n",
       "39                       class   \n",
       "\n",
       "                                              metrica     metrica_v2  \n",
       "0                                        memoria 18gb           None  \n",
       "1   {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "2   {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "3   {\\n    \"Quantidade de instâncias contrafactuai...  zero metricas  \n",
       "4   {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "5   {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "6   Input contains NaN, infinity or a value too la...           None  \n",
       "7                        base de dados nao processada           None  \n",
       "8                                             memoria           None  \n",
       "9   {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "10                                            memoria           None  \n",
       "11  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "12                                            memoria           None  \n",
       "13  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "14  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "15  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "16                array must not contain infs or NaNs           None  \n",
       "17                array must not contain infs or NaNs           None  \n",
       "18  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "19  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "20  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "21  {\\n    \"Quantidade de instâncias contrafactuai...           None  \n",
       "22  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "23  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "24  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "25                          fica dando erro de coluna           None  \n",
       "26                                            memoria           None  \n",
       "27  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "28  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "29  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "30  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "31                array must not contain infs or NaNs           None  \n",
       "32  Input contains NaN, infinity or a value too la...           None  \n",
       "33  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "34  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "35  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "36                                                 {}           None  \n",
       "37  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "38                                     demorou demais           None  \n",
       "39  {\\n    \"Quantidade de instâncias contrafactuai...  zero metricas  "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfz.loc[10, 'metrica_v2'] = None\n",
    "dfz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "fdba8645",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz.to_parquet(f\"s3://omar-testes-gerais/artigos/artifacts/dfm_use.parquet\", engine = 'pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "0a2a746c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'list.remove(x): x not in list'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_use_index = 25\n",
    "dfz.iloc[df_use_index]['metrica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "0421d0a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>-170</td>\n",
       "      <td>-45</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-302</td>\n",
       "      <td>60</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>31</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>-161</td>\n",
       "      <td>-45</td>\n",
       "      <td>-28</td>\n",
       "      <td>...</td>\n",
       "      <td>-73</td>\n",
       "      <td>-127</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>30</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-110</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>23</td>\n",
       "      <td>-95</td>\n",
       "      <td>-28</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-302</td>\n",
       "      <td>60</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>30</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-102</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>-87</td>\n",
       "      <td>-28</td>\n",
       "      <td>-28</td>\n",
       "      <td>...</td>\n",
       "      <td>-73</td>\n",
       "      <td>-127</td>\n",
       "      <td>51.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>144</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>-170</td>\n",
       "      <td>-45</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-300</td>\n",
       "      <td>61</td>\n",
       "      <td>51.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>143</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  155  156    157  \\\n",
       "0   42 -191 -142  -65 -117   55   49 -170  -45    5  ... -302   60 -120.0   \n",
       "1   42 -191 -142  -75 -117   11   49 -161  -45  -28  ...  -73 -127 -120.0   \n",
       "2   42 -198 -110  -65 -117   55   23  -95  -28    5  ... -302   60 -120.0   \n",
       "3   42 -198 -102  -75 -117   10   24  -87  -28  -28  ...  -73 -127   51.0   \n",
       "4   42 -191 -142  -65 -117   55   49 -170  -45    6  ... -300   61   51.0   \n",
       "\n",
       "     158  159   160   161   162   163  164  \n",
       "0  -39.0   31  48.0 -37.0   5.0  30.0  1.0  \n",
       "1  -38.0   30  48.0 -37.0   5.0  31.0  1.0  \n",
       "2  -39.0   30  48.0 -37.0   6.0  30.0  1.0  \n",
       "3  128.0  144  43.0 -30.0  14.0  26.0  1.0  \n",
       "4  127.0  143  42.0 -31.0  14.0  26.0  1.0  \n",
       "\n",
       "[5 rows x 165 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 's3://omar-testes-gerais/artigos/artifacts/datasets'\n",
    "\n",
    "dfx = pd.read_csv(f\"{path}/{dfz.iloc[df_use_index]['path']}\", header = None)\n",
    "# dfx = pd.read_csv(f\"{path}/{dfz.iloc[df_use_index]['path']}\")\n",
    "dfx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e2454b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(475, 167)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e4a1b0ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 475 entries, 0 to 474\n",
      "Columns: 167 entries, 0 to 166\n",
      "dtypes: float64(34), int64(133)\n",
      "memory usage: 619.9 KB\n"
     ]
    }
   ],
   "source": [
    "dfx.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "23036025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' kw_avg_min', ' kw_avg_max']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valor_procurado = '316.142.857.143'\n",
    "colunas_com_valor = [col for col in dfx.columns if dfx[col].astype(str).str.contains(valor_procurado).any()]\n",
    "# colunas_com_valor = [col for col in dfx.columns if dfx[col].astype(str).str.contains(valor_procurado).any()]\n",
    "\n",
    "colunas_com_valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d40a4718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
      "/tmp/ipykernel_16424/693293896.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>157_convert</th>\n",
       "      <th>158_convert</th>\n",
       "      <th>159_convert</th>\n",
       "      <th>160_convert</th>\n",
       "      <th>161_convert</th>\n",
       "      <th>162_convert</th>\n",
       "      <th>163_convert</th>\n",
       "      <th>164_convert</th>\n",
       "      <th>165_convert</th>\n",
       "      <th>166_convert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>-170</td>\n",
       "      <td>-45</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>-161</td>\n",
       "      <td>-45</td>\n",
       "      <td>-28</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-110</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>23</td>\n",
       "      <td>-95</td>\n",
       "      <td>-28</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-102</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>-87</td>\n",
       "      <td>-28</td>\n",
       "      <td>-28</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>-170</td>\n",
       "      <td>-45</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>49</td>\n",
       "      <td>-199</td>\n",
       "      <td>-161</td>\n",
       "      <td>29</td>\n",
       "      <td>-95</td>\n",
       "      <td>-86</td>\n",
       "      <td>-48</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>-79</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>38</td>\n",
       "      <td>-123</td>\n",
       "      <td>-139</td>\n",
       "      <td>30</td>\n",
       "      <td>-117</td>\n",
       "      <td>-88</td>\n",
       "      <td>214</td>\n",
       "      <td>-13</td>\n",
       "      <td>-74</td>\n",
       "      <td>-129</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>43</td>\n",
       "      <td>-102</td>\n",
       "      <td>-20</td>\n",
       "      <td>-101</td>\n",
       "      <td>-116</td>\n",
       "      <td>200</td>\n",
       "      <td>-166</td>\n",
       "      <td>66</td>\n",
       "      <td>-222</td>\n",
       "      <td>-49</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>39</td>\n",
       "      <td>-58</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>-117</td>\n",
       "      <td>-92</td>\n",
       "      <td>85</td>\n",
       "      <td>21</td>\n",
       "      <td>-73</td>\n",
       "      <td>-68</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>52</td>\n",
       "      <td>-121</td>\n",
       "      <td>-24</td>\n",
       "      <td>-104</td>\n",
       "      <td>-116</td>\n",
       "      <td>195</td>\n",
       "      <td>-162</td>\n",
       "      <td>76</td>\n",
       "      <td>-226</td>\n",
       "      <td>-56</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>475 rows × 334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9  ...  157_convert  \\\n",
       "0    42 -191 -142  -65 -117   55   49 -170  -45    5  ...         True   \n",
       "1    42 -191 -142  -75 -117   11   49 -161  -45  -28  ...         True   \n",
       "2    42 -198 -110  -65 -117   55   23  -95  -28    5  ...         True   \n",
       "3    42 -198 -102  -75 -117   10   24  -87  -28  -28  ...         True   \n",
       "4    42 -191 -142  -65 -117   55   49 -170  -45    6  ...         True   \n",
       "..   ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...          ...   \n",
       "470  49 -199 -161   29  -95  -86  -48    2  112  -79  ...         True   \n",
       "471  38 -123 -139   30 -117  -88  214  -13  -74 -129  ...         True   \n",
       "472  43 -102  -20 -101 -116  200 -166   66 -222  -49  ...         True   \n",
       "473  39  -58   27   31 -117  -92   85   21  -73  -68  ...         True   \n",
       "474  52 -121  -24 -104 -116  195 -162   76 -226  -56  ...         True   \n",
       "\n",
       "     158_convert  159_convert  160_convert  161_convert  162_convert  \\\n",
       "0           True         True         True         True         True   \n",
       "1           True         True         True         True         True   \n",
       "2           True         True         True         True         True   \n",
       "3           True         True         True         True         True   \n",
       "4           True         True         True         True         True   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "470         True         True         True         True         True   \n",
       "471         True         True         True         True         True   \n",
       "472         True         True         True         True         True   \n",
       "473         True         True         True         True         True   \n",
       "474         True         True         True         True         True   \n",
       "\n",
       "     163_convert  164_convert  165_convert  166_convert  \n",
       "0           True         True         True         True  \n",
       "1           True         True         True         True  \n",
       "2           True         True         True         True  \n",
       "3           True         True         True         True  \n",
       "4           True         True         True         True  \n",
       "..           ...          ...          ...          ...  \n",
       "470         True         True         True         True  \n",
       "471         True         True         True         True  \n",
       "472         True         True         True         True  \n",
       "473         True         True         True         True  \n",
       "474         True         True         True         True  \n",
       "\n",
       "[475 rows x 334 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Função para verificar se um valor pode ser convertido para float\n",
    "def pode_converter_para_float(valor):\n",
    "    try:\n",
    "        float(valor)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "for col in dfx.columns:\n",
    "    # Aplicar a função nas duas colunas\n",
    "    dfx[f'{str(col)}_convert'] = dfx[col].apply(pode_converter_para_float)\n",
    "dfx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "8fefed02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0_convert', '1_convert', '2_convert', '3_convert', '4_convert', '5_convert', '6_convert', '7_convert', '8_convert', '9_convert', '10_convert', '11_convert', '12_convert', '13_convert', '14_convert', '15_convert', '16_convert', '17_convert', '18_convert', '19_convert', '20_convert', '21_convert', '22_convert', '23_convert', '24_convert', '25_convert', '26_convert', '27_convert', '28_convert', '29_convert', '30_convert', '31_convert', '32_convert', '33_convert', '34_convert', '35_convert', '36_convert', '37_convert', '38_convert', '39_convert', '40_convert', '41_convert', '42_convert', '43_convert', '44_convert', '45_convert', '46_convert', '47_convert', '48_convert', '49_convert', '50_convert', '51_convert', '52_convert', '53_convert', '54_convert', '55_convert', '56_convert', '57_convert', '58_convert', '59_convert', '60_convert', '61_convert', '62_convert', '63_convert', '64_convert', '65_convert', '66_convert', '67_convert', '68_convert', '69_convert', '70_convert', '71_convert', '72_convert', '73_convert', '74_convert', '75_convert', '76_convert', '77_convert', '78_convert', '79_convert', '80_convert', '81_convert', '82_convert', '83_convert', '84_convert', '85_convert', '86_convert', '87_convert', '88_convert', '89_convert', '90_convert', '91_convert', '92_convert', '93_convert', '94_convert', '95_convert', '96_convert', '97_convert', '98_convert', '99_convert', '100_convert', '101_convert', '102_convert', '103_convert', '104_convert', '105_convert', '106_convert', '107_convert', '108_convert', '109_convert', '110_convert', '111_convert', '112_convert', '113_convert', '114_convert', '115_convert', '116_convert', '117_convert', '118_convert', '119_convert', '120_convert', '121_convert', '122_convert', '123_convert', '124_convert', '125_convert', '126_convert', '127_convert', '128_convert', '129_convert', '130_convert', '131_convert', '132_convert', '133_convert', '134_convert', '135_convert', '136_convert', '137_convert', '138_convert', '139_convert', '140_convert', '141_convert', '142_convert', '143_convert', '144_convert', '145_convert', '146_convert', '147_convert', '148_convert', '149_convert', '150_convert', '151_convert', '152_convert', '153_convert', '154_convert', '155_convert', '156_convert', '157_convert', '158_convert', '159_convert', '160_convert', '161_convert', '162_convert', '163_convert', '164_convert', '165_convert', '166_convert']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrar as colunas que contêm \"_convert\" no nome\n",
    "colunas_convert = [col for col in dfx.columns if '_convert' in str(col)]\n",
    "print(colunas_convert)\n",
    "# Contar os valores False em cada coluna\n",
    "contagem_falsos = dfx[colunas_convert].apply(lambda coluna: (coluna == False).sum())\n",
    "\n",
    "# print(\"Quantidade de False em cada coluna '_convert':\")\n",
    "# print(contagem_falsos)\n",
    "contagem_falsos[contagem_falsos > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "5c2aa311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>-170</td>\n",
       "      <td>-45</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-302</td>\n",
       "      <td>60</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>31</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>-161</td>\n",
       "      <td>-45</td>\n",
       "      <td>-28</td>\n",
       "      <td>...</td>\n",
       "      <td>-73</td>\n",
       "      <td>-127</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>30</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-110</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>23</td>\n",
       "      <td>-95</td>\n",
       "      <td>-28</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-302</td>\n",
       "      <td>60</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>30</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-102</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>-87</td>\n",
       "      <td>-28</td>\n",
       "      <td>-28</td>\n",
       "      <td>...</td>\n",
       "      <td>-73</td>\n",
       "      <td>-127</td>\n",
       "      <td>51.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>144</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>-170</td>\n",
       "      <td>-45</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-300</td>\n",
       "      <td>61</td>\n",
       "      <td>51.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>143</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>49</td>\n",
       "      <td>-199</td>\n",
       "      <td>-161</td>\n",
       "      <td>29</td>\n",
       "      <td>-95</td>\n",
       "      <td>-86</td>\n",
       "      <td>-48</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>-79</td>\n",
       "      <td>...</td>\n",
       "      <td>-246</td>\n",
       "      <td>-209</td>\n",
       "      <td>33.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>134</td>\n",
       "      <td>47.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>38</td>\n",
       "      <td>-123</td>\n",
       "      <td>-139</td>\n",
       "      <td>30</td>\n",
       "      <td>-117</td>\n",
       "      <td>-88</td>\n",
       "      <td>214</td>\n",
       "      <td>-13</td>\n",
       "      <td>-74</td>\n",
       "      <td>-129</td>\n",
       "      <td>...</td>\n",
       "      <td>-226</td>\n",
       "      <td>-210</td>\n",
       "      <td>20.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>119</td>\n",
       "      <td>79.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>43</td>\n",
       "      <td>-102</td>\n",
       "      <td>-20</td>\n",
       "      <td>-101</td>\n",
       "      <td>-116</td>\n",
       "      <td>200</td>\n",
       "      <td>-166</td>\n",
       "      <td>66</td>\n",
       "      <td>-222</td>\n",
       "      <td>-49</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>136</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>121</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>39</td>\n",
       "      <td>-58</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>-117</td>\n",
       "      <td>-92</td>\n",
       "      <td>85</td>\n",
       "      <td>21</td>\n",
       "      <td>-73</td>\n",
       "      <td>-68</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>-206</td>\n",
       "      <td>13.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>116</td>\n",
       "      <td>79.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>52</td>\n",
       "      <td>-121</td>\n",
       "      <td>-24</td>\n",
       "      <td>-104</td>\n",
       "      <td>-116</td>\n",
       "      <td>195</td>\n",
       "      <td>-162</td>\n",
       "      <td>76</td>\n",
       "      <td>-226</td>\n",
       "      <td>-56</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>133</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>95</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>475 rows × 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    ...  156  157    158  \\\n",
       "0     42 -191 -142  -65 -117   55   49 -170  -45    5  ... -302   60 -120.0   \n",
       "1     42 -191 -142  -75 -117   11   49 -161  -45  -28  ...  -73 -127 -120.0   \n",
       "2     42 -198 -110  -65 -117   55   23  -95  -28    5  ... -302   60 -120.0   \n",
       "3     42 -198 -102  -75 -117   10   24  -87  -28  -28  ...  -73 -127   51.0   \n",
       "4     42 -191 -142  -65 -117   55   49 -170  -45    6  ... -300   61   51.0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...   \n",
       "470   49 -199 -161   29  -95  -86  -48    2  112  -79  ... -246 -209   33.0   \n",
       "471   38 -123 -139   30 -117  -88  214  -13  -74 -129  ... -226 -210   20.0   \n",
       "472   43 -102  -20 -101 -116  200 -166   66 -222  -49  ...   32  136  -15.0   \n",
       "473   39  -58   27   31 -117  -92   85   21  -73  -68  ... -232 -206   13.0   \n",
       "474   52 -121  -24 -104 -116  195 -162   76 -226  -56  ...   34  133  -20.0   \n",
       "\n",
       "       159  160   161   162   163   164  165  \n",
       "0    -39.0   31  48.0 -37.0   5.0  30.0  1.0  \n",
       "1    -38.0   30  48.0 -37.0   5.0  31.0  1.0  \n",
       "2    -39.0   30  48.0 -37.0   6.0  30.0  1.0  \n",
       "3    128.0  144  43.0 -30.0  14.0  26.0  1.0  \n",
       "4    127.0  143  42.0 -31.0  14.0  26.0  1.0  \n",
       "..     ...  ...   ...   ...   ...   ...  ...  \n",
       "470  152.0  134  47.0 -43.0 -15.0 -10.0  0.0  \n",
       "471   55.0  119  79.0 -28.0   4.0  74.0  0.0  \n",
       "472  143.0  121  55.0 -37.0 -19.0 -36.0  0.0  \n",
       "473   45.0  116  79.0 -28.0   3.0  74.0  0.0  \n",
       "474  -46.0   95  98.0 -14.0  12.0  96.0  0.0  \n",
       "\n",
       "[475 rows x 165 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx = dfx.drop([12], axis = 1)\n",
    "dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "19e14866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>-170</td>\n",
       "      <td>-45</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-302</td>\n",
       "      <td>60</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>31</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>-161</td>\n",
       "      <td>-45</td>\n",
       "      <td>-28</td>\n",
       "      <td>...</td>\n",
       "      <td>-73</td>\n",
       "      <td>-127</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>30</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-110</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>23</td>\n",
       "      <td>-95</td>\n",
       "      <td>-28</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-302</td>\n",
       "      <td>60</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>30</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-102</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>-87</td>\n",
       "      <td>-28</td>\n",
       "      <td>-28</td>\n",
       "      <td>...</td>\n",
       "      <td>-73</td>\n",
       "      <td>-127</td>\n",
       "      <td>51.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>144</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>-170</td>\n",
       "      <td>-45</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-300</td>\n",
       "      <td>61</td>\n",
       "      <td>51.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>143</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>49</td>\n",
       "      <td>-199</td>\n",
       "      <td>-161</td>\n",
       "      <td>29</td>\n",
       "      <td>-95</td>\n",
       "      <td>-86</td>\n",
       "      <td>-48</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>-79</td>\n",
       "      <td>...</td>\n",
       "      <td>-246</td>\n",
       "      <td>-209</td>\n",
       "      <td>33.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>134</td>\n",
       "      <td>47.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>38</td>\n",
       "      <td>-123</td>\n",
       "      <td>-139</td>\n",
       "      <td>30</td>\n",
       "      <td>-117</td>\n",
       "      <td>-88</td>\n",
       "      <td>214</td>\n",
       "      <td>-13</td>\n",
       "      <td>-74</td>\n",
       "      <td>-129</td>\n",
       "      <td>...</td>\n",
       "      <td>-226</td>\n",
       "      <td>-210</td>\n",
       "      <td>20.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>119</td>\n",
       "      <td>79.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>43</td>\n",
       "      <td>-102</td>\n",
       "      <td>-20</td>\n",
       "      <td>-101</td>\n",
       "      <td>-116</td>\n",
       "      <td>200</td>\n",
       "      <td>-166</td>\n",
       "      <td>66</td>\n",
       "      <td>-222</td>\n",
       "      <td>-49</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>136</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>121</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>39</td>\n",
       "      <td>-58</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>-117</td>\n",
       "      <td>-92</td>\n",
       "      <td>85</td>\n",
       "      <td>21</td>\n",
       "      <td>-73</td>\n",
       "      <td>-68</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>-206</td>\n",
       "      <td>13.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>116</td>\n",
       "      <td>79.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>52</td>\n",
       "      <td>-121</td>\n",
       "      <td>-24</td>\n",
       "      <td>-104</td>\n",
       "      <td>-116</td>\n",
       "      <td>195</td>\n",
       "      <td>-162</td>\n",
       "      <td>76</td>\n",
       "      <td>-226</td>\n",
       "      <td>-56</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>133</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>95</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>475 rows × 166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    ...  157  158    159  \\\n",
       "0     42 -191 -142  -65 -117   55   49 -170  -45    5  ... -302   60 -120.0   \n",
       "1     42 -191 -142  -75 -117   11   49 -161  -45  -28  ...  -73 -127 -120.0   \n",
       "2     42 -198 -110  -65 -117   55   23  -95  -28    5  ... -302   60 -120.0   \n",
       "3     42 -198 -102  -75 -117   10   24  -87  -28  -28  ...  -73 -127   51.0   \n",
       "4     42 -191 -142  -65 -117   55   49 -170  -45    6  ... -300   61   51.0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...   \n",
       "470   49 -199 -161   29  -95  -86  -48    2  112  -79  ... -246 -209   33.0   \n",
       "471   38 -123 -139   30 -117  -88  214  -13  -74 -129  ... -226 -210   20.0   \n",
       "472   43 -102  -20 -101 -116  200 -166   66 -222  -49  ...   32  136  -15.0   \n",
       "473   39  -58   27   31 -117  -92   85   21  -73  -68  ... -232 -206   13.0   \n",
       "474   52 -121  -24 -104 -116  195 -162   76 -226  -56  ...   34  133  -20.0   \n",
       "\n",
       "       160  161   162   163   164   165  166  \n",
       "0    -39.0   31  48.0 -37.0   5.0  30.0  1.0  \n",
       "1    -38.0   30  48.0 -37.0   5.0  31.0  1.0  \n",
       "2    -39.0   30  48.0 -37.0   6.0  30.0  1.0  \n",
       "3    128.0  144  43.0 -30.0  14.0  26.0  1.0  \n",
       "4    127.0  143  42.0 -31.0  14.0  26.0  1.0  \n",
       "..     ...  ...   ...   ...   ...   ...  ...  \n",
       "470  152.0  134  47.0 -43.0 -15.0 -10.0  0.0  \n",
       "471   55.0  119  79.0 -28.0   4.0  74.0  0.0  \n",
       "472  143.0  121  55.0 -37.0 -19.0 -36.0  0.0  \n",
       "473   45.0  116  79.0 -28.0   3.0  74.0  0.0  \n",
       "474  -46.0   95  98.0 -14.0  12.0  96.0  0.0  \n",
       "\n",
       "[475 rows x 166 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrar as colunas que contêm \"_convert\" no nome\n",
    "colunas_convert = [col for col in dfx.columns if '_convert' in str(col)]\n",
    "\n",
    "# Dropar as colunas do DataFrame\n",
    "dfx = dfx.drop(columns=colunas_convert)\n",
    "dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "5b47fd4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 475 entries, 0 to 474\n",
      "Columns: 166 entries, 0 to 166\n",
      "dtypes: float64(34), int64(132)\n",
      "memory usage: 616.1 KB\n"
     ]
    }
   ],
   "source": [
    "dfx.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "d03cd45a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contém NaN: False\n",
      "Contém Inf ou -Inf: False\n",
      "Valores maiores que float32:\n",
      " 0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "162    0\n",
      "163    0\n",
      "164    0\n",
      "165    0\n",
      "166    0\n",
      "Length: 166, dtype: int64\n",
      "Colunas com NaN: []\n"
     ]
    }
   ],
   "source": [
    "# Converte todas as colunas para numérico, substituindo valores não numéricos por NaN\n",
    "df_numeric = dfx.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Verifica se existe algum valor NaN\n",
    "tem_nan = df_numeric.isna().values.any()\n",
    "\n",
    "# Verifica se existe algum valor Inf ou -Inf\n",
    "tem_inf = np.isinf(df_numeric).values.any()\n",
    "\n",
    "# Limita valores muito grandes ao máximo permitido por float32\n",
    "max_float32 = np.finfo(np.float32).max\n",
    "df_numeric = df_numeric.clip(upper=max_float32)\n",
    "\n",
    "valores_grandes = (df_numeric.abs() > np.finfo(np.float32).max).sum()\n",
    "\n",
    "print(f\"Contém NaN: {tem_nan}\")\n",
    "print(f\"Contém Inf ou -Inf: {tem_inf}\")\n",
    "print(\"Valores maiores que float32:\\n\", valores_grandes)\n",
    "\n",
    "\n",
    "colunas_com_nan = df_numeric.columns[df_numeric.isna().any()].tolist()\n",
    "\n",
    "print(\"Colunas com NaN:\", colunas_com_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3a5f20ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 6,\n",
       " 7,\n",
       " 16,\n",
       " 19,\n",
       " 20,\n",
       " 22,\n",
       " 36,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 46,\n",
       " 51,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 62,\n",
       " 64,\n",
       " 71,\n",
       " 74,\n",
       " 85,\n",
       " 89,\n",
       " 90,\n",
       " 95,\n",
       " 97,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 109,\n",
       " 114,\n",
       " 120,\n",
       " 132,\n",
       " 148,\n",
       " 163,\n",
       " 167,\n",
       " 171,\n",
       " 174,\n",
       " 177,\n",
       " 179,\n",
       " 192,\n",
       " 194,\n",
       " 207,\n",
       " 213,\n",
       " 222,\n",
       " 223,\n",
       " 247,\n",
       " 260,\n",
       " 266,\n",
       " 268,\n",
       " 275,\n",
       " 289,\n",
       " 290,\n",
       " 292,\n",
       " 297,\n",
       " 298,\n",
       " 306,\n",
       " 316,\n",
       " 318,\n",
       " 321,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 330,\n",
       " 332,\n",
       " 336,\n",
       " 338,\n",
       " 350,\n",
       " 386,\n",
       " 394,\n",
       " 397,\n",
       " 426,\n",
       " 434,\n",
       " 440,\n",
       " 457,\n",
       " 462,\n",
       " 493,\n",
       " 494,\n",
       " 506,\n",
       " 517,\n",
       " 526,\n",
       " 532,\n",
       " 534,\n",
       " 579,\n",
       " 588,\n",
       " 606,\n",
       " 622,\n",
       " 636,\n",
       " 650,\n",
       " 655,\n",
       " 670,\n",
       " 682,\n",
       " 683,\n",
       " 684,\n",
       " 703,\n",
       " 710,\n",
       " 756,\n",
       " 759,\n",
       " 766,\n",
       " 768,\n",
       " 769,\n",
       " 804,\n",
       " 812,\n",
       " 813,\n",
       " 843,\n",
       " 850,\n",
       " 853,\n",
       " 854,\n",
       " 862,\n",
       " 870,\n",
       " 892,\n",
       " 907,\n",
       " 923,\n",
       " 979,\n",
       " 983,\n",
       " 996,\n",
       " 1002,\n",
       " 1010,\n",
       " 1011,\n",
       " 1031,\n",
       " 1063,\n",
       " 1066,\n",
       " 1067,\n",
       " 1078,\n",
       " 1106,\n",
       " 1118,\n",
       " 1120,\n",
       " 1137,\n",
       " 1141,\n",
       " 1148,\n",
       " 1169,\n",
       " 1191,\n",
       " 1208,\n",
       " 1209,\n",
       " 1220,\n",
       " 1251,\n",
       " 1269,\n",
       " 1278,\n",
       " 1284,\n",
       " 1285,\n",
       " 1313,\n",
       " 1323,\n",
       " 1337,\n",
       " 1346,\n",
       " 1358,\n",
       " 1361,\n",
       " 1384,\n",
       " 1421,\n",
       " 1439,\n",
       " 1476,\n",
       " 1484,\n",
       " 1523,\n",
       " 1528,\n",
       " 1529,\n",
       " 1532,\n",
       " 1534,\n",
       " 1543,\n",
       " 1546,\n",
       " 1566,\n",
       " 1569,\n",
       " 1601,\n",
       " 1610,\n",
       " 1615,\n",
       " 1622,\n",
       " 1626,\n",
       " 1641,\n",
       " 1673,\n",
       " 1685,\n",
       " 1687,\n",
       " 1709,\n",
       " 1713,\n",
       " 1716,\n",
       " 1721,\n",
       " 1746,\n",
       " 1775,\n",
       " 1783,\n",
       " 1784,\n",
       " 1817,\n",
       " 1840,\n",
       " 1853,\n",
       " 1854,\n",
       " 1859,\n",
       " 1868,\n",
       " 1910,\n",
       " 1950,\n",
       " 1958,\n",
       " 1969,\n",
       " 1995,\n",
       " 1997,\n",
       " 1998,\n",
       " 2007,\n",
       " 2024,\n",
       " 2052,\n",
       " 2089,\n",
       " 2097,\n",
       " 2098,\n",
       " 2130,\n",
       " 2153,\n",
       " 2169,\n",
       " 2176,\n",
       " 2187,\n",
       " 2208,\n",
       " 2218,\n",
       " 2262,\n",
       " 2279,\n",
       " 2297,\n",
       " 2314,\n",
       " 2332,\n",
       " 2368,\n",
       " 2372,\n",
       " 2385,\n",
       " 2392,\n",
       " 2394,\n",
       " 2400,\n",
       " 2407,\n",
       " 2417,\n",
       " 2463,\n",
       " 2468,\n",
       " 2478,\n",
       " 2484,\n",
       " 2493,\n",
       " 2550,\n",
       " 2567,\n",
       " 2569,\n",
       " 2571,\n",
       " 2577,\n",
       " 2582,\n",
       " 2593,\n",
       " 2602,\n",
       " 2608,\n",
       " 2616,\n",
       " 2623,\n",
       " 2630,\n",
       " 2642,\n",
       " 2651,\n",
       " 2658,\n",
       " 2665,\n",
       " 2686,\n",
       " 2694,\n",
       " 2728,\n",
       " 2733,\n",
       " 2735,\n",
       " 2773,\n",
       " 2818,\n",
       " 2825,\n",
       " 2841,\n",
       " 2845,\n",
       " 2872,\n",
       " 2877,\n",
       " 2887,\n",
       " 2894,\n",
       " 2897,\n",
       " 2913,\n",
       " 2926,\n",
       " 2947,\n",
       " 2949,\n",
       " 2955,\n",
       " 2956,\n",
       " 2968,\n",
       " 2979,\n",
       " 2981,\n",
       " 2989,\n",
       " 3025,\n",
       " 3031,\n",
       " 3036,\n",
       " 3056,\n",
       " 3059,\n",
       " 3067,\n",
       " 3069,\n",
       " 3107,\n",
       " 3109,\n",
       " 3118,\n",
       " 3121,\n",
       " 3132,\n",
       " 3134,\n",
       " 3162,\n",
       " 3191,\n",
       " 3200,\n",
       " 3234,\n",
       " 3249,\n",
       " 3267,\n",
       " 3269,\n",
       " 3289,\n",
       " 3298,\n",
       " 3306,\n",
       " 3311,\n",
       " 3323,\n",
       " 3328,\n",
       " 3342,\n",
       " 3344,\n",
       " 3349,\n",
       " 3354,\n",
       " 3361,\n",
       " 3362,\n",
       " 3380,\n",
       " 3388,\n",
       " 3391,\n",
       " 3392,\n",
       " 3402,\n",
       " 3404,\n",
       " 3406,\n",
       " 3415,\n",
       " 3423,\n",
       " 3432,\n",
       " 3441,\n",
       " 3451,\n",
       " 3462,\n",
       " 3469,\n",
       " 3471,\n",
       " 3493,\n",
       " 3509,\n",
       " 3527,\n",
       " 3541,\n",
       " 3543,\n",
       " 3564,\n",
       " 3569,\n",
       " 3607,\n",
       " 3616,\n",
       " 3632,\n",
       " 3641,\n",
       " 3662,\n",
       " 3664,\n",
       " 3674,\n",
       " 3675,\n",
       " 3680,\n",
       " 3719,\n",
       " 3735,\n",
       " 3756,\n",
       " 3763,\n",
       " 3764,\n",
       " 3771,\n",
       " 3785,\n",
       " 3814,\n",
       " 3817,\n",
       " 3826,\n",
       " 3835,\n",
       " 3839,\n",
       " 3842,\n",
       " 3867,\n",
       " 3892,\n",
       " 3897,\n",
       " 3911,\n",
       " 3916,\n",
       " 3924,\n",
       " 3932,\n",
       " 3936,\n",
       " 3938,\n",
       " 3942,\n",
       " 3954,\n",
       " 3961,\n",
       " 3973,\n",
       " 3979,\n",
       " 3999,\n",
       " 4006,\n",
       " 4008,\n",
       " 4010,\n",
       " 4015,\n",
       " 4035,\n",
       " 4038,\n",
       " 4049,\n",
       " 4066,\n",
       " 4074,\n",
       " 4075,\n",
       " 4087,\n",
       " 4101,\n",
       " 4136,\n",
       " 4151,\n",
       " 4154,\n",
       " 4161,\n",
       " 4172,\n",
       " 4179,\n",
       " 4182,\n",
       " 4191,\n",
       " 4199,\n",
       " 4200,\n",
       " 4203,\n",
       " 4233,\n",
       " 4247,\n",
       " 4248,\n",
       " 4251,\n",
       " 4259,\n",
       " 4260,\n",
       " 4264,\n",
       " 4268,\n",
       " 4273,\n",
       " 4276,\n",
       " 4284,\n",
       " 4289,\n",
       " 4298,\n",
       " 4314,\n",
       " 4317,\n",
       " 4342,\n",
       " 4357,\n",
       " 4382,\n",
       " 4394,\n",
       " 4403,\n",
       " 4418,\n",
       " 4429,\n",
       " 4439,\n",
       " 4445,\n",
       " 4454,\n",
       " 4462,\n",
       " 4463,\n",
       " 4467,\n",
       " 4481,\n",
       " 4493,\n",
       " 4496,\n",
       " 4515,\n",
       " 4533,\n",
       " 4543,\n",
       " 4549,\n",
       " 4566,\n",
       " 4569,\n",
       " 4570,\n",
       " 4573,\n",
       " 4585,\n",
       " 4593,\n",
       " 4604,\n",
       " 4606,\n",
       " 4608,\n",
       " 4612,\n",
       " 4618,\n",
       " 4622,\n",
       " 4630,\n",
       " 4639,\n",
       " 4643,\n",
       " 4644,\n",
       " 4646,\n",
       " 4661,\n",
       " 4675,\n",
       " 4702,\n",
       " 4735,\n",
       " 4739,\n",
       " 4745,\n",
       " 4753,\n",
       " 4766,\n",
       " 4783,\n",
       " 4797,\n",
       " 4807,\n",
       " 4820,\n",
       " 4844,\n",
       " 4869,\n",
       " 4876,\n",
       " 4880,\n",
       " 4885,\n",
       " 4886,\n",
       " 4896,\n",
       " 4904,\n",
       " 4918,\n",
       " 4929,\n",
       " 4944,\n",
       " 4970,\n",
       " 4984,\n",
       " 4988,\n",
       " 5009,\n",
       " 5011,\n",
       " 5013,\n",
       " 5028,\n",
       " 5057,\n",
       " 5067,\n",
       " 5078,\n",
       " 5095,\n",
       " 5105,\n",
       " 5109,\n",
       " 5111,\n",
       " 5122,\n",
       " 5141,\n",
       " 5142,\n",
       " 5165,\n",
       " 5178,\n",
       " 5181,\n",
       " 5194,\n",
       " 5199,\n",
       " 5201,\n",
       " 5209,\n",
       " 5220,\n",
       " 5221,\n",
       " 5227,\n",
       " 5232,\n",
       " 5237,\n",
       " 5270,\n",
       " 5271,\n",
       " 5293,\n",
       " 5309,\n",
       " 5315,\n",
       " 5318,\n",
       " 5330,\n",
       " 5342,\n",
       " 5370,\n",
       " 5372,\n",
       " 5382,\n",
       " 5388,\n",
       " 5394,\n",
       " 5407,\n",
       " 5412,\n",
       " 5455,\n",
       " 5466,\n",
       " 5470,\n",
       " 5473,\n",
       " 5475,\n",
       " 5488,\n",
       " 5489,\n",
       " 5508,\n",
       " 5511,\n",
       " 5524,\n",
       " 5525,\n",
       " 5535,\n",
       " 5544,\n",
       " 5551,\n",
       " 5557,\n",
       " 5563,\n",
       " 5586,\n",
       " 5593,\n",
       " 5599,\n",
       " 5603,\n",
       " 5656,\n",
       " 5660,\n",
       " 5664,\n",
       " 5665,\n",
       " 5668,\n",
       " 5672,\n",
       " 5674,\n",
       " 5693,\n",
       " 5706,\n",
       " 5725,\n",
       " 5749,\n",
       " 5751,\n",
       " 5754,\n",
       " 5766,\n",
       " 5769,\n",
       " 5786,\n",
       " 5788,\n",
       " 5803,\n",
       " 5808,\n",
       " 5849,\n",
       " 5851,\n",
       " 5853,\n",
       " 5873,\n",
       " 5874,\n",
       " 5888,\n",
       " 5889,\n",
       " 5908,\n",
       " 5918,\n",
       " 5923,\n",
       " 5928,\n",
       " 5936,\n",
       " 5938,\n",
       " 5940,\n",
       " 5941,\n",
       " 5945,\n",
       " 5950,\n",
       " 5966,\n",
       " 5991,\n",
       " 6000,\n",
       " 6005,\n",
       " 6023,\n",
       " 6033,\n",
       " 6034,\n",
       " 6039,\n",
       " 6048,\n",
       " 6057,\n",
       " 6065,\n",
       " 6076,\n",
       " 6087,\n",
       " 6089,\n",
       " 6094,\n",
       " 6097,\n",
       " 6101,\n",
       " 6112,\n",
       " 6134,\n",
       " 6150,\n",
       " 6153,\n",
       " 6187,\n",
       " 6190,\n",
       " 6211,\n",
       " 6218,\n",
       " 6223,\n",
       " 6224,\n",
       " 6269,\n",
       " 6273,\n",
       " 6284,\n",
       " 6288,\n",
       " 6297,\n",
       " 6299,\n",
       " 6316,\n",
       " 6378,\n",
       " 6382,\n",
       " 6393,\n",
       " 6398,\n",
       " 6399,\n",
       " 6416,\n",
       " 6422,\n",
       " 6423,\n",
       " 6428,\n",
       " 6429,\n",
       " 6481,\n",
       " 6499,\n",
       " 6536,\n",
       " 6544,\n",
       " 6546,\n",
       " 6561,\n",
       " 6568,\n",
       " 6587,\n",
       " 6624,\n",
       " 6632,\n",
       " 6646,\n",
       " 6665,\n",
       " 6668,\n",
       " 6694,\n",
       " 6709,\n",
       " 6710,\n",
       " 6725,\n",
       " 6741,\n",
       " 6751,\n",
       " 6754,\n",
       " 6773,\n",
       " 6787,\n",
       " 6805,\n",
       " 6822,\n",
       " 6824,\n",
       " 6835,\n",
       " 6836,\n",
       " 6840,\n",
       " 6859,\n",
       " 6866,\n",
       " 6902,\n",
       " 6944,\n",
       " 6976,\n",
       " 6980,\n",
       " 6989,\n",
       " 6994,\n",
       " 7005,\n",
       " 7014,\n",
       " 7019,\n",
       " 7034,\n",
       " 7043,\n",
       " 7045,\n",
       " 7048,\n",
       " 7051,\n",
       " 7055,\n",
       " 7062,\n",
       " 7065,\n",
       " 7069,\n",
       " 7078,\n",
       " 7083,\n",
       " 7094,\n",
       " 7096,\n",
       " 7105,\n",
       " 7115,\n",
       " 7123,\n",
       " 7163,\n",
       " 7183,\n",
       " 7184,\n",
       " 7189,\n",
       " 7197,\n",
       " 7206,\n",
       " 7212,\n",
       " 7215,\n",
       " 7217,\n",
       " 7221,\n",
       " 7239,\n",
       " 7251,\n",
       " 7261,\n",
       " 7263,\n",
       " 7268,\n",
       " 7274,\n",
       " 7294,\n",
       " 7295,\n",
       " 7312,\n",
       " 7321,\n",
       " 7323,\n",
       " 7341,\n",
       " 7353,\n",
       " 7359,\n",
       " 7361,\n",
       " 7373,\n",
       " 7381,\n",
       " 7384,\n",
       " 7387,\n",
       " 7395,\n",
       " 7406,\n",
       " 7407,\n",
       " 7419,\n",
       " 7431,\n",
       " 7440,\n",
       " 7454,\n",
       " 7485,\n",
       " 7490,\n",
       " 7508,\n",
       " 7534,\n",
       " 7536,\n",
       " 7537,\n",
       " 7547,\n",
       " 7550,\n",
       " 7564,\n",
       " 7574,\n",
       " 7580,\n",
       " 7584,\n",
       " 7588,\n",
       " 7589,\n",
       " 7608,\n",
       " 7621,\n",
       " 7626,\n",
       " 7660,\n",
       " 7665,\n",
       " 7679,\n",
       " 7692,\n",
       " 7719,\n",
       " 7729,\n",
       " 7734,\n",
       " 7749,\n",
       " 7751,\n",
       " 7755,\n",
       " 7765,\n",
       " 7771,\n",
       " 7773,\n",
       " 7788,\n",
       " 7789,\n",
       " 7816,\n",
       " 7824,\n",
       " 7828,\n",
       " 7855,\n",
       " 7865,\n",
       " 7873,\n",
       " 7878,\n",
       " 7889,\n",
       " 7890,\n",
       " 7897,\n",
       " 7906,\n",
       " 7923,\n",
       " 7939,\n",
       " 7941,\n",
       " 7951,\n",
       " 7975,\n",
       " 7986,\n",
       " 8007,\n",
       " 8033,\n",
       " 8042,\n",
       " 8051,\n",
       " 8055,\n",
       " 8057,\n",
       " 8058,\n",
       " 8062,\n",
       " 8075,\n",
       " 8081,\n",
       " 8098,\n",
       " 8102,\n",
       " 8118,\n",
       " 8120,\n",
       " 8141,\n",
       " 8158,\n",
       " 8178,\n",
       " 8197,\n",
       " 8208,\n",
       " 8209,\n",
       " 8229,\n",
       " 8238,\n",
       " 8257,\n",
       " 8265,\n",
       " 8269,\n",
       " 8275,\n",
       " 8282,\n",
       " 8293,\n",
       " 8303,\n",
       " 8316,\n",
       " 8333,\n",
       " 8335,\n",
       " 8338,\n",
       " 8339,\n",
       " 8345,\n",
       " 8385,\n",
       " 8387,\n",
       " 8401,\n",
       " 8404,\n",
       " 8406,\n",
       " 8412,\n",
       " 8422,\n",
       " 8438,\n",
       " 8439,\n",
       " 8447,\n",
       " 8451,\n",
       " 8470,\n",
       " 8471,\n",
       " 8489,\n",
       " 8492,\n",
       " 8497,\n",
       " 8498,\n",
       " 8512,\n",
       " 8519,\n",
       " 8524,\n",
       " 8531,\n",
       " 8536,\n",
       " 8565,\n",
       " 8574,\n",
       " 8577,\n",
       " 8594,\n",
       " 8599,\n",
       " 8605,\n",
       " 8635,\n",
       " 8644,\n",
       " 8649,\n",
       " 8674,\n",
       " 8678,\n",
       " 8700,\n",
       " 8709,\n",
       " 8710,\n",
       " 8713,\n",
       " 8717,\n",
       " 8719,\n",
       " 8747,\n",
       " 8753,\n",
       " 8757,\n",
       " 8760,\n",
       " 8764,\n",
       " 8765,\n",
       " 8772,\n",
       " 8810,\n",
       " 8811,\n",
       " 8818,\n",
       " 8855,\n",
       " 8865,\n",
       " 8878,\n",
       " 8891,\n",
       " 8902,\n",
       " 8915,\n",
       " 8920,\n",
       " 8945,\n",
       " 8968,\n",
       " 8973,\n",
       " 8974,\n",
       " 8980,\n",
       " 8986,\n",
       " 9025,\n",
       " 9087,\n",
       " 9090,\n",
       " 9093,\n",
       " 9097,\n",
       " 9103,\n",
       " 9106,\n",
       " 9124,\n",
       " 9129,\n",
       " 9156,\n",
       " 9160,\n",
       " 9174,\n",
       " 9194,\n",
       " 9218,\n",
       " 9239,\n",
       " 9241,\n",
       " 9248,\n",
       " 9256,\n",
       " 9262,\n",
       " 9268,\n",
       " 9269,\n",
       " 9287,\n",
       " 9299,\n",
       " 9310,\n",
       " 9364,\n",
       " 9365,\n",
       " 9377,\n",
       " 9380,\n",
       " 9387,\n",
       " 9389,\n",
       " 9395,\n",
       " 9403,\n",
       " 9411,\n",
       " 9440,\n",
       " 9452,\n",
       " 9456,\n",
       " 9458,\n",
       " 9460,\n",
       " 9461,\n",
       " 9463,\n",
       " 9471,\n",
       " 9478,\n",
       " 9500,\n",
       " 9503,\n",
       " 9507,\n",
       " 9516,\n",
       " 9524,\n",
       " 9527,\n",
       " 9537,\n",
       " 9543,\n",
       " 9550,\n",
       " 9560,\n",
       " 9561,\n",
       " 9572,\n",
       " 9580,\n",
       " 9583,\n",
       " 9593,\n",
       " 9603,\n",
       " 9605,\n",
       " 9611,\n",
       " 9617,\n",
       " 9618,\n",
       " 9626,\n",
       " 9630,\n",
       " 9634,\n",
       " 9657,\n",
       " 9658,\n",
       " 9665,\n",
       " 9668,\n",
       " 9687,\n",
       " 9702,\n",
       " 9705,\n",
       " 9720,\n",
       " 9721,\n",
       " 9724,\n",
       " 9725,\n",
       " 9731,\n",
       " 9736,\n",
       " 9745,\n",
       " 9778,\n",
       " 9788,\n",
       " 9790,\n",
       " 9808,\n",
       " 9828,\n",
       " 9830,\n",
       " 9834,\n",
       " 9838,\n",
       " 9840,\n",
       " 9858,\n",
       " 9861,\n",
       " 9871,\n",
       " 9876,\n",
       " 9883,\n",
       " 9893,\n",
       " 9896,\n",
       " 9909,\n",
       " 9913,\n",
       " 9922,\n",
       " 9930,\n",
       " 9931,\n",
       " 9933,\n",
       " 9952,\n",
       " 9956,\n",
       " 9968,\n",
       " 9975,\n",
       " 9991,\n",
       " 9997,\n",
       " 10013,\n",
       " 10017,\n",
       " 10027,\n",
       " 10037,\n",
       " 10038,\n",
       " 10057,\n",
       " 10082,\n",
       " 10092,\n",
       " 10096,\n",
       " 10101,\n",
       " 10119,\n",
       " 10133,\n",
       " 10138,\n",
       " 10141,\n",
       " 10142,\n",
       " 10155,\n",
       " 10171,\n",
       " 10174,\n",
       " 10182,\n",
       " 10189,\n",
       " 10190,\n",
       " 10196,\n",
       " 10212,\n",
       " 10213,\n",
       " 10220,\n",
       " 10234,\n",
       " 10247,\n",
       " 10286,\n",
       " 10287,\n",
       " 10290,\n",
       " 10298,\n",
       " 10305,\n",
       " 10336,\n",
       " 10362,\n",
       " 10369,\n",
       " 10371,\n",
       " 10374,\n",
       " 10386,\n",
       " 10400,\n",
       " 10401,\n",
       " 10410,\n",
       " 10445,\n",
       " 10455,\n",
       " 10498,\n",
       " 10505,\n",
       " 10513,\n",
       " 10560,\n",
       " 10583,\n",
       " 10594,\n",
       " 10605,\n",
       " 10620,\n",
       " 10638,\n",
       " 10642,\n",
       " 10650,\n",
       " 10654,\n",
       " 10656,\n",
       " 10657,\n",
       " 10658,\n",
       " 10672,\n",
       " 10708,\n",
       " 10709,\n",
       " 10712,\n",
       " ...]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index_to_drop = dfx.loc[dfx[' average_token_length'] == valor_procurado].index.to_list()\n",
    "index_to_drop = list(df_numeric[df_numeric[' self_reference_avg_sharess'].isna()].index)\n",
    "index_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "401dc7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>-170</td>\n",
       "      <td>-45</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-302</td>\n",
       "      <td>60</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>31</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>-161</td>\n",
       "      <td>-45</td>\n",
       "      <td>-28</td>\n",
       "      <td>...</td>\n",
       "      <td>-73</td>\n",
       "      <td>-127</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>30</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-110</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>23</td>\n",
       "      <td>-95</td>\n",
       "      <td>-28</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-302</td>\n",
       "      <td>60</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>30</td>\n",
       "      <td>48.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>-198</td>\n",
       "      <td>-102</td>\n",
       "      <td>-75</td>\n",
       "      <td>-117</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>-87</td>\n",
       "      <td>-28</td>\n",
       "      <td>-28</td>\n",
       "      <td>...</td>\n",
       "      <td>-73</td>\n",
       "      <td>-127</td>\n",
       "      <td>51.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>144</td>\n",
       "      <td>43.0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>-191</td>\n",
       "      <td>-142</td>\n",
       "      <td>-65</td>\n",
       "      <td>-117</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>-170</td>\n",
       "      <td>-45</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-300</td>\n",
       "      <td>61</td>\n",
       "      <td>51.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>143</td>\n",
       "      <td>42.0</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>49</td>\n",
       "      <td>-199</td>\n",
       "      <td>-161</td>\n",
       "      <td>29</td>\n",
       "      <td>-95</td>\n",
       "      <td>-86</td>\n",
       "      <td>-48</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>-79</td>\n",
       "      <td>...</td>\n",
       "      <td>-246</td>\n",
       "      <td>-209</td>\n",
       "      <td>33.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>134</td>\n",
       "      <td>47.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>38</td>\n",
       "      <td>-123</td>\n",
       "      <td>-139</td>\n",
       "      <td>30</td>\n",
       "      <td>-117</td>\n",
       "      <td>-88</td>\n",
       "      <td>214</td>\n",
       "      <td>-13</td>\n",
       "      <td>-74</td>\n",
       "      <td>-129</td>\n",
       "      <td>...</td>\n",
       "      <td>-226</td>\n",
       "      <td>-210</td>\n",
       "      <td>20.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>119</td>\n",
       "      <td>79.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>43</td>\n",
       "      <td>-102</td>\n",
       "      <td>-20</td>\n",
       "      <td>-101</td>\n",
       "      <td>-116</td>\n",
       "      <td>200</td>\n",
       "      <td>-166</td>\n",
       "      <td>66</td>\n",
       "      <td>-222</td>\n",
       "      <td>-49</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>136</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>121</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>39</td>\n",
       "      <td>-58</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>-117</td>\n",
       "      <td>-92</td>\n",
       "      <td>85</td>\n",
       "      <td>21</td>\n",
       "      <td>-73</td>\n",
       "      <td>-68</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>-206</td>\n",
       "      <td>13.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>116</td>\n",
       "      <td>79.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>52</td>\n",
       "      <td>-121</td>\n",
       "      <td>-24</td>\n",
       "      <td>-104</td>\n",
       "      <td>-116</td>\n",
       "      <td>195</td>\n",
       "      <td>-162</td>\n",
       "      <td>76</td>\n",
       "      <td>-226</td>\n",
       "      <td>-56</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>133</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>95</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>475 rows × 166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    ...  157  158    159  \\\n",
       "0     42 -191 -142  -65 -117   55   49 -170  -45    5  ... -302   60 -120.0   \n",
       "1     42 -191 -142  -75 -117   11   49 -161  -45  -28  ...  -73 -127 -120.0   \n",
       "2     42 -198 -110  -65 -117   55   23  -95  -28    5  ... -302   60 -120.0   \n",
       "3     42 -198 -102  -75 -117   10   24  -87  -28  -28  ...  -73 -127   51.0   \n",
       "4     42 -191 -142  -65 -117   55   49 -170  -45    6  ... -300   61   51.0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...   \n",
       "470   49 -199 -161   29  -95  -86  -48    2  112  -79  ... -246 -209   33.0   \n",
       "471   38 -123 -139   30 -117  -88  214  -13  -74 -129  ... -226 -210   20.0   \n",
       "472   43 -102  -20 -101 -116  200 -166   66 -222  -49  ...   32  136  -15.0   \n",
       "473   39  -58   27   31 -117  -92   85   21  -73  -68  ... -232 -206   13.0   \n",
       "474   52 -121  -24 -104 -116  195 -162   76 -226  -56  ...   34  133  -20.0   \n",
       "\n",
       "       160  161   162   163   164   165  166  \n",
       "0    -39.0   31  48.0 -37.0   5.0  30.0  1.0  \n",
       "1    -38.0   30  48.0 -37.0   5.0  31.0  1.0  \n",
       "2    -39.0   30  48.0 -37.0   6.0  30.0  1.0  \n",
       "3    128.0  144  43.0 -30.0  14.0  26.0  1.0  \n",
       "4    127.0  143  42.0 -31.0  14.0  26.0  1.0  \n",
       "..     ...  ...   ...   ...   ...   ...  ...  \n",
       "470  152.0  134  47.0 -43.0 -15.0 -10.0  0.0  \n",
       "471   55.0  119  79.0 -28.0   4.0  74.0  0.0  \n",
       "472  143.0  121  55.0 -37.0 -19.0 -36.0  0.0  \n",
       "473   45.0  116  79.0 -28.0   3.0  74.0  0.0  \n",
       "474  -46.0   95  98.0 -14.0  12.0  96.0  0.0  \n",
       "\n",
       "[475 rows x 166 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dfx = dfx.drop(index_to_drop)\n",
    "# dfx = dfx.drop(['convert'], axis = 1)\n",
    "dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "cc7598de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx.to_csv(f\"{path}/{dfz.iloc[df_use_index]['path']}\", index = False, header = False)\n",
    "# dfx.to_csv(f\"{path}/{dfz.iloc[df_use_index]['path']}\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1f35f58a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surgery</th>\n",
       "      <th>age</th>\n",
       "      <th>hospital_number</th>\n",
       "      <th>rectal_temp</th>\n",
       "      <th>pulse</th>\n",
       "      <th>respiratory_rate</th>\n",
       "      <th>temp_of_extremities</th>\n",
       "      <th>peripheral_pulse</th>\n",
       "      <th>pain</th>\n",
       "      <th>peristalsis</th>\n",
       "      <th>...</th>\n",
       "      <th>capillary_refill_time=more_3_sec</th>\n",
       "      <th>abdomen=2</th>\n",
       "      <th>abdomen=distend_large</th>\n",
       "      <th>abdomen=distend_small</th>\n",
       "      <th>abdomen=firm</th>\n",
       "      <th>abdomen=other</th>\n",
       "      <th>outcome=died</th>\n",
       "      <th>outcome=euthanized</th>\n",
       "      <th>outcome=lived</th>\n",
       "      <th>cp_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>530101</td>\n",
       "      <td>38.5</td>\n",
       "      <td>66</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>534817</td>\n",
       "      <td>39.2</td>\n",
       "      <td>88</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>530334</td>\n",
       "      <td>38.3</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5290409</td>\n",
       "      <td>39.1</td>\n",
       "      <td>164</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>530255</td>\n",
       "      <td>37.3</td>\n",
       "      <td>104</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>533902</td>\n",
       "      <td>38.5</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>527702</td>\n",
       "      <td>37.2</td>\n",
       "      <td>72</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>529386</td>\n",
       "      <td>37.5</td>\n",
       "      <td>72</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>530612</td>\n",
       "      <td>36.5</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>534618</td>\n",
       "      <td>37.2</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     surgery  age  hospital_number  rectal_temp  pulse  respiratory_rate  \\\n",
       "0          0    0           530101         38.5     66                28   \n",
       "1          1    0           534817         39.2     88                20   \n",
       "2          0    0           530334         38.3     40                24   \n",
       "3          1    1          5290409         39.1    164                84   \n",
       "4          0    0           530255         37.3    104                35   \n",
       "..       ...  ...              ...          ...    ...               ...   \n",
       "234        0    0           533902         38.5     40                16   \n",
       "235        0    0           527702         37.2     72                24   \n",
       "236        1    0           529386         37.5     72                30   \n",
       "237        1    0           530612         36.5    100                24   \n",
       "238        1    0           534618         37.2     40                20   \n",
       "\n",
       "     temp_of_extremities  peripheral_pulse  pain  peristalsis  ...  \\\n",
       "0                      1                 1     5            4  ...   \n",
       "1                      1                 1     3            4  ...   \n",
       "2                      2                 2     3            3  ...   \n",
       "3                      0                 2     2            4  ...   \n",
       "4                      1                 1     2            2  ...   \n",
       "..                   ...               ...   ...          ...  ...   \n",
       "234                    2                 2     2            1  ...   \n",
       "235                    1                 3     4            3  ...   \n",
       "236                    0                 1     4            4  ...   \n",
       "237                    1                 1     3            3  ...   \n",
       "238                    1                 1     2            2  ...   \n",
       "\n",
       "     capillary_refill_time=more_3_sec  abdomen=2  abdomen=distend_large  \\\n",
       "0                                   1          0                      1   \n",
       "1                                   0          0                      0   \n",
       "2                                   0          1                      0   \n",
       "3                                   1          0                      1   \n",
       "4                                   1          0                      1   \n",
       "..                                ...        ...                    ...   \n",
       "234                                 0          0                      0   \n",
       "235                                 1          0                      0   \n",
       "236                                 0          0                      1   \n",
       "237                                 0          0                      0   \n",
       "238                                 0          1                      0   \n",
       "\n",
       "     abdomen=distend_small  abdomen=firm  abdomen=other  outcome=died  \\\n",
       "0                        0             0              0             1   \n",
       "1                        0             0              1             0   \n",
       "2                        0             0              0             0   \n",
       "3                        0             0              0             1   \n",
       "4                        0             0              0             1   \n",
       "..                     ...           ...            ...           ...   \n",
       "234                      0             0              1             0   \n",
       "235                      1             0              0             0   \n",
       "236                      0             0              0             1   \n",
       "237                      1             0              0             0   \n",
       "238                      0             0              0             0   \n",
       "\n",
       "     outcome=euthanized  outcome=lived  cp_data  \n",
       "0                     0              0        0  \n",
       "1                     1              0        0  \n",
       "2                     0              1        1  \n",
       "3                     0              0        1  \n",
       "4                     0              0        0  \n",
       "..                  ...            ...      ...  \n",
       "234                   0              1        0  \n",
       "235                   1              0        1  \n",
       "236                   0              0        0  \n",
       "237                   0              1        1  \n",
       "238                   1              0        0  \n",
       "\n",
       "[239 rows x 37 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dfx = dfx.drop('abdomo_protein', axis = 1)\n",
    "# dfx[dfx['sogastric_reflux_ph'] != '4.707.547.169.811.320']\n",
    "dfx['cp_data'] = dfx['cp_data'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c868f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
