{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f5cf5a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lingam in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.9.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (1.5.0)\n",
      "Requirement already satisfied: graphviz in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (0.20.3)\n",
      "Requirement already satisfied: statsmodels in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (0.14.2)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (3.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (2.2.2)\n",
      "Requirement already satisfied: pygam in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (0.9.1)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (3.8.4)\n",
      "Requirement already satisfied: psy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (0.0.1)\n",
      "Requirement already satisfied: semopy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (2.3.11)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->lingam) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->lingam) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->lingam) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->lingam) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->lingam) (21.3)\n",
      "Requirement already satisfied: pillow>=8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->lingam) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->lingam) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->lingam) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->lingam) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->lingam) (2024.1)\n",
      "Requirement already satisfied: progressbar2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from psy->lingam) (4.4.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn->lingam) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn->lingam) (3.5.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from semopy->lingam) (1.12)\n",
      "Requirement already satisfied: numdifftools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from semopy->lingam) (0.9.41)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from statsmodels->lingam) (0.5.6)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from patsy>=0.5.6->statsmodels->lingam) (1.16.0)\n",
      "Requirement already satisfied: python-utils>=3.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from progressbar2->psy->lingam) (3.8.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->semopy->lingam) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>3.10.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-utils>=3.8.1->progressbar2->psy->lingam) (4.12.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lingam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37b54b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#German\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from csse import CSSE\n",
    "from prepare_dataset import *\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import graphviz\n",
    "import lingam\n",
    "from lingam.utils import print_causal_directions, print_dagc, make_dot\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random as rnd\n",
    "import ast\n",
    "from IPython.display import display\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b7584be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#German\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from csse import CSSE\n",
    "from prepare_dataset import *\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "import lingam\n",
    "from lingam.utils import print_causal_directions, print_dagc, make_dot\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random as rnd\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "class CCSSE:\n",
    "    def __init__(self, dataset, samples = None, K = 5, generation = 10, bb_model):\n",
    "        self.df_datasets = self.load_df_dataset()\n",
    "        self.dataset = dataset\n",
    "        self.samples = samples\n",
    "        self.K = K\n",
    "        self.generation = generation\n",
    "        \n",
    "#         self.x_train, self.x_test, self.y_train, self.y_test, self.dfx_full, self.dfy_full = self.get_datasets_train_test()\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test, self.dfx_full, self.dfy_full = self.get_dataset()\n",
    "\n",
    "        self.bb_model, self.p = self.get_bb_model(bb_model)\n",
    "        self.explainerCSSE = self.get_model_contrafactual()\n",
    "        self.model_causal, self.df_causal_effects, self.df_error, self.causal_order = self.get_model_causality()\n",
    "    \n",
    "        self.run_dict = {}\n",
    "        self.run_non_causal_dict = {}\n",
    "        \n",
    "    def load_df_dataset(self):\n",
    "        def convert_to_list(val):\n",
    "            try:\n",
    "                return ast.literal_eval(val) if isinstance(val, str) and val.startswith('[') and val.endswith(']') else val\n",
    "            except (ValueError, SyntaxError):\n",
    "                return val\n",
    "            \n",
    "        df = pd.read_parquet(\"datasets/df_map_inference_datasets.parquet\")\n",
    "        df['path'] = df['path'].apply(convert_to_list)\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "    def get_dataset(self):\n",
    "        dataset_dict = self.df_datasets[self.df_datasets['name'] == self.dataset].iloc[0].to_dict()\n",
    "        \n",
    "        if isinstance(dataset_dict['path'], list):\n",
    "            if 'Column' in dataset_dict['classe']:\n",
    "                df_train = pd.read_csv(f\"s3://omar-testes-gerais/artigos/artifacts/datasets/{dataset_dict['path'][0]}\", header = None)\n",
    "                df_test = pd.read_csv(f\"s3://omar-testes-gerais/artigos/artifacts/datasets/{dataset_dict['path'][1]}\", header = None)\n",
    "                class_name = int(dataset_dict['class'].split('Column')[1])\n",
    "            else:\n",
    "                df_train = pd.read_csv(f\"s3://omar-testes-gerais/artigos/artifacts/datasets/{dataset_dict['path'][0]}\")\n",
    "                df_test = pd.read_csv(f\"s3://omar-testes-gerais/artigos/artifacts/datasets/{dataset_dict['path'][1]}\")\n",
    "                class_name = dataset_dict['class']\n",
    "            \n",
    "            x_train = df_train.drop(columns=[class_column])\n",
    "            y_train = df_train[class_column]\n",
    "\n",
    "            # Dividindo o df_test\n",
    "            x_test = df_test.drop(columns=[class_column])\n",
    "            y_test = df_test[class_column]\n",
    "            \n",
    "            dfx_full = pd.concat([x_train, x_test])\n",
    "            dfy_full = pd.concat([y_train, y_test])\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            if 'Column' in dataset_dict['classe']:\n",
    "                df_main = pd.read_csv(f\"s3://omar-testes-gerais/artigos/artifacts/datasets/{dataset_dict['path']}\", header = None)\n",
    "                class_name = int(dataset_dict['classe'].split('Column')[1])\n",
    "            else:\n",
    "                df_main = pd.read_csv(f\"s3://omar-testes-gerais/artigos/artifacts/datasets/{dataset_dict['path']}\")\n",
    "                class_name = dataset_dict['classe']\n",
    "                \n",
    "            columns = df_main.columns\n",
    "            columns_tmp = list(columns)\n",
    "            columns_tmp.remove(class_name)\n",
    "\n",
    "            x_train, x_test, y_train, y_test = train_test_split(df_main[columns_tmp], df_main[class_name], test_size=0.1)\n",
    "\n",
    "            dfx_full = pd.concat([x_train, x_test])\n",
    "            dfy_full = pd.concat([y_train, y_test])\n",
    "            \n",
    "        return x_train, x_test, y_train, y_test, dfx_full, dfy_full\n",
    "    \n",
    "    def get_datasets_train_test(self):\n",
    "        if self.dataset == \"german_short\":\n",
    "            map_columns = {\n",
    "                'Unnamed: 0': 'index',\n",
    "                'x0': 'Sex',\n",
    "                'x1': 'Age',\n",
    "                'x2': 'Credit',\n",
    "                'x3': 'LoanDuration',\n",
    "            }\n",
    "            x_train = pd.read_csv(\"data/algrec_german/X_train_short.csv\").rename(columns = map_columns)\n",
    "            x_test = pd.read_csv(\"data/algrec_german/X_test_short.csv\").rename(columns = map_columns)\n",
    "            y_train = pd.read_csv(\"data/algrec_german/y_train_short.csv\").rename(columns={'Unnamed: 0': 'index'})\n",
    "            y_test = pd.read_csv(\"data/algrec_german/y_test_short.csv\").rename(columns={'Unnamed: 0': 'index'})\n",
    "            x_train = x_train.set_index('index')\n",
    "            x_test = x_test.set_index('index')\n",
    "            y_train = y_train.set_index('index')\n",
    "            y_test = y_test.set_index('index')\n",
    "            dfx_full = pd.concat([x_train, x_test])\n",
    "            dfy_full = pd.concat([y_train, y_test])\n",
    "\n",
    "        elif self.dataset == \"german_medium\":\n",
    "            map_columns = {\n",
    "                'Unnamed: 0': 'index',\n",
    "                'x0': 'Sex',\n",
    "                'x1': 'Age',\n",
    "                'x2': 'Credit',\n",
    "                'x3': 'LoanDuration',\n",
    "                'x4': 'CheckingAccountBalance',\n",
    "                'x5':'SavingsAccountBalance',\n",
    "                'x6':'HousingStatus'\n",
    "            }\n",
    "            x_train = pd.read_csv(\"data/algrec_german/X_train.csv\").rename(columns = map_columns)\n",
    "            x_test = pd.read_csv(\"data/algrec_german/X_test.csv\").rename(columns = map_columns)\n",
    "            y_train = pd.read_csv(\"data/algrec_german/y_train.csv\").rename(columns={'Unnamed: 0': 'index'})\n",
    "            y_test = pd.read_csv(\"data/algrec_german/y_test.csv\").rename(columns={'Unnamed: 0': 'index'})\n",
    "            x_train = x_train.set_index('index')\n",
    "            x_test = x_test.set_index('index')\n",
    "            y_train = y_train.set_index('index')\n",
    "            y_test = y_test.set_index('index')\n",
    "            dfx_full = pd.concat([x_train, x_test])\n",
    "            dfy_full = pd.concat([y_train, y_test])\n",
    "\n",
    "        elif self.dataset == \"german_full\":\n",
    "            df_main = prepare_german_dataset(\"german_credit.csv\", \"data/\")\n",
    "            columns = df_main.columns\n",
    "            class_name = 'default' # default = 0 = \"Good class\" / default = 1 = \"Bad class\" \n",
    "            columns_tmp = list(columns)\n",
    "            columns_tmp.remove(class_name)\n",
    "\n",
    "            x_train, x_test, y_train, y_test = train_test_split(df_main[columns_tmp], df_main[class_name], test_size=0.1)\n",
    "\n",
    "            dfx_full = pd.concat([x_train, x_test])\n",
    "            dfy_full = pd.concat([y_train, y_test])\n",
    "            \n",
    "        elif self.dataset == 'np':\n",
    "            df_main = pd.read_csv(\"data/breast_coimbra_np.csv\")\n",
    "            columns = df_main.columns\n",
    "            class_name = 'Classification' # default = 0 = \"Good class\" / default = 1 = \"Bad class\" \n",
    "            columns_tmp = list(columns)\n",
    "            columns_tmp.remove(class_name)\n",
    "\n",
    "            x_train, x_test, y_train, y_test = train_test_split(df_main[columns_tmp], df_main[class_name], test_size=0.1)\n",
    "\n",
    "            dfx_full = pd.concat([x_train, x_test])\n",
    "            dfy_full = pd.concat([y_train, y_test])\n",
    "            \n",
    "        elif self.dataset == 'nm':\n",
    "            df_main = pd.read_csv(\"data/heloc_dataset_v1_nm.csv\")\n",
    "            columns = df_main.columns\n",
    "            class_name = 'RiskPerformance' # default = 0 = \"Good class\" / default = 1 = \"Bad class\" \n",
    "            columns_tmp = list(columns)\n",
    "            columns_tmp.remove(class_name)\n",
    "\n",
    "            x_train, x_test, y_train, y_test = train_test_split(df_main[columns_tmp], df_main[class_name], test_size=0.1)\n",
    "\n",
    "            dfx_full = pd.concat([x_train, x_test])\n",
    "            dfy_full = pd.concat([y_train, y_test])\n",
    "            \n",
    "        elif self.dataset == 'cm':\n",
    "            df_main = pd.read_csv(\"data/house_votes_84_processada_cm.csv\")\n",
    "            columns = df_main.columns\n",
    "            class_name = 'Class Name' # default = 0 = \"Good class\" / default = 1 = \"Bad class\" \n",
    "            columns_tmp = list(columns)\n",
    "            columns_tmp.remove(class_name)\n",
    "\n",
    "            x_train, x_test, y_train, y_test = train_test_split(df_main[columns_tmp], df_main[class_name], test_size=0.1)\n",
    "\n",
    "            dfx_full = pd.concat([x_train, x_test])\n",
    "            dfy_full = pd.concat([y_train, y_test])\n",
    "            \n",
    "        elif self.dataset == 'ng':\n",
    "            df_main = pd.read_csv(\"data/ionosphere_ng.csv\")\n",
    "            columns = df_main.columns\n",
    "            class_name = 'target' # default = 0 = \"Good class\" / default = 1 = \"Bad class\" \n",
    "            columns_tmp = list(columns)\n",
    "            columns_tmp.remove(class_name)\n",
    "\n",
    "            x_train, x_test, y_train, y_test = train_test_split(df_main[columns_tmp], df_main[class_name], test_size=0.1)\n",
    "\n",
    "            dfx_full = pd.concat([x_train, x_test])\n",
    "            dfy_full = pd.concat([y_train, y_test])\n",
    "            \n",
    "        elif self.dataset == 'tokyo_ng':\n",
    "            df_main = pd.read_csv(\"data/Tokyo_ng.csv\").rename(columns = {'Unnamed: 44': 'class'})\n",
    "            columns = df_main.columns\n",
    "            class_name = 'class' # default = 0 = \"Good class\" / default = 1 = \"Bad class\" \n",
    "            columns_tmp = list(columns)\n",
    "            columns_tmp.remove(class_name)\n",
    "\n",
    "            x_train, x_test, y_train, y_test = train_test_split(df_main[columns_tmp], df_main[class_name], test_size=0.1)\n",
    "\n",
    "            dfx_full = pd.concat([x_train, x_test])\n",
    "            dfy_full = pd.concat([y_train, y_test])\n",
    "            \n",
    "        elif self.dataset == 'breast-cancer_ng':\n",
    "            df_main = pd.read_csv(\"data/breast-cancer_ng.csv\")\n",
    "            columns = df_main.columns\n",
    "            class_name = 'diagnosis' # default = 0 = \"Good class\" / default = 1 = \"Bad class\" \n",
    "            columns_tmp = list(columns)\n",
    "            columns_tmp.remove(class_name)\n",
    "\n",
    "            x_train, x_test, y_train, y_test = train_test_split(df_main[columns_tmp], df_main[class_name], test_size=0.1)\n",
    "\n",
    "            dfx_full = pd.concat([x_train, x_test])\n",
    "            dfy_full = pd.concat([y_train, y_test])\n",
    "        \n",
    "        elif self.dataset == 'cp':\n",
    "            df_train = pd.read_csv(\"data/monks-1_train_cp.csv\")\n",
    "\n",
    "            #Get the input features\n",
    "            columns = df_train.columns\n",
    "            class_name = 'Class' # default = 0 = \"Good class\" / default = 1 = \"Bad class\" \n",
    "            columns_tmp = list(columns)\n",
    "            columns_tmp.remove(class_name)\n",
    "            columns_tmp.remove('Id')\n",
    "\n",
    "            x_train = df_train[columns_tmp]\n",
    "            y_train = df_train[['Class']]\n",
    "\n",
    "            # x_train, x_test, y_train, y_test = train_test_split(df_main[columns_tmp], df_main[class_name], test_size=0.1)\n",
    "\n",
    "            model = RandomForestClassifier()  \n",
    "            model.fit(x_train, y_train)\n",
    "\n",
    "            df_test = pd.read_csv('data/monks-1_test_cp.csv')\n",
    "\n",
    "            #Get the input features\n",
    "            columns = df_test.columns\n",
    "            class_name = 'Class' # default = 0 = \"Good class\" / default = 1 = \"Bad class\" \n",
    "            columns_tmp = list(columns)\n",
    "            columns_tmp.remove(class_name)\n",
    "            columns_tmp.remove('Id')\n",
    "\n",
    "            x_test = df_test[columns_tmp]\n",
    "            y_test = df_test[['Class']]\n",
    "\n",
    "            dfx_full = pd.concat([x_train, x_test])\n",
    "            dfy_full = pd.concat([y_train, y_test])\n",
    "            \n",
    "        elif self.dataset == 'cg':\n",
    "            df_main = pd.read_csv(\"data/mushrooms_processada_cg.csv\")[:1000]\n",
    "            columns = df_main.columns\n",
    "            class_name = 'class' # default = 0 = \"Good class\" / default = 1 = \"Bad class\" \n",
    "            columns_tmp = list(columns)\n",
    "            columns_tmp.remove(class_name)\n",
    "\n",
    "            x_train, x_test, y_train, y_test = train_test_split(df_main[columns_tmp], df_main[class_name], test_size=0.1)\n",
    "\n",
    "            dfx_full = pd.concat([x_train, x_test])\n",
    "            dfy_full = pd.concat([y_train, y_test])\n",
    "            \n",
    "        elif self.dataset == 'Phishing_cg':\n",
    "            df_main = pd.read_csv(\"data/Phishing_cg.csv\")[2:1000].astype(float)\n",
    "            columns = df_main.columns\n",
    "            class_name = 'Class' # default = 0 = \"Good class\" / default = 1 = \"Bad class\" \n",
    "            columns_tmp = list(columns)\n",
    "            columns_tmp.remove(class_name)\n",
    "\n",
    "            x_train, x_test, y_train, y_test = train_test_split(df_main[columns_tmp], df_main[class_name], test_size=0.1)\n",
    "\n",
    "            dfx_full = pd.concat([x_train, x_test])\n",
    "            dfy_full = pd.concat([y_train, y_test])\n",
    "\n",
    "        else:\n",
    "            x_train = pd.DataFrame()\n",
    "            x_test = pd.DataFrame()\n",
    "            y_train = pd.DataFrame()\n",
    "            y_test = pd.DataFrame()\n",
    "            dfx_full = pd.DataFrame()\n",
    "            dfy_full = pd.DataFrame()\n",
    "\n",
    "        return x_train, x_test, y_train, y_test, dfx_full, dfy_full\n",
    "    \n",
    "\n",
    "    def get_bb_model(self, bb_model_name):\n",
    "        \n",
    "        if bb_model_name == 'rf':\n",
    "            bb_model = RandomForestClassifier()  \n",
    "            bb_model.fit(self.x_train, self.y_train)\n",
    "\n",
    "            p = bb_model.predict(self.x_test)\n",
    "\n",
    "            print(classification_report(self.y_test, p))\n",
    "\n",
    "            return bb_model, p\n",
    "        elif bb_model_name == 'rn':\n",
    "            pass\n",
    "\n",
    "    def get_model_contrafactual(self):\n",
    "        return CSSE(self.dfx_full, self.bb_model, K = self.K, num_gen = self.generation)\n",
    "\n",
    "    def get_model_causality(self):\n",
    "        model_causal = lingam.DirectLiNGAM()\n",
    "        model_causal.fit(self.dfx_full)\n",
    "            \n",
    "        labels = [f'{i}' for i in self.dfx_full.columns]\n",
    "        causal_order = [labels[x] for x in model_causal.causal_order_]\n",
    "        \n",
    "        matrix = model_causal.adjacency_matrix_\n",
    "        from_list = []\n",
    "        to_list = []\n",
    "        effect_list = []\n",
    "\n",
    "        # Iteração sobre a matriz para extrair os valores e suas posições\n",
    "        for i in range(len(matrix)):\n",
    "            for j in range(len(matrix[i])):\n",
    "                if matrix[i][j] != 0:\n",
    "                    from_list.append(j)\n",
    "                    to_list.append(i)\n",
    "                    effect_list.append(matrix[i][j])\n",
    "\n",
    "        # Criando o DataFrame\n",
    "        df_causal_effects = pd.DataFrame({'from': from_list, 'to': to_list, 'effect': effect_list})\n",
    "        labels = [f'{i}' for i in self.dfx_full.columns]\n",
    "        df_causal_effects['from'] = df_causal_effects['from'].apply(lambda x : labels[x])\n",
    "        df_causal_effects['to'] = df_causal_effects['to'].apply(lambda x : labels[x])\n",
    "\n",
    "\n",
    "        matrix_error = model_causal.get_error_independence_p_values(self.dfx_full)\n",
    "        from_list = []\n",
    "        to_list = []\n",
    "        effect_list = []\n",
    "\n",
    "        # Iteração sobre a matriz para extrair os valores e suas posições\n",
    "        for i in range(len(matrix_error)):\n",
    "            for j in range(i + 1, len(matrix_error[i])):\n",
    "                if matrix_error[i][j] != 0:\n",
    "                    from_list.append(j)\n",
    "                    to_list.append(i)\n",
    "                    effect_list.append(matrix_error[i][j])\n",
    "\n",
    "        # Criando o DataFrame\n",
    "        df_error = pd.DataFrame({'from': from_list, 'to': to_list, 'effect': effect_list})\n",
    "        labels = [f'{i}' for i in self.dfx_full.columns]\n",
    "        df_error['from'] = df_error['from'].apply(lambda x : labels[x])\n",
    "        df_error['to'] = df_error['to'].apply(lambda x : labels[x])\n",
    "        \n",
    "\n",
    "        return model_causal, df_causal_effects, df_error, causal_order\n",
    "        \n",
    "    \n",
    "    def print_causal_graph(self):\n",
    "        make_dot(self.model_causal.adjacency_matrix_)\n",
    "\n",
    "    def run_non_causal(self):\n",
    "        self.run_non_causal_dict = {}\n",
    "\n",
    "        if isinstance(self.samples, list):\n",
    "            self.create_run_dict(self)\n",
    "            for sample in self.samples:\n",
    "                self.run_non_causal_sample(sample)\n",
    "                \n",
    "        elif isinstance(self.samples, int):\n",
    "            for sample in range(self.samples):\n",
    "                self.run_non_causal_sample(sample)\n",
    "        \n",
    "        else: \n",
    "            for sample in range(10):\n",
    "                self.run_non_causal_sample(sample)\n",
    "                \n",
    "    def run_non_causal_sample(self, sample):\n",
    "        self.run_non_causal_dict[sample] = {}\n",
    "        original_instance = self.x_test.iloc[sample].copy()\n",
    "        contrafactual_set, solution = self.explainerCSSE.explain(original_instance, self.p[sample]) #Method returns the list of counterfactuals and the explanations generated from them\n",
    "\n",
    "        self.run_non_causal_dict[sample]['solution'] = solution\n",
    "\n",
    "    def run_causal(self):\n",
    "        start_time = time.time()\n",
    "        self.run_dict = {}\n",
    "        self.run_dict['global_numbers'] = {\n",
    "                    \"global_quant_changes\": 0,\n",
    "                    \"global_quant_causal_changes\": 0,\n",
    "                    \"global_quant_causal_rules\": 0,\n",
    "                    \"global_quant_zeros_causal\": 0,\n",
    "                    \"global_quant_full_causal\": 0,\n",
    "                    \"global_quant_causal_contrafac\": 0,\n",
    "                    \"global_quant_maioria_causal_satisfeita\": 0,\n",
    "                    \"global_quant_contrafac_unico\": 0,\n",
    "            }\n",
    "        self.global_quant_contrafac_max = 0\n",
    "        if isinstance(self.samples, list):\n",
    "            for sample in self.samples:\n",
    "                self.run_causal_sample(sample)\n",
    "                \n",
    "        elif isinstance(self.samples, int):\n",
    "            for sample in range(self.samples):\n",
    "                self.run_causal_sample(sample)\n",
    "        \n",
    "        else: \n",
    "            for sample in range(10):\n",
    "                self.run_causal_sample(sample)\n",
    "        \n",
    "        self.global_quant_contrafac_max = self.K * len(self.run_dict)\n",
    "        self.run_dict['global_numbers']['global_timing_run_causal'] = time.time() - start_time\n",
    "\n",
    "\n",
    "    def run_causal_sample(self, sample):\n",
    "        if isinstance(self.samples, list):\n",
    "            original_instance = self.dfx_full.iloc[sample]\n",
    "        else:\n",
    "            original_instance = self.x_test.iloc[sample]\n",
    "        self.run_dict[sample] = {}\n",
    "        self.run_dict[sample]['original_instance'] = original_instance\n",
    "\n",
    "        print(f'Running original instance:\\n {display(original_instance)}')\n",
    "\n",
    "        causal_explain = self.get_causal_explain(sample)\n",
    "        self.run_dict[sample]['causal_explain'] = causal_explain\n",
    "\n",
    "        list_analyse = []\n",
    "        for contrafactual in causal_explain[0]:\n",
    "            list_analyse.append(self.analyse_contrafac(contrafactual, causal_explain[1], causal_explain[2]))\n",
    "\n",
    "        self.run_dict[sample]['list_analyse'] = list_analyse\n",
    "        self.analyse_explaination(sample)\n",
    "\n",
    "    def analyse_contrafac(self, contrafac, df, original_ind):\n",
    "        columns = [x.column for x in contrafac]\n",
    "        condicao = (df['to'].isin(columns)) & (df['from'].isin(columns))\n",
    "        ind = original_ind[columns]\n",
    "        return [contrafac, df[condicao], ind]\n",
    "\n",
    "    def get_causal_explain(self, sample):\n",
    "        if isinstance(self.samples, list):\n",
    "            original_ind = self.dfx_full.iloc[sample].copy()\n",
    "        else:\n",
    "            original_ind = self.x_test.iloc[sample].copy() #Original instance\n",
    "        #self.ind_cur_class = ind_cur_class #Index in the shap corresponds to the original instance class\n",
    "        self.explainerCSSE.current_class = self.p[sample] #Original instance class\n",
    "        self.explainerCSSE.original_ind = original_ind\n",
    "        \n",
    "        ind_cur_class = self.explainerCSSE.getBadClass()\n",
    "\n",
    "        #Gets the valid values range of each feature\n",
    "        features_range = []\n",
    "        features_range = self.explainerCSSE.getFeaturesRange()\n",
    "\n",
    "        #The DataFrame df will have the current population\n",
    "        df = pd.DataFrame(columns=self.explainerCSSE.input_dataset.columns)\n",
    "\n",
    "        #Generates the initial population with popinitial mutants        \n",
    "        self.explainerCSSE.getPopInicial(df, features_range)\n",
    "        df_causal = df.copy()\n",
    "        dict_dfs = {}\n",
    "\n",
    "        # for g in tqdm(range(self.explainerCSSE.num_gen), desc= \"Processing...\"):\n",
    "        for g in tqdm(range(self.generation), desc= \"Processing...\"):\n",
    "\n",
    "            #To use on the parents of each generation\n",
    "            old_parents = pd.DataFrame(columns=self.explainerCSSE.input_dataset.columns)\n",
    "\n",
    "            #Copy parents to the next generation\n",
    "            old_parents = df_causal.copy()\n",
    "            dict_dfs[g] = {}\n",
    "\n",
    "            parents_causal = self.apply_causality(old_parents)\n",
    "            dict_dfs[g]['causal_parents'] = parents_causal\n",
    "            #df will contain the new population\n",
    "            df_causal = pd.DataFrame(columns=self.explainerCSSE.input_dataset.columns)\n",
    "            evaluation_causal = []\n",
    "\n",
    "            #Assessing generation counterfactuals\n",
    "            self.explainerCSSE.fitness(dict_dfs[g]['causal_parents'], evaluation_causal, ind_cur_class)\n",
    "\n",
    "            #The original individual will always be in the 0 position of the df - So that it is normalized too (it will be used later in the distance function)\n",
    "            df_causal.loc[0] = original_ind.copy()\n",
    "\n",
    "            #Copies to the next generation the per_elit best individuals\n",
    "            self.explainerCSSE.elitism(evaluation_causal, df_causal, parents_causal)\n",
    "            number_cross_repetitions = 0\n",
    "            while len(df_causal) < self.explainerCSSE.pop_size + 1: #+1, as the 1st position is used to store the reference individual\n",
    "                number_cross_repetitions_causal = self.explainerCSSE.crossover(df_causal, parents_causal, evaluation_causal, number_cross_repetitions)\n",
    "\n",
    "                mutation_op = rnd.random()\n",
    "                if mutation_op <= self.explainerCSSE.mutation_proba:\n",
    "                    self.explainerCSSE.mutation(df_causal, len(df_causal) - 1, features_range)\n",
    "\n",
    "\n",
    "        evaluation = []\n",
    "        evaluation_causal = []\n",
    "\n",
    "        #Evaluating the latest generation\n",
    "        self.explainerCSSE.fitness(df_causal, evaluation_causal, ind_cur_class)\n",
    "\n",
    "        #Order the last generation by distance to the original instance     \n",
    "        evaluation_causal.sort(key=lambda individual: individual.aval_norm) \n",
    "\n",
    "        #Getting the counterfactual CAUSAL set\n",
    "        contrafactual_set_causal, solution_list_causal = self.explainerCSSE.getContrafactual(df_causal, evaluation_causal) \n",
    "\n",
    "        dict_dfs['contrafactual_set_causal'] = contrafactual_set_causal\n",
    "        dict_dfs['solution_list_causal'] = solution_list_causal\n",
    "        \n",
    "        df_contrafac_causal = self.get_contrafac_df_causal(solution_list_causal)\n",
    "        return [solution_list_causal, df_contrafac_causal, original_ind]\n",
    "    \n",
    "\n",
    "    def apply_causality(self, df):\n",
    "        df_apply_causal = pd.DataFrame(columns = df.columns)\n",
    "        original = df.iloc[0]\n",
    "        df_apply_causal.loc[0] = original\n",
    "        for index, df_row in df.iloc[1:].iterrows():\n",
    "            causal_ind = df_row.copy()\n",
    "            for column in self.causal_order:\n",
    "                value_diff = causal_ind[column] - original[column]\n",
    "                if value_diff != 0:\n",
    "                    tmp_effects = self.df_causal_effects[self.df_causal_effects['from'] == column]\n",
    "                    for index, row in tmp_effects.iterrows():\n",
    "    #                     prob = rnd.random()\n",
    "    #                     if row['probability'] <= prob:\n",
    "                        tmp_error = self.df_error[self.df_error['from'].isin([column, row['to']]) | self.df_error['to'].isin([column, row['to']])]\n",
    "                        error_value = tmp_error['effect'].iloc[0]\n",
    "    #                     print(f'error value = {error_value}')\n",
    "                        causal_ind[row['to']] = causal_ind[row['to']] + (value_diff * row['effect']) + tmp_error['effect'].iloc[0]\n",
    "            df_apply_causal.loc[len(df_apply_causal)] = causal_ind\n",
    "        return df_apply_causal\n",
    "\n",
    "\n",
    "    def get_contrafac_df_causal(self, solution_list_causal):\n",
    "        lista_solution_causal = [[t.column for t in sublist] for sublist in solution_list_causal]\n",
    "\n",
    "        # Inicializa uma lista para armazenar os resultados\n",
    "        resultados = []\n",
    "\n",
    "        # Loop sobre os valores na lista\n",
    "        for lista_valores in lista_solution_causal:\n",
    "            if len(lista_valores) > 1:\n",
    "                for v1 in lista_valores:\n",
    "                    for v2 in lista_valores:\n",
    "                        if v1 != v2:\n",
    "                            # Cria uma condição para cada par de valores diferentes na lista\n",
    "                            condicao = (self.df_causal_effects['to'].isin([v1, v2])) & (self.df_causal_effects['from'].isin([v1, v2]))\n",
    "                            # Realiza a busca no DataFrame usando a condição e armazena os resultados\n",
    "                            resultados.append(self.df_causal_effects[condicao])\n",
    "\n",
    "        # Concatena os resultados em um único DataFrame\n",
    "        if resultados:\n",
    "            resultado_final = pd.concat(resultados)\n",
    "            resultado_final = resultado_final.drop_duplicates()\n",
    "        else:\n",
    "            resultado_final = pd.DataFrame(columns = self.df_causal_effects.columns)\n",
    "            \n",
    "        return resultado_final\n",
    "    \n",
    "\n",
    "    def analyse_explaination(self, sample):\n",
    "        self.run_dict[sample]['data_analysis'] = []\n",
    "        for i, content in enumerate(self.run_dict[sample]['list_analyse']):\n",
    "            self.global_quant_contrafac_max += 1\n",
    "            controle = {}\n",
    "            causal = content[0]\n",
    "            df = content[1]\n",
    "            ori = content[2]\n",
    "            \n",
    "            \n",
    "            num_changes = len(causal)\n",
    "            self.run_dict['global_numbers']['global_quant_changes'] += num_changes\n",
    "            \n",
    "            num_causal_rules = len(df)\n",
    "            self.run_dict['global_numbers']['global_quant_causal_rules'] += num_causal_rules\n",
    "            \n",
    "            for attr in causal:\n",
    "                key = attr.column\n",
    "                if attr.value > ori[key]:\n",
    "                    controle[key] = 'mais'\n",
    "                else:\n",
    "                    controle[key] = 'menos'\n",
    "\n",
    "            df_temp = df.copy()\n",
    "            df_temp['from'] = df['from'].map(controle)\n",
    "            df_temp['to'] = df['to'].map(controle)\n",
    "            df_temp['causal'] = df_temp.apply(self.verificar_condicoes, axis = 1)\n",
    "            data_dict = {}\n",
    "\n",
    "            data_dict['df_respeita_causal'] = df_temp\n",
    "            data_dict['contrafactual_causal'] = causal\n",
    "            data_dict['df_causal_effects'] = df\n",
    "            \n",
    "            self.run_dict[sample]['data_analysis'].append(data_dict)\n",
    "\n",
    "\n",
    "            causal_finds = df_temp['causal'].sum()\n",
    "            self.run_dict['global_numbers']['global_quant_causal_changes'] += causal_finds\n",
    "            \n",
    "            # print(f'causal = \\n{causal}\\n')\n",
    "            # print(f'original = \\n{ori}\\n')\n",
    "            # print(f'df_temp = \\n{display(df_temp)}\\n')\n",
    "            \n",
    "            if len(df_temp) > 0:\n",
    "                if causal_finds > 0:\n",
    "                    self.run_dict['global_numbers']['global_quant_causal_contrafac'] += 1\n",
    "                else:\n",
    "                    # print(f'nenhuma relaçao causal satisfeita')\n",
    "                    self.run_dict['global_numbers']['global_quant_zeros_causal'] += 1\n",
    "    #                 display(df_temp)\n",
    "    #                 print(f\"original = {ori}\")\n",
    "    #                 print(f\"causal = {causal}\")\n",
    "\n",
    "                if causal_finds == num_causal_rules:\n",
    "                    self.run_dict['global_numbers']['global_quant_full_causal'] += 1\n",
    "                    # if causal_finds > 2:\n",
    "                        # print(f'todas > 2 relaçoes causais satisfeitas')\n",
    "    #                     display(df_temp)\n",
    "    #                     print(f\"original = {ori}\")\n",
    "    #                     print(f\"causal = {causal}\")\n",
    "                    # elif causal_finds == 1:\n",
    "                        # print(f'todas = 1 relaçoes causais satisfeitas')\n",
    "                \n",
    "                if causal_finds >= (len(df_temp)/2):\n",
    "                    self.run_dict['global_numbers']['global_quant_maioria_causal_satisfeita'] += 1\n",
    "            else:\n",
    "    #             if len(causal) > 0:\n",
    "                self.run_dict['global_numbers']['global_quant_contrafac_unico'] += 1\n",
    "        \n",
    "    def verificar_condicoes(self, row):\n",
    "        if (row['from'] == 'mais' and row['to'] == 'mais' and row['effect'] > 0):\n",
    "            return True\n",
    "        elif row['from'] == 'menos' and row['to'] == 'menos' and row['effect'] > 0:\n",
    "            return True\n",
    "        elif row['from'] == 'mais' and row['to'] == 'menos' and row['effect'] < 0:\n",
    "            return True\n",
    "        elif row['from'] == 'menos' and row['to'] == 'mais' and row['effect'] < 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "            \n",
    "\n",
    "    def show_metrics(self, get_output = False):\n",
    "        \n",
    "        print(f\"Quantidade de instâncias contrafactuais = {self.global_quant_contrafac_max}\")\n",
    "        print(f'Quantidade de relações causais na base de dados = {len(self.df_causal_effects)}')\n",
    "        print(f\"Quantidade de atributos modificados = {self.run_dict['global_numbers']['global_quant_changes']}\")\n",
    "        print(f\"Quantidade de instâncias contrafactuais causais = {self.run_dict['global_numbers']['global_quant_contrafac_unico'] + self.run_dict['global_numbers']['global_quant_causal_contrafac']}\")\n",
    "        print(f\"Quantidade de relações causais analisadas = {self.run_dict['global_numbers']['global_quant_causal_rules']}\")\n",
    "        print(f\"Quantidade de relações causais satisfeitas = {self.run_dict['global_numbers']['global_quant_causal_changes']}\")\n",
    "        print(f\"Quantidade de instâncias contrafactuais com um único atributo modificado = {self.run_dict['global_numbers']['global_quant_contrafac_unico']}\")\n",
    "        print(f\"Tempo de execução = {self.run_dict['global_numbers']['global_timing_run_causal']}\")\n",
    "        \n",
    "        if get_output:\n",
    "            metrics_dict = {\n",
    "                \"Quantidade de instâncias contrafactuais\": self.global_quant_contrafac_max,\n",
    "                \"Quantidade de relações causais na base de dados\": len(self.df_causal_effects),\n",
    "                \"Quantidade de atributos modificados\": self.run_dict['global_numbers']['global_quant_changes'],\n",
    "                \"Quantidade de instâncias contrafactuais causais\": self.run_dict['global_numbers']['global_quant_contrafac_unico'] + self.run_dict['global_numbers']['global_quant_causal_contrafac'],\n",
    "                \"Quantidade de relações causais analisadas\": self.run_dict['global_numbers']['global_quant_causal_rules'],\n",
    "                \"Quantidade de relações causais satisfeitas\": self.run_dict['global_numbers']['global_quant_causal_changes'],\n",
    "                \"Quantidade de instâncias contrafactuais com um único atributo modificado\": self.run_dict['global_numbers']['global_quant_contrafac_unico'],\n",
    "                \"Tempo de execução\": self.run_dict['global_numbers']['global_timing_run_causal']\n",
    "            }\n",
    "        \n",
    "            return metrics_dict\n",
    "              \n",
    "              \n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6be25a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'path', 'classe'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_map_inference_datasets = pd.read_parquet(\"datasets/df_map_inference_datasets.parquet\")\n",
    "df_map_inference_datasets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e512b0be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                           Adult\n",
      "path      adult/adult_processada.csv\n",
      "classe               Above/Below 50K\n",
      "Name: 0, dtype: object\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.88      0.92      0.90      3741\n",
      "        >50K       0.70      0.60      0.65      1144\n",
      "\n",
      "    accuracy                           0.85      4885\n",
      "   macro avg       0.79      0.76      0.77      4885\n",
      "weighted avg       0.84      0.85      0.84      4885\n",
      "\n",
      "name                                   Australian\n",
      "path      Australian/Credit_Card_Applications.csv\n",
      "classe                                      Class\n",
      "Name: 1, dtype: object\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93        42\n",
      "           1       0.96      0.81      0.88        27\n",
      "\n",
      "    accuracy                           0.91        69\n",
      "   macro avg       0.92      0.90      0.91        69\n",
      "weighted avg       0.92      0.91      0.91        69\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomerID    15657228.00\n",
       "A1                   1.00\n",
       "A2                  21.42\n",
       "A3                   0.75\n",
       "A4                   1.00\n",
       "A5                  12.00\n",
       "A6                   7.00\n",
       "A7                   0.75\n",
       "A8                   0.00\n",
       "A9                   0.00\n",
       "A10                  0.00\n",
       "A11                  1.00\n",
       "A12                  2.00\n",
       "A13                132.00\n",
       "A14                  3.00\n",
       "Name: 510, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:11<00:00,  1.15s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomerID    15697460.00\n",
       "A1                   1.00\n",
       "A2                  22.00\n",
       "A3                   0.79\n",
       "A4                   2.00\n",
       "A5                   9.00\n",
       "A6                   4.00\n",
       "A7                   0.29\n",
       "A8                   0.00\n",
       "A9                   1.00\n",
       "A10                  1.00\n",
       "A11                  0.00\n",
       "A12                  2.00\n",
       "A13                420.00\n",
       "A14                284.00\n",
       "Name: 125, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:12<00:00,  1.23s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomerID    15656417.00\n",
       "A1                   1.00\n",
       "A2                  40.58\n",
       "A3                   1.50\n",
       "A4                   2.00\n",
       "A5                   3.00\n",
       "A6                   5.00\n",
       "A7                   0.00\n",
       "A8                   0.00\n",
       "A9                   0.00\n",
       "A10                  0.00\n",
       "A11                  0.00\n",
       "A12                  1.00\n",
       "A13                300.00\n",
       "A14                  1.00\n",
       "Name: 579, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:12<00:00,  1.29s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomerID    1.572150e+07\n",
       "A1            0.000000e+00\n",
       "A2            2.450000e+01\n",
       "A3            2.415000e+00\n",
       "A4            1.000000e+00\n",
       "A5            8.000000e+00\n",
       "A6            4.000000e+00\n",
       "A7            0.000000e+00\n",
       "A8            0.000000e+00\n",
       "A9            0.000000e+00\n",
       "A10           0.000000e+00\n",
       "A11           0.000000e+00\n",
       "A12           2.000000e+00\n",
       "A13           1.200000e+02\n",
       "A14           1.000000e+00\n",
       "Name: 556, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:11<00:00,  1.19s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomerID    1.574046e+07\n",
       "A1            1.000000e+00\n",
       "A2            2.333000e+01\n",
       "A3            1.162500e+01\n",
       "A4            1.000000e+00\n",
       "A5            9.000000e+00\n",
       "A6            4.000000e+00\n",
       "A7            8.350000e-01\n",
       "A8            1.000000e+00\n",
       "A9            0.000000e+00\n",
       "A10           0.000000e+00\n",
       "A11           1.000000e+00\n",
       "A12           2.000000e+00\n",
       "A13           1.600000e+02\n",
       "A14           3.010000e+02\n",
       "Name: 184, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:13<00:00,  1.38s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomerID    15789014.00\n",
       "A1                   1.00\n",
       "A2                  27.58\n",
       "A3                   2.04\n",
       "A4                   1.00\n",
       "A5                   6.00\n",
       "A6                   4.00\n",
       "A7                   2.00\n",
       "A8                   1.00\n",
       "A9                   1.00\n",
       "A10                  3.00\n",
       "A11                  1.00\n",
       "A12                  2.00\n",
       "A13                370.00\n",
       "A14                561.00\n",
       "Name: 490, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:13<00:00,  1.37s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomerID    1.567101e+07\n",
       "A1            0.000000e+00\n",
       "A2            2.533000e+01\n",
       "A3            2.085000e+00\n",
       "A4            2.000000e+00\n",
       "A5            8.000000e+00\n",
       "A6            8.000000e+00\n",
       "A7            2.750000e+00\n",
       "A8            1.000000e+00\n",
       "A9            0.000000e+00\n",
       "A10           0.000000e+00\n",
       "A11           1.000000e+00\n",
       "A12           2.000000e+00\n",
       "A13           3.600000e+02\n",
       "A14           2.000000e+00\n",
       "Name: 203, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:11<00:00,  1.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomerID    1.556816e+07\n",
       "A1            0.000000e+00\n",
       "A2            1.950000e+01\n",
       "A3            1.650000e-01\n",
       "A4            2.000000e+00\n",
       "A5            1.100000e+01\n",
       "A6            4.000000e+00\n",
       "A7            4.000000e-02\n",
       "A8            0.000000e+00\n",
       "A9            0.000000e+00\n",
       "A10           0.000000e+00\n",
       "A11           1.000000e+00\n",
       "A12           2.000000e+00\n",
       "A13           3.800000e+02\n",
       "A14           1.000000e+00\n",
       "Name: 66, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:12<00:00,  1.23s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomerID    1.566868e+07\n",
       "A1            0.000000e+00\n",
       "A2            4.742000e+01\n",
       "A3            3.000000e+00\n",
       "A4            2.000000e+00\n",
       "A5            1.400000e+01\n",
       "A6            4.000000e+00\n",
       "A7            1.387500e+01\n",
       "A8            1.000000e+00\n",
       "A9            1.000000e+00\n",
       "A10           2.000000e+00\n",
       "A11           1.000000e+00\n",
       "A12           2.000000e+00\n",
       "A13           5.190000e+02\n",
       "A14           1.705000e+03\n",
       "Name: 39, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:13<00:00,  1.32s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomerID    15570990.00\n",
       "A1                   1.00\n",
       "A2                  29.42\n",
       "A3                   1.25\n",
       "A4                   2.00\n",
       "A5                   8.00\n",
       "A6                   8.00\n",
       "A7                   0.25\n",
       "A8                   0.00\n",
       "A9                   1.00\n",
       "A10                  2.00\n",
       "A11                  1.00\n",
       "A12                  2.00\n",
       "A13                400.00\n",
       "A14                109.00\n",
       "Name: 208, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:12<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de instâncias contrafactuais = 110\n",
      "Quantidade de relações causais na base de dados = 25\n",
      "Quantidade de atributos modificados = 32\n",
      "Quantidade de instâncias contrafactuais causais = 17\n",
      "Quantidade de relações causais analisadas = 14\n",
      "Quantidade de relações causais satisfeitas = 13.0\n",
      "Quantidade de instâncias contrafactuais com um único atributo modificado = 11\n",
      "name                                  Banknote\n",
      "path      Banknote/BankNote_Authentication.csv\n",
      "classe                                   class\n",
      "Name: 2, dtype: object\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        70\n",
      "           1       0.99      1.00      0.99        68\n",
      "\n",
      "    accuracy                           0.99       138\n",
      "   macro avg       0.99      0.99      0.99       138\n",
      "weighted avg       0.99      0.99      0.99       138\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "variance   -0.27802\n",
       "skewness    8.18810\n",
       "curtosis   -3.13380\n",
       "entropy    -2.52760\n",
       "Name: 588, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:13<00:00,  1.37s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "variance   -1.6386\n",
       "skewness    3.3584\n",
       "curtosis   -1.7302\n",
       "entropy    -3.5646\n",
       "Name: 1135, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "variance    0.32230\n",
       "skewness   -0.89808\n",
       "curtosis    8.08830\n",
       "entropy     0.69222\n",
       "Name: 283, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "variance    3.89620\n",
       "skewness   -4.79040\n",
       "curtosis    3.39540\n",
       "entropy    -0.53751\n",
       "Name: 577, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "variance   -5.38570\n",
       "skewness    9.12140\n",
       "curtosis   -0.41929\n",
       "entropy    -5.91810\n",
       "Name: 1347, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "variance   -1.27860\n",
       "skewness   -2.40870\n",
       "curtosis    4.57350\n",
       "entropy     0.47627\n",
       "Name: 936, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "variance    2.161600\n",
       "skewness   -6.880400\n",
       "curtosis    8.151700\n",
       "entropy    -0.081048\n",
       "Name: 97, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "variance   -3.22380\n",
       "skewness    2.79350\n",
       "curtosis    0.32274\n",
       "entropy    -0.86078\n",
       "Name: 799, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "variance   -4.28590\n",
       "skewness    8.52340\n",
       "curtosis    3.13920\n",
       "entropy    -0.91639\n",
       "Name: 349, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "variance   -7.03640\n",
       "skewness    9.29310\n",
       "curtosis    0.16594\n",
       "entropy    -4.53960\n",
       "Name: 1294, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de instâncias contrafactuais = 110\n",
      "Quantidade de relações causais na base de dados = 6\n",
      "Quantidade de atributos modificados = 37\n",
      "Quantidade de instâncias contrafactuais causais = 16\n",
      "Quantidade de relações causais analisadas = 28\n",
      "Quantidade de relações causais satisfeitas = 18.0\n",
      "Quantidade de instâncias contrafactuais com um único atributo modificado = 5\n",
      "name                      Biodeg\n",
      "path      Biodeg/qsar-biodeg.csv\n",
      "classe                     Class\n",
      "Name: 3, dtype: object\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.97      0.90        66\n",
      "           2       0.93      0.70      0.80        40\n",
      "\n",
      "    accuracy                           0.87       106\n",
      "   macro avg       0.89      0.83      0.85       106\n",
      "weighted avg       0.88      0.87      0.86       106\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "V1      4.8070\n",
       "V2      3.2486\n",
       "V3      0.0000\n",
       "V4      0.0000\n",
       "V5      0.0000\n",
       "V6      0.0000\n",
       "V7      3.0000\n",
       "V8     42.1000\n",
       "V9      2.0000\n",
       "V10     1.0000\n",
       "V11     0.0000\n",
       "V12     0.0000\n",
       "V13     3.1000\n",
       "V14     0.8810\n",
       "V15     9.8330\n",
       "V16     3.0000\n",
       "V17     0.9870\n",
       "V18     1.1200\n",
       "V19     0.0000\n",
       "V20     0.0000\n",
       "V21     0.0000\n",
       "V22     1.2720\n",
       "V23     1.0000\n",
       "V24     0.0000\n",
       "V25     0.0000\n",
       "V26     0.0000\n",
       "V27     2.2460\n",
       "V28    -0.0240\n",
       "V29     0.0000\n",
       "V30     0.0000\n",
       "V31     1.0600\n",
       "V32     0.0000\n",
       "V33     1.0000\n",
       "V34     0.0000\n",
       "V35     1.0000\n",
       "V36     3.7100\n",
       "V37     2.3330\n",
       "V38     0.0000\n",
       "V39     8.1140\n",
       "V40     0.0000\n",
       "V41     0.0000\n",
       "Name: 61, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...:   0%|          | 0/10 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                         Breast Cancer Coimbra\n",
      "path      Breast Cancer Coimbra/breast_coimbra.csv\n",
      "classe                              Classification\n",
      "Name: 4, dtype: object\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.33      0.40         3\n",
      "           2       0.80      0.89      0.84         9\n",
      "\n",
      "    accuracy                           0.75        12\n",
      "   macro avg       0.65      0.61      0.62        12\n",
      "weighted avg       0.72      0.75      0.73        12\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age             38.000000\n",
       "BMI             22.499637\n",
       "Glucose         95.000000\n",
       "Insulin          5.261000\n",
       "HOMA             1.232828\n",
       "Leptin           8.438000\n",
       "Adiponectin      4.771920\n",
       "Resistin        15.736060\n",
       "MCP.1          199.055000\n",
       "Name: 60, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age              48.00000\n",
       "BMI              28.12500\n",
       "Glucose          90.00000\n",
       "Insulin           2.54000\n",
       "HOMA              0.56388\n",
       "Leptin           15.53250\n",
       "Adiponectin      10.22231\n",
       "Resistin         16.11032\n",
       "MCP.1          1698.44000\n",
       "Name: 86, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age             69.000000\n",
       "BMI             21.513859\n",
       "Glucose        112.000000\n",
       "Insulin          6.683000\n",
       "HOMA             1.846290\n",
       "Leptin          32.580000\n",
       "Adiponectin      4.138025\n",
       "Resistin        15.698760\n",
       "MCP.1          713.239000\n",
       "Name: 61, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age             46.000000\n",
       "BMI             20.830000\n",
       "Glucose         88.000000\n",
       "Insulin          3.420000\n",
       "HOMA             0.742368\n",
       "Leptin          12.870000\n",
       "Adiponectin     18.550000\n",
       "Resistin        13.560000\n",
       "MCP.1          301.210000\n",
       "Name: 68, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age             66.000000\n",
       "BMI             36.212279\n",
       "Glucose        101.000000\n",
       "Insulin         15.533000\n",
       "HOMA             3.869788\n",
       "Leptin          74.706900\n",
       "Adiponectin      7.539550\n",
       "Resistin        22.320240\n",
       "MCP.1          864.968000\n",
       "Name: 30, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age             49.000000\n",
       "BMI             21.367521\n",
       "Glucose         78.000000\n",
       "Insulin          2.640000\n",
       "HOMA             0.507936\n",
       "Leptin           6.333900\n",
       "Adiponectin      3.886145\n",
       "Resistin        22.942540\n",
       "MCP.1          737.672000\n",
       "Name: 62, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age             82.000000\n",
       "BMI             31.217482\n",
       "Glucose        100.000000\n",
       "Insulin         18.077000\n",
       "HOMA             4.458993\n",
       "Leptin          31.645300\n",
       "Adiponectin      9.923650\n",
       "Resistin        19.946870\n",
       "MCP.1          994.316000\n",
       "Name: 91, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:10<00:00,  1.05s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age             42.000000\n",
       "BMI             21.359915\n",
       "Glucose         93.000000\n",
       "Insulin          2.999000\n",
       "HOMA             0.687971\n",
       "Leptin          19.082600\n",
       "Adiponectin      8.462915\n",
       "Resistin        17.376150\n",
       "MCP.1          321.919000\n",
       "Name: 56, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age             34.000000\n",
       "BMI             31.975015\n",
       "Glucose         87.000000\n",
       "Insulin          4.530000\n",
       "HOMA             0.972138\n",
       "Leptin          28.750200\n",
       "Adiponectin      7.642760\n",
       "Resistin         5.625920\n",
       "MCP.1          572.783000\n",
       "Name: 21, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:11<00:00,  1.11s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Age             66.000000\n",
       "BMI             26.562500\n",
       "Glucose         89.000000\n",
       "Insulin          6.524000\n",
       "HOMA             1.432235\n",
       "Leptin          14.908400\n",
       "Adiponectin      8.429960\n",
       "Resistin        14.919220\n",
       "MCP.1          269.487000\n",
       "Name: 101, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:10<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de instâncias contrafactuais = 110\n",
      "Quantidade de relações causais na base de dados = 12\n",
      "Quantidade de atributos modificados = 51\n",
      "Quantidade de instâncias contrafactuais causais = 29\n",
      "Quantidade de relações causais analisadas = 19\n",
      "Quantidade de relações causais satisfeitas = 16.0\n",
      "Quantidade de instâncias contrafactuais com um único atributo modificado = 16\n",
      "name                        Breast Cancer Wisconsin\n",
      "path      Breast Cancer Wisconsin/breast-cancer.csv\n",
      "classe                                    diagnosis\n",
      "Name: 5, dtype: object\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.94      1.00      0.97        32\n",
      "           M       1.00      0.92      0.96        25\n",
      "\n",
      "    accuracy                           0.96        57\n",
      "   macro avg       0.97      0.96      0.96        57\n",
      "weighted avg       0.97      0.96      0.96        57\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                         894326.000000\n",
       "radius_mean                    18.220000\n",
       "texture_mean                   18.870000\n",
       "perimeter_mean                118.700000\n",
       "area_mean                    1027.000000\n",
       "smoothness_mean                 0.097460\n",
       "compactness_mean                0.111700\n",
       "concavity_mean                  0.113000\n",
       "concave points_mean             0.079500\n",
       "symmetry_mean                   0.180700\n",
       "fractal_dimension_mean          0.056640\n",
       "radius_se                       0.404100\n",
       "texture_se                      0.550300\n",
       "perimeter_se                    2.547000\n",
       "area_se                        48.900000\n",
       "smoothness_se                   0.004821\n",
       "compactness_se                  0.016590\n",
       "concavity_se                    0.024080\n",
       "concave points_se               0.011430\n",
       "symmetry_se                     0.012750\n",
       "fractal_dimension_se            0.002451\n",
       "radius_worst                   21.840000\n",
       "texture_worst                  25.000000\n",
       "perimeter_worst               140.900000\n",
       "area_worst                   1485.000000\n",
       "smoothness_worst                0.143400\n",
       "compactness_worst               0.276300\n",
       "concavity_worst                 0.385300\n",
       "concave points_worst            0.177600\n",
       "symmetry_worst                  0.281200\n",
       "fractal_dimension_worst         0.081980\n",
       "Name: 317, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [01:51<00:00, 11.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                         904357.000000\n",
       "radius_mean                    11.800000\n",
       "texture_mean                   17.260000\n",
       "perimeter_mean                 75.260000\n",
       "area_mean                     431.900000\n",
       "smoothness_mean                 0.090870\n",
       "compactness_mean                0.062320\n",
       "concavity_mean                  0.028530\n",
       "concave points_mean             0.016380\n",
       "symmetry_mean                   0.184700\n",
       "fractal_dimension_mean          0.060190\n",
       "radius_se                       0.343800\n",
       "texture_se                      1.140000\n",
       "perimeter_se                    2.225000\n",
       "area_se                        25.060000\n",
       "smoothness_se                   0.005463\n",
       "compactness_se                  0.019640\n",
       "concavity_se                    0.020790\n",
       "concave points_se               0.005398\n",
       "symmetry_se                     0.014770\n",
       "fractal_dimension_se            0.003071\n",
       "radius_worst                   13.450000\n",
       "texture_worst                  24.490000\n",
       "perimeter_worst                86.000000\n",
       "area_worst                    562.000000\n",
       "smoothness_worst                0.124400\n",
       "compactness_worst               0.172600\n",
       "concavity_worst                 0.144900\n",
       "concave points_worst            0.053560\n",
       "symmetry_worst                  0.277900\n",
       "fractal_dimension_worst         0.081210\n",
       "Name: 399, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:55<00:00,  5.57s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                         911202.000000\n",
       "radius_mean                    12.620000\n",
       "texture_mean                   17.150000\n",
       "perimeter_mean                 80.620000\n",
       "area_mean                     492.900000\n",
       "smoothness_mean                 0.085830\n",
       "compactness_mean                0.054300\n",
       "concavity_mean                  0.029660\n",
       "concave points_mean             0.022720\n",
       "symmetry_mean                   0.179900\n",
       "fractal_dimension_mean          0.058260\n",
       "radius_se                       0.169200\n",
       "texture_se                      0.667400\n",
       "perimeter_se                    1.116000\n",
       "area_se                        13.320000\n",
       "smoothness_se                   0.003888\n",
       "compactness_se                  0.008539\n",
       "concavity_se                    0.012560\n",
       "concave points_se               0.006888\n",
       "symmetry_se                     0.016080\n",
       "fractal_dimension_se            0.001638\n",
       "radius_worst                   14.340000\n",
       "texture_worst                  22.150000\n",
       "perimeter_worst                91.620000\n",
       "area_worst                    633.500000\n",
       "smoothness_worst                0.122500\n",
       "compactness_worst               0.151700\n",
       "concavity_worst                 0.188700\n",
       "concave points_worst            0.098510\n",
       "symmetry_worst                  0.327000\n",
       "fractal_dimension_worst         0.073300\n",
       "Name: 454, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:59<00:00,  5.96s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                         884689.000000\n",
       "radius_mean                    11.520000\n",
       "texture_mean                   14.930000\n",
       "perimeter_mean                 73.870000\n",
       "area_mean                     406.300000\n",
       "smoothness_mean                 0.101300\n",
       "compactness_mean                0.078080\n",
       "concavity_mean                  0.043280\n",
       "concave points_mean             0.029290\n",
       "symmetry_mean                   0.188300\n",
       "fractal_dimension_mean          0.061680\n",
       "radius_se                       0.256200\n",
       "texture_se                      1.038000\n",
       "perimeter_se                    1.686000\n",
       "area_se                        18.620000\n",
       "smoothness_se                   0.006662\n",
       "compactness_se                  0.012280\n",
       "concavity_se                    0.021050\n",
       "concave points_se               0.010060\n",
       "symmetry_se                     0.016770\n",
       "fractal_dimension_se            0.002784\n",
       "radius_worst                   12.650000\n",
       "texture_worst                  21.190000\n",
       "perimeter_worst                80.880000\n",
       "area_worst                    491.800000\n",
       "smoothness_worst                0.138900\n",
       "compactness_worst               0.158200\n",
       "concavity_worst                 0.180400\n",
       "concave points_worst            0.096080\n",
       "symmetry_worst                  0.266400\n",
       "fractal_dimension_worst         0.078090\n",
       "Name: 249, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [01:03<00:00,  6.32s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                         886452.000000\n",
       "radius_mean                    13.960000\n",
       "texture_mean                   17.050000\n",
       "perimeter_mean                 91.430000\n",
       "area_mean                     602.400000\n",
       "smoothness_mean                 0.109600\n",
       "compactness_mean                0.127900\n",
       "concavity_mean                  0.097890\n",
       "concave points_mean             0.052460\n",
       "symmetry_mean                   0.190800\n",
       "fractal_dimension_mean          0.061300\n",
       "radius_se                       0.425000\n",
       "texture_se                      0.809800\n",
       "perimeter_se                    2.563000\n",
       "area_se                        35.740000\n",
       "smoothness_se                   0.006351\n",
       "compactness_se                  0.026790\n",
       "concavity_se                    0.031190\n",
       "concave points_se               0.013420\n",
       "symmetry_se                     0.020620\n",
       "fractal_dimension_se            0.002695\n",
       "radius_worst                   16.390000\n",
       "texture_worst                  22.070000\n",
       "perimeter_worst               108.100000\n",
       "area_worst                    826.000000\n",
       "smoothness_worst                0.151200\n",
       "compactness_worst               0.326200\n",
       "concavity_worst                 0.320900\n",
       "concave points_worst            0.137400\n",
       "symmetry_worst                  0.306800\n",
       "fractal_dimension_worst         0.079570\n",
       "Name: 255, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:34<00:00,  3.41s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                         92751.000000\n",
       "radius_mean                    7.760000\n",
       "texture_mean                  24.540000\n",
       "perimeter_mean                47.920000\n",
       "area_mean                    181.000000\n",
       "smoothness_mean                0.052630\n",
       "compactness_mean               0.043620\n",
       "concavity_mean                 0.000000\n",
       "concave points_mean            0.000000\n",
       "symmetry_mean                  0.158700\n",
       "fractal_dimension_mean         0.058840\n",
       "radius_se                      0.385700\n",
       "texture_se                     1.428000\n",
       "perimeter_se                   2.548000\n",
       "area_se                       19.150000\n",
       "smoothness_se                  0.007189\n",
       "compactness_se                 0.004660\n",
       "concavity_se                   0.000000\n",
       "concave points_se              0.000000\n",
       "symmetry_se                    0.026760\n",
       "fractal_dimension_se           0.002783\n",
       "radius_worst                   9.456000\n",
       "texture_worst                 30.370000\n",
       "perimeter_worst               59.160000\n",
       "area_worst                   268.600000\n",
       "smoothness_worst               0.089960\n",
       "compactness_worst              0.064440\n",
       "concavity_worst                0.000000\n",
       "concave points_worst           0.000000\n",
       "symmetry_worst                 0.287100\n",
       "fractal_dimension_worst        0.070390\n",
       "Name: 568, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:56<00:00,  5.61s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                         8.810465e+08\n",
       "radius_mean                2.058000e+01\n",
       "texture_mean               2.214000e+01\n",
       "perimeter_mean             1.347000e+02\n",
       "area_mean                  1.290000e+03\n",
       "smoothness_mean            9.090000e-02\n",
       "compactness_mean           1.348000e-01\n",
       "concavity_mean             1.640000e-01\n",
       "concave points_mean        9.561000e-02\n",
       "symmetry_mean              1.765000e-01\n",
       "fractal_dimension_mean     5.024000e-02\n",
       "radius_se                  8.601000e-01\n",
       "texture_se                 1.480000e+00\n",
       "perimeter_se               7.029000e+00\n",
       "area_se                    1.117000e+02\n",
       "smoothness_se              8.124000e-03\n",
       "compactness_se             3.611000e-02\n",
       "concavity_se               5.489000e-02\n",
       "concave points_se          2.765000e-02\n",
       "symmetry_se                3.176000e-02\n",
       "fractal_dimension_se       2.365000e-03\n",
       "radius_worst               2.324000e+01\n",
       "texture_worst              2.784000e+01\n",
       "perimeter_worst            1.583000e+02\n",
       "area_worst                 1.656000e+03\n",
       "smoothness_worst           1.178000e-01\n",
       "compactness_worst          2.920000e-01\n",
       "concavity_worst            3.861000e-01\n",
       "concave points_worst       1.920000e-01\n",
       "symmetry_worst             2.909000e-01\n",
       "fractal_dimension_worst    5.865000e-02\n",
       "Name: 210, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [01:50<00:00, 11.08s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                         8.697370e+07\n",
       "radius_mean                1.444000e+01\n",
       "texture_mean               1.518000e+01\n",
       "perimeter_mean             9.397000e+01\n",
       "area_mean                  6.401000e+02\n",
       "smoothness_mean            9.970000e-02\n",
       "compactness_mean           1.021000e-01\n",
       "concavity_mean             8.487000e-02\n",
       "concave points_mean        5.532000e-02\n",
       "symmetry_mean              1.724000e-01\n",
       "fractal_dimension_mean     6.081000e-02\n",
       "radius_se                  2.406000e-01\n",
       "texture_se                 7.394000e-01\n",
       "perimeter_se               2.120000e+00\n",
       "area_se                    2.120000e+01\n",
       "smoothness_se              5.706000e-03\n",
       "compactness_se             2.297000e-02\n",
       "concavity_se               3.114000e-02\n",
       "concave points_se          1.493000e-02\n",
       "symmetry_se                1.454000e-02\n",
       "fractal_dimension_se       2.528000e-03\n",
       "radius_worst               1.585000e+01\n",
       "texture_worst              1.985000e+01\n",
       "perimeter_worst            1.086000e+02\n",
       "area_worst                 7.669000e+02\n",
       "smoothness_worst           1.316000e-01\n",
       "compactness_worst          2.735000e-01\n",
       "concavity_worst            3.103000e-01\n",
       "concave points_worst       1.599000e-01\n",
       "symmetry_worst             2.691000e-01\n",
       "fractal_dimension_worst    7.683000e-02\n",
       "Name: 148, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:34<00:00,  3.43s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                         8.611792e+06\n",
       "radius_mean                1.910000e+01\n",
       "texture_mean               2.629000e+01\n",
       "perimeter_mean             1.291000e+02\n",
       "area_mean                  1.132000e+03\n",
       "smoothness_mean            1.215000e-01\n",
       "compactness_mean           1.791000e-01\n",
       "concavity_mean             1.937000e-01\n",
       "concave points_mean        1.469000e-01\n",
       "symmetry_mean              1.634000e-01\n",
       "fractal_dimension_mean     7.224000e-02\n",
       "radius_se                  5.190000e-01\n",
       "texture_se                 2.910000e+00\n",
       "perimeter_se               5.801000e+00\n",
       "area_se                    6.710000e+01\n",
       "smoothness_se              7.545000e-03\n",
       "compactness_se             6.050000e-02\n",
       "concavity_se               2.134000e-02\n",
       "concave points_se          1.843000e-02\n",
       "symmetry_se                3.056000e-02\n",
       "fractal_dimension_se       1.039000e-02\n",
       "radius_worst               2.033000e+01\n",
       "texture_worst              3.272000e+01\n",
       "perimeter_worst            1.413000e+02\n",
       "area_worst                 1.298000e+03\n",
       "smoothness_worst           1.392000e-01\n",
       "compactness_worst          2.817000e-01\n",
       "concavity_worst            2.432000e-01\n",
       "concave points_worst       1.841000e-01\n",
       "symmetry_worst             2.311000e-01\n",
       "fractal_dimension_worst    9.203000e-02\n",
       "Name: 83, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [01:52<00:00, 11.20s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                         842517.000000\n",
       "radius_mean                    20.570000\n",
       "texture_mean                   17.770000\n",
       "perimeter_mean                132.900000\n",
       "area_mean                    1326.000000\n",
       "smoothness_mean                 0.084740\n",
       "compactness_mean                0.078640\n",
       "concavity_mean                  0.086900\n",
       "concave points_mean             0.070170\n",
       "symmetry_mean                   0.181200\n",
       "fractal_dimension_mean          0.056670\n",
       "radius_se                       0.543500\n",
       "texture_se                      0.733900\n",
       "perimeter_se                    3.398000\n",
       "area_se                        74.080000\n",
       "smoothness_se                   0.005225\n",
       "compactness_se                  0.013080\n",
       "concavity_se                    0.018600\n",
       "concave points_se               0.013400\n",
       "symmetry_se                     0.013890\n",
       "fractal_dimension_se            0.003532\n",
       "radius_worst                   24.990000\n",
       "texture_worst                  23.410000\n",
       "perimeter_worst               158.800000\n",
       "area_worst                   1956.000000\n",
       "smoothness_worst                0.123800\n",
       "compactness_worst               0.186600\n",
       "concavity_worst                 0.241600\n",
       "concave points_worst            0.186000\n",
       "symmetry_worst                  0.275000\n",
       "fractal_dimension_worst         0.089020\n",
       "Name: 1, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [01:46<00:00, 10.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de instâncias contrafactuais = 110\n",
      "Quantidade de relações causais na base de dados = 260\n",
      "Quantidade de atributos modificados = 215\n",
      "Quantidade de instâncias contrafactuais causais = 17\n",
      "Quantidade de relações causais analisadas = 1034\n",
      "Quantidade de relações causais satisfeitas = 596.0\n",
      "Quantidade de instâncias contrafactuais com um único atributo modificado = 1\n",
      "name                                                  Churn\n",
      "path      Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...\n",
      "classe                                                Churn\n",
      "Name: 6, dtype: object\n",
      "name                                  Compas\n",
      "path      Compas/compas-scores-two-years.csv\n",
      "classe                        two_year_recid\n",
      "Name: 7, dtype: object\n",
      "name                          Credit default\n",
      "path      Credit default/UCI_Credit_Card.csv\n",
      "classe            default.payment.next.month\n",
      "Name: 8, dtype: object\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      2348\n",
      "           1       0.63      0.36      0.46       652\n",
      "\n",
      "    accuracy                           0.82      3000\n",
      "   macro avg       0.74      0.65      0.68      3000\n",
      "weighted avg       0.80      0.82      0.80      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_causal_metrics(row):\n",
    "    try:\n",
    "        print(row)\n",
    "        ccsse = CCSSE(row['name'], samples = 10, K = 10, generation= 10)\n",
    "        ccsse.run_causal()\n",
    "        return ccsse.show_metrics(get_output = True)\n",
    "    except Exception as e:\n",
    "        return e\n",
    "\n",
    "df_map_inference_datasets['causal_metrics'] = df_map_inference_datasets.apply(get_causal_metrics, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf513e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map_inference_datasets.to_parquet(f\"datasets/df_map_inference_datasets_causal_metrics.parquet\", engine = \"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c0ff994d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>classe</th>\n",
       "      <th>causal_metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult</td>\n",
       "      <td>adult/adult_processada.csv</td>\n",
       "      <td>Above/Below 50K</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australian</td>\n",
       "      <td>Australian/Credit_Card_Applications.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Banknote</td>\n",
       "      <td>Banknote/BankNote_Authentication.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biodeg</td>\n",
       "      <td>Biodeg/qsar-biodeg.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Coimbra</td>\n",
       "      <td>Breast Cancer Coimbra/breast_coimbra.csv</td>\n",
       "      <td>Classification</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Breast Cancer Wisconsin</td>\n",
       "      <td>Breast Cancer Wisconsin/breast-cancer.csv</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Churn</td>\n",
       "      <td>Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...</td>\n",
       "      <td>Churn</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Compas</td>\n",
       "      <td>Compas/compas-scores-two-years.csv</td>\n",
       "      <td>two_year_recid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit default</td>\n",
       "      <td>Credit default/UCI_Credit_Card.csv</td>\n",
       "      <td>default.payment.next.month</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Diabetes/diabetes.csv</td>\n",
       "      <td>Outcome</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Driving Behavior</td>\n",
       "      <td>['Driving Behavior/train_motion_data.csv', 'Dr...</td>\n",
       "      <td>Class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EEg</td>\n",
       "      <td>EEg/EEG Eye State.csv</td>\n",
       "      <td>Column15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>German</td>\n",
       "      <td>German/german_credit.csv</td>\n",
       "      <td>default</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GiveMeSomeCredit</td>\n",
       "      <td>GiveMeSomeCredit/GiveMeSomeCredit_processada.csv</td>\n",
       "      <td>SeriousDlqin2yrs</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Heart</td>\n",
       "      <td>Heart/heart.csv</td>\n",
       "      <td>output</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Heart_2</td>\n",
       "      <td>Heart/heart2.csv</td>\n",
       "      <td>num</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Heart Failure Prediction</td>\n",
       "      <td>Heart Failure Prediction/heart_failure_clinica...</td>\n",
       "      <td>DEATH_EVENT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HELOC</td>\n",
       "      <td>HELOC/heloc_dataset_v1.csv</td>\n",
       "      <td>RiskPerformance</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Hill</td>\n",
       "      <td>['Hill/Hill_Valley_with_noise_Training.csv', '...</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Horse colic</td>\n",
       "      <td>Horse colic/horseV2_processada.csv</td>\n",
       "      <td>surgery</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Indian Liver Patient Dataset</td>\n",
       "      <td>Indian Liver Patient Dataset/Indian Liver Pati...</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ionosfera</td>\n",
       "      <td>Ionosfera/ionosphere.csv</td>\n",
       "      <td>target</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>IRIS</td>\n",
       "      <td>IRIS/Iris.csv</td>\n",
       "      <td>Species</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>KC2</td>\n",
       "      <td>KC2/KC2.csv</td>\n",
       "      <td>defects</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>liver disorders_bupa</td>\n",
       "      <td>liver disorders_bupa/bupa.csv</td>\n",
       "      <td>selector</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Magic</td>\n",
       "      <td>Magic/telescope_data.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mammographic_masses</td>\n",
       "      <td>mammographic_masses/mammographic_masses_cleane...</td>\n",
       "      <td>Severity</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Mobile Price Classification</td>\n",
       "      <td>Mobile Price Classification/train_mobile_proce...</td>\n",
       "      <td>range</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Monk_1</td>\n",
       "      <td>['Monk/monks-1_train.csv', 'Monk/monks-1_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Monk_2</td>\n",
       "      <td>['Monk/monks-2_train.csv', 'Monk/monks-2_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Monk_3</td>\n",
       "      <td>['Monk/monks-3_train.csv', 'Monk/monks-3_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Mushrooms</td>\n",
       "      <td>Mushrooms/mushrooms_processada.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Musk</td>\n",
       "      <td>Musk/clean1.csv</td>\n",
       "      <td>Column169</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>News popularity</td>\n",
       "      <td>News popularity/OnlineNewsPopularity.csv</td>\n",
       "      <td>shares</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>no2</td>\n",
       "      <td>no2/no2.csv</td>\n",
       "      <td>Column1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>OnlineNewsPopularity</td>\n",
       "      <td>OnlineNewsPopularity/OnlineNewsPopularity_proc...</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>optdigits_csv</td>\n",
       "      <td>optdigits_csv/optdigits_csv.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>pc1</td>\n",
       "      <td>pc1/pc1.csv</td>\n",
       "      <td>defects</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Phishing</td>\n",
       "      <td>Phishing/Phishing.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Phoneme</td>\n",
       "      <td>Phoneme/phoneme.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Plasma</td>\n",
       "      <td>Plasma/plasma.csv</td>\n",
       "      <td>Column14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>post-operative</td>\n",
       "      <td>post-operative/post-operative-data.csv</td>\n",
       "      <td>decision ADM-DECS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>price</td>\n",
       "      <td>['price/train.csv', 'price/test.csv']</td>\n",
       "      <td>price_range</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Room Occupancy</td>\n",
       "      <td>Room Occupancy/Room Occupancy.csv</td>\n",
       "      <td>Occupancy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>seismic</td>\n",
       "      <td>seismic/seismic_processada.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Shopping</td>\n",
       "      <td>Shopping/e-shop clothing 2008.csv</td>\n",
       "      <td>page</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Sky Survey</td>\n",
       "      <td>Sky Survey/Skyserver_SQL2_27_2018 6_51_39 PM.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Sonar</td>\n",
       "      <td>Sonar/sonar.all-data.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Spambase</td>\n",
       "      <td>Spambase/Spambase.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Student</td>\n",
       "      <td>Student/Students-Performance-MAT_processada.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Tic-Tac-Toe</td>\n",
       "      <td>Tic-Tac-Toe/tic-tac-toe-endgame.csv</td>\n",
       "      <td>V10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>titanic</td>\n",
       "      <td>titanic/titanic_processada.csv</td>\n",
       "      <td>Survived</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo/Tokyo.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>twonorm</td>\n",
       "      <td>twonorm/twonorm.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Vertebral_2C</td>\n",
       "      <td>Vertebral/column_2C.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Vertebral_3C</td>\n",
       "      <td>Vertebral/column_3C.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Votes_Congressional</td>\n",
       "      <td>Votes_Congressional/house-votes-84_processada.csv</td>\n",
       "      <td>Class Name</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>wine</td>\n",
       "      <td>wine/WineQT.csv</td>\n",
       "      <td>quality</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>xd6</td>\n",
       "      <td>xd6/xd6_dataset_csv.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  \\\n",
       "0                          Adult   \n",
       "1                     Australian   \n",
       "2                       Banknote   \n",
       "3                         Biodeg   \n",
       "4          Breast Cancer Coimbra   \n",
       "5        Breast Cancer Wisconsin   \n",
       "6                          Churn   \n",
       "7                         Compas   \n",
       "8                 Credit default   \n",
       "9                       Diabetes   \n",
       "10              Driving Behavior   \n",
       "11                           EEg   \n",
       "12                        German   \n",
       "13              GiveMeSomeCredit   \n",
       "14                         Heart   \n",
       "15                       Heart_2   \n",
       "16      Heart Failure Prediction   \n",
       "17                         HELOC   \n",
       "18                          Hill   \n",
       "19                   Horse colic   \n",
       "20  Indian Liver Patient Dataset   \n",
       "21                     Ionosfera   \n",
       "22                          IRIS   \n",
       "23                           KC2   \n",
       "24          liver disorders_bupa   \n",
       "25                         Magic   \n",
       "26           mammographic_masses   \n",
       "27   Mobile Price Classification   \n",
       "28                        Monk_1   \n",
       "29                        Monk_2   \n",
       "30                        Monk_3   \n",
       "31                     Mushrooms   \n",
       "32                          Musk   \n",
       "33               News popularity   \n",
       "34                           no2   \n",
       "35          OnlineNewsPopularity   \n",
       "36                 optdigits_csv   \n",
       "37                           pc1   \n",
       "38                      Phishing   \n",
       "39                       Phoneme   \n",
       "40                        Plasma   \n",
       "41                post-operative   \n",
       "42                         price   \n",
       "43                Room Occupancy   \n",
       "44                       seismic   \n",
       "45                      Shopping   \n",
       "46                    Sky Survey   \n",
       "47                         Sonar   \n",
       "48                      Spambase   \n",
       "49                       Student   \n",
       "50                   Tic-Tac-Toe   \n",
       "51                       titanic   \n",
       "52                         Tokyo   \n",
       "53                       twonorm   \n",
       "54                  Vertebral_2C   \n",
       "55                  Vertebral_3C   \n",
       "56           Votes_Congressional   \n",
       "57                          wine   \n",
       "58                           xd6   \n",
       "\n",
       "                                                 path  \\\n",
       "0                          adult/adult_processada.csv   \n",
       "1             Australian/Credit_Card_Applications.csv   \n",
       "2                Banknote/BankNote_Authentication.csv   \n",
       "3                              Biodeg/qsar-biodeg.csv   \n",
       "4            Breast Cancer Coimbra/breast_coimbra.csv   \n",
       "5           Breast Cancer Wisconsin/breast-cancer.csv   \n",
       "6   Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...   \n",
       "7                  Compas/compas-scores-two-years.csv   \n",
       "8                  Credit default/UCI_Credit_Card.csv   \n",
       "9                               Diabetes/diabetes.csv   \n",
       "10  ['Driving Behavior/train_motion_data.csv', 'Dr...   \n",
       "11                              EEg/EEG Eye State.csv   \n",
       "12                           German/german_credit.csv   \n",
       "13   GiveMeSomeCredit/GiveMeSomeCredit_processada.csv   \n",
       "14                                    Heart/heart.csv   \n",
       "15                                   Heart/heart2.csv   \n",
       "16  Heart Failure Prediction/heart_failure_clinica...   \n",
       "17                         HELOC/heloc_dataset_v1.csv   \n",
       "18  ['Hill/Hill_Valley_with_noise_Training.csv', '...   \n",
       "19                 Horse colic/horseV2_processada.csv   \n",
       "20  Indian Liver Patient Dataset/Indian Liver Pati...   \n",
       "21                           Ionosfera/ionosphere.csv   \n",
       "22                                      IRIS/Iris.csv   \n",
       "23                                        KC2/KC2.csv   \n",
       "24                      liver disorders_bupa/bupa.csv   \n",
       "25                           Magic/telescope_data.csv   \n",
       "26  mammographic_masses/mammographic_masses_cleane...   \n",
       "27  Mobile Price Classification/train_mobile_proce...   \n",
       "28  ['Monk/monks-1_train.csv', 'Monk/monks-1_test....   \n",
       "29  ['Monk/monks-2_train.csv', 'Monk/monks-2_test....   \n",
       "30  ['Monk/monks-3_train.csv', 'Monk/monks-3_test....   \n",
       "31                 Mushrooms/mushrooms_processada.csv   \n",
       "32                                    Musk/clean1.csv   \n",
       "33           News popularity/OnlineNewsPopularity.csv   \n",
       "34                                        no2/no2.csv   \n",
       "35  OnlineNewsPopularity/OnlineNewsPopularity_proc...   \n",
       "36                    optdigits_csv/optdigits_csv.csv   \n",
       "37                                        pc1/pc1.csv   \n",
       "38                              Phishing/Phishing.csv   \n",
       "39                                Phoneme/phoneme.csv   \n",
       "40                                  Plasma/plasma.csv   \n",
       "41             post-operative/post-operative-data.csv   \n",
       "42              ['price/train.csv', 'price/test.csv']   \n",
       "43                  Room Occupancy/Room Occupancy.csv   \n",
       "44                     seismic/seismic_processada.csv   \n",
       "45                  Shopping/e-shop clothing 2008.csv   \n",
       "46   Sky Survey/Skyserver_SQL2_27_2018 6_51_39 PM.csv   \n",
       "47                           Sonar/sonar.all-data.csv   \n",
       "48                              Spambase/Spambase.csv   \n",
       "49    Student/Students-Performance-MAT_processada.csv   \n",
       "50                Tic-Tac-Toe/tic-tac-toe-endgame.csv   \n",
       "51                     titanic/titanic_processada.csv   \n",
       "52                                    Tokyo/Tokyo.csv   \n",
       "53                                twonorm/twonorm.csv   \n",
       "54                            Vertebral/column_2C.csv   \n",
       "55                            Vertebral/column_3C.csv   \n",
       "56  Votes_Congressional/house-votes-84_processada.csv   \n",
       "57                                    wine/WineQT.csv   \n",
       "58                            xd6/xd6_dataset_csv.csv   \n",
       "\n",
       "                        classe causal_metrics  \n",
       "0              Above/Below 50K            NaN  \n",
       "1                        Class            NaN  \n",
       "2                        class            NaN  \n",
       "3                        Class            NaN  \n",
       "4               Classification            NaN  \n",
       "5                    diagnosis            NaN  \n",
       "6                        Churn            NaN  \n",
       "7               two_year_recid            NaN  \n",
       "8   default.payment.next.month            NaN  \n",
       "9                      Outcome            NaN  \n",
       "10                       Class            NaN  \n",
       "11                    Column15            NaN  \n",
       "12                     default            NaN  \n",
       "13            SeriousDlqin2yrs            NaN  \n",
       "14                      output            NaN  \n",
       "15                         num            NaN  \n",
       "16                 DEATH_EVENT            NaN  \n",
       "17             RiskPerformance            NaN  \n",
       "18                       class            NaN  \n",
       "19                     surgery            NaN  \n",
       "20                       class            NaN  \n",
       "21                      target            NaN  \n",
       "22                     Species            NaN  \n",
       "23                     defects            NaN  \n",
       "24                    selector            NaN  \n",
       "25                       class            NaN  \n",
       "26                    Severity            NaN  \n",
       "27                       range            NaN  \n",
       "28                       Class            NaN  \n",
       "29                       Class            NaN  \n",
       "30                       Class            NaN  \n",
       "31                       class            NaN  \n",
       "32                   Column169            NaN  \n",
       "33                      shares            NaN  \n",
       "34                     Column1            NaN  \n",
       "35                       class            NaN  \n",
       "36                       class            NaN  \n",
       "37                     defects            NaN  \n",
       "38                       Class            NaN  \n",
       "39                       class            NaN  \n",
       "40                    Column14            NaN  \n",
       "41           decision ADM-DECS            NaN  \n",
       "42                 price_range            NaN  \n",
       "43                   Occupancy            NaN  \n",
       "44                       class            NaN  \n",
       "45                        page            NaN  \n",
       "46                       class            NaN  \n",
       "47                       class            NaN  \n",
       "48                       Class            NaN  \n",
       "49                       Class            NaN  \n",
       "50                         V10            NaN  \n",
       "51                    Survived            NaN  \n",
       "52                       class            NaN  \n",
       "53                       class            NaN  \n",
       "54                       class            NaN  \n",
       "55                       class            NaN  \n",
       "56                  Class Name            NaN  \n",
       "57                     quality            NaN  \n",
       "58                       class            NaN  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_map_inference_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "345d9581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95        42\n",
      "           1       0.90      0.96      0.93        27\n",
      "\n",
      "    accuracy                           0.94        69\n",
      "   macro avg       0.94      0.95      0.94        69\n",
      "weighted avg       0.94      0.94      0.94        69\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ccsse = CCSSE('Australian', samples = 10, K = 1, generation= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5c5a5566",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerID    1.558727e+07\n",
       "A1            1.000000e+00\n",
       "A2            2.858000e+01\n",
       "A3            3.625000e+00\n",
       "A4            2.000000e+00\n",
       "A5            6.000000e+00\n",
       "A6            4.000000e+00\n",
       "A7            2.500000e-01\n",
       "A8            0.000000e+00\n",
       "A9            0.000000e+00\n",
       "A10           0.000000e+00\n",
       "A11           1.000000e+00\n",
       "A12           2.000000e+00\n",
       "A13           1.000000e+02\n",
       "A14           1.000000e+00\n",
       "Name: 269, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:11<00:00,  1.20s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomerID    15679394.0\n",
       "A1                   0.0\n",
       "A2                  36.0\n",
       "A3                   1.0\n",
       "A4                   2.0\n",
       "A5                   8.0\n",
       "A6                   4.0\n",
       "A7                   2.0\n",
       "A8                   1.0\n",
       "A9                   1.0\n",
       "A10                 11.0\n",
       "A11                  0.0\n",
       "A12                  2.0\n",
       "A13                  0.0\n",
       "A14                457.0\n",
       "Name: 336, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:12<00:00,  1.28s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomerID    1.575939e+07\n",
       "A1            0.000000e+00\n",
       "A2            4.417000e+01\n",
       "A3            6.665000e+00\n",
       "A4            2.000000e+00\n",
       "A5            1.100000e+01\n",
       "A6            4.000000e+00\n",
       "A7            7.375000e+00\n",
       "A8            1.000000e+00\n",
       "A9            1.000000e+00\n",
       "A10           3.000000e+00\n",
       "A11           1.000000e+00\n",
       "A12           2.000000e+00\n",
       "A13           0.000000e+00\n",
       "A14           1.000000e+00\n",
       "Name: 565, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:13<00:00,  1.30s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomerID    15801473.00\n",
       "A1                   0.00\n",
       "A2                  20.83\n",
       "A3                   0.50\n",
       "A4                   1.00\n",
       "A5                  10.00\n",
       "A6                   2.00\n",
       "A7                   1.00\n",
       "A8                   0.00\n",
       "A9                   0.00\n",
       "A10                  0.00\n",
       "A11                  0.00\n",
       "A12                  2.00\n",
       "A13                260.00\n",
       "A14                  1.00\n",
       "Name: 131, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:11<00:00,  1.19s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomerID    15593959.00\n",
       "A1                   0.00\n",
       "A2                  21.75\n",
       "A3                   1.75\n",
       "A4                   1.00\n",
       "A5                   5.00\n",
       "A6                   3.00\n",
       "A7                   0.00\n",
       "A8                   0.00\n",
       "A9                   0.00\n",
       "A10                  0.00\n",
       "A11                  0.00\n",
       "A12                  2.00\n",
       "A13                160.00\n",
       "A14                  1.00\n",
       "Name: 201, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:11<00:00,  1.17s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomerID    1.578534e+07\n",
       "A1            1.000000e+00\n",
       "A2            3.525000e+01\n",
       "A3            3.165000e+00\n",
       "A4            2.000000e+00\n",
       "A5            1.400000e+01\n",
       "A6            8.000000e+00\n",
       "A7            3.750000e+00\n",
       "A8            1.000000e+00\n",
       "A9            0.000000e+00\n",
       "A10           0.000000e+00\n",
       "A11           1.000000e+00\n",
       "A12           2.000000e+00\n",
       "A13           6.800000e+02\n",
       "A14           1.000000e+00\n",
       "Name: 175, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:11<00:00,  1.12s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomerID    15815040.0\n",
       "A1                   1.0\n",
       "A2                  19.0\n",
       "A3                   0.0\n",
       "A4                   1.0\n",
       "A5                   1.0\n",
       "A6                   1.0\n",
       "A7                   0.0\n",
       "A8                   0.0\n",
       "A9                   1.0\n",
       "A10                  4.0\n",
       "A11                  0.0\n",
       "A12                  2.0\n",
       "A13                 45.0\n",
       "A14                  2.0\n",
       "Name: 104, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:14<00:00,  1.48s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomerID    15655658.00\n",
       "A1                   1.00\n",
       "A2                  22.58\n",
       "A3                   1.50\n",
       "A4                   1.00\n",
       "A5                   6.00\n",
       "A6                   4.00\n",
       "A7                   0.54\n",
       "A8                   0.00\n",
       "A9                   0.00\n",
       "A10                  0.00\n",
       "A11                  1.00\n",
       "A12                  2.00\n",
       "A13                120.00\n",
       "A14                 68.00\n",
       "Name: 41, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:13<00:00,  1.31s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomerID    15595010.00\n",
       "A1                   1.00\n",
       "A2                  34.17\n",
       "A3                   9.17\n",
       "A4                   2.00\n",
       "A5                   8.00\n",
       "A6                   4.00\n",
       "A7                   4.50\n",
       "A8                   1.00\n",
       "A9                   1.00\n",
       "A10                 12.00\n",
       "A11                  1.00\n",
       "A12                  2.00\n",
       "A13                  0.00\n",
       "A14                222.00\n",
       "Name: 585, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:14<00:00,  1.41s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomerID    15723884.00\n",
       "A1                   1.00\n",
       "A2                  36.25\n",
       "A3                   5.00\n",
       "A4                   2.00\n",
       "A5                   8.00\n",
       "A6                   5.00\n",
       "A7                   2.50\n",
       "A8                   1.00\n",
       "A9                   1.00\n",
       "A10                  6.00\n",
       "A11                  0.00\n",
       "A12                  2.00\n",
       "A13                  0.00\n",
       "A14                368.00\n",
       "Name: 93, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:13<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "ccsse.run_causal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fea7c3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de instâncias contrafactuais = 11\n",
      "Quantidade de relações causais na base de dados = 25\n",
      "Quantidade de atributos modificados = 18\n",
      "Quantidade de instâncias contrafactuais causais = 10\n",
      "Quantidade de relações causais analisadas = 5\n",
      "Quantidade de relações causais satisfeitas = 5.0\n",
      "Quantidade de instâncias contrafactuais com um único atributo modificado = 8\n",
      "---------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ccsse.show_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "92b5fdaf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global_numbers': {'global_quant_changes': 18,\n",
       "  'global_quant_causal_changes': 5.0,\n",
       "  'global_quant_causal_rules': 5,\n",
       "  'global_quant_zeros_causal': 0,\n",
       "  'global_quant_full_causal': 2,\n",
       "  'global_quant_causal_contrafac': 2,\n",
       "  'global_quant_maioria_causal_satisfeita': 2,\n",
       "  'global_quant_contrafac_unico': 8},\n",
       " 0: {'original_instance': CustomerID    1.558727e+07\n",
       "  A1            1.000000e+00\n",
       "  A2            2.858000e+01\n",
       "  A3            3.625000e+00\n",
       "  A4            2.000000e+00\n",
       "  A5            6.000000e+00\n",
       "  A6            4.000000e+00\n",
       "  A7            2.500000e-01\n",
       "  A8            0.000000e+00\n",
       "  A9            0.000000e+00\n",
       "  A10           0.000000e+00\n",
       "  A11           1.000000e+00\n",
       "  A12           2.000000e+00\n",
       "  A13           1.000000e+02\n",
       "  A14           1.000000e+00\n",
       "  Name: 269, dtype: float64,\n",
       "  'causal_explain': [[[('A8', 1.0), ('A13', 36.75777104155044)]],\n",
       "   Empty DataFrame\n",
       "   Columns: [from, to, effect]\n",
       "   Index: [],\n",
       "   CustomerID    1.558727e+07\n",
       "   A1            1.000000e+00\n",
       "   A2            2.858000e+01\n",
       "   A3            3.625000e+00\n",
       "   A4            2.000000e+00\n",
       "   A5            6.000000e+00\n",
       "   A6            4.000000e+00\n",
       "   A7            2.500000e-01\n",
       "   A8            0.000000e+00\n",
       "   A9            0.000000e+00\n",
       "   A10           0.000000e+00\n",
       "   A11           1.000000e+00\n",
       "   A12           2.000000e+00\n",
       "   A13           1.000000e+02\n",
       "   A14           1.000000e+00\n",
       "   Name: 269, dtype: float64],\n",
       "  'list_analyse': [[[('A8', 1.0), ('A13', 36.75777104155044)],\n",
       "    Empty DataFrame\n",
       "    Columns: [from, to, effect]\n",
       "    Index: [],\n",
       "    A8       0.0\n",
       "    A13    100.0\n",
       "    Name: 269, dtype: float64]],\n",
       "  'data_analysis': [{'df_respeita_causal': Empty DataFrame\n",
       "    Columns: [from, to, effect, causal]\n",
       "    Index: [],\n",
       "    'contrafactual_causal': [('A8', 1.0), ('A13', 36.75777104155044)],\n",
       "    'df_causal_effects': Empty DataFrame\n",
       "    Columns: [from, to, effect]\n",
       "    Index: []}]},\n",
       " 1: {'original_instance': CustomerID    15679394.0\n",
       "  A1                   0.0\n",
       "  A2                  36.0\n",
       "  A3                   1.0\n",
       "  A4                   2.0\n",
       "  A5                   8.0\n",
       "  A6                   4.0\n",
       "  A7                   2.0\n",
       "  A8                   1.0\n",
       "  A9                   1.0\n",
       "  A10                 11.0\n",
       "  A11                  0.0\n",
       "  A12                  2.0\n",
       "  A13                  0.0\n",
       "  A14                457.0\n",
       "  Name: 336, dtype: float64,\n",
       "  'causal_explain': [[[('A8', 0.0)]],\n",
       "   Empty DataFrame\n",
       "   Columns: [from, to, effect]\n",
       "   Index: [],\n",
       "   CustomerID    15679394.0\n",
       "   A1                   0.0\n",
       "   A2                  36.0\n",
       "   A3                   1.0\n",
       "   A4                   2.0\n",
       "   A5                   8.0\n",
       "   A6                   4.0\n",
       "   A7                   2.0\n",
       "   A8                   1.0\n",
       "   A9                   1.0\n",
       "   A10                 11.0\n",
       "   A11                  0.0\n",
       "   A12                  2.0\n",
       "   A13                  0.0\n",
       "   A14                457.0\n",
       "   Name: 336, dtype: float64],\n",
       "  'list_analyse': [[[('A8', 0.0)],\n",
       "    Empty DataFrame\n",
       "    Columns: [from, to, effect]\n",
       "    Index: [],\n",
       "    A8    1.0\n",
       "    Name: 336, dtype: float64]],\n",
       "  'data_analysis': [{'df_respeita_causal': Empty DataFrame\n",
       "    Columns: [from, to, effect, causal]\n",
       "    Index: [],\n",
       "    'contrafactual_causal': [('A8', 0.0)],\n",
       "    'df_causal_effects': Empty DataFrame\n",
       "    Columns: [from, to, effect]\n",
       "    Index: []}]},\n",
       " 2: {'original_instance': CustomerID    1.575939e+07\n",
       "  A1            0.000000e+00\n",
       "  A2            4.417000e+01\n",
       "  A3            6.665000e+00\n",
       "  A4            2.000000e+00\n",
       "  A5            1.100000e+01\n",
       "  A6            4.000000e+00\n",
       "  A7            7.375000e+00\n",
       "  A8            1.000000e+00\n",
       "  A9            1.000000e+00\n",
       "  A10           3.000000e+00\n",
       "  A11           1.000000e+00\n",
       "  A12           2.000000e+00\n",
       "  A13           0.000000e+00\n",
       "  A14           1.000000e+00\n",
       "  Name: 565, dtype: float64,\n",
       "  'causal_explain': [[[('A8', 0.4932608260050229)]],\n",
       "   Empty DataFrame\n",
       "   Columns: [from, to, effect]\n",
       "   Index: [],\n",
       "   CustomerID    1.575939e+07\n",
       "   A1            0.000000e+00\n",
       "   A2            4.417000e+01\n",
       "   A3            6.665000e+00\n",
       "   A4            2.000000e+00\n",
       "   A5            1.100000e+01\n",
       "   A6            4.000000e+00\n",
       "   A7            7.375000e+00\n",
       "   A8            1.000000e+00\n",
       "   A9            1.000000e+00\n",
       "   A10           3.000000e+00\n",
       "   A11           1.000000e+00\n",
       "   A12           2.000000e+00\n",
       "   A13           0.000000e+00\n",
       "   A14           1.000000e+00\n",
       "   Name: 565, dtype: float64],\n",
       "  'list_analyse': [[[('A8', 0.4932608260050229)],\n",
       "    Empty DataFrame\n",
       "    Columns: [from, to, effect]\n",
       "    Index: [],\n",
       "    A8    1.0\n",
       "    Name: 565, dtype: float64]],\n",
       "  'data_analysis': [{'df_respeita_causal': Empty DataFrame\n",
       "    Columns: [from, to, effect, causal]\n",
       "    Index: [],\n",
       "    'contrafactual_causal': [('A8', 0.4932608260050229)],\n",
       "    'df_causal_effects': Empty DataFrame\n",
       "    Columns: [from, to, effect]\n",
       "    Index: []}]},\n",
       " 3: {'original_instance': CustomerID    15801473.00\n",
       "  A1                   0.00\n",
       "  A2                  20.83\n",
       "  A3                   0.50\n",
       "  A4                   1.00\n",
       "  A5                  10.00\n",
       "  A6                   2.00\n",
       "  A7                   1.00\n",
       "  A8                   0.00\n",
       "  A9                   0.00\n",
       "  A10                  0.00\n",
       "  A11                  0.00\n",
       "  A12                  2.00\n",
       "  A13                260.00\n",
       "  A14                  1.00\n",
       "  Name: 131, dtype: float64,\n",
       "  'causal_explain': [[[('A8', 1.64942955251785), ('A13', 89.29200211851844)]],\n",
       "   Empty DataFrame\n",
       "   Columns: [from, to, effect]\n",
       "   Index: [],\n",
       "   CustomerID    15801473.00\n",
       "   A1                   0.00\n",
       "   A2                  20.83\n",
       "   A3                   0.50\n",
       "   A4                   1.00\n",
       "   A5                  10.00\n",
       "   A6                   2.00\n",
       "   A7                   1.00\n",
       "   A8                   0.00\n",
       "   A9                   0.00\n",
       "   A10                  0.00\n",
       "   A11                  0.00\n",
       "   A12                  2.00\n",
       "   A13                260.00\n",
       "   A14                  1.00\n",
       "   Name: 131, dtype: float64],\n",
       "  'list_analyse': [[[('A8', 1.64942955251785), ('A13', 89.29200211851844)],\n",
       "    Empty DataFrame\n",
       "    Columns: [from, to, effect]\n",
       "    Index: [],\n",
       "    A8       0.0\n",
       "    A13    260.0\n",
       "    Name: 131, dtype: float64]],\n",
       "  'data_analysis': [{'df_respeita_causal': Empty DataFrame\n",
       "    Columns: [from, to, effect, causal]\n",
       "    Index: [],\n",
       "    'contrafactual_causal': [('A8', 1.64942955251785),\n",
       "     ('A13', 89.29200211851844)],\n",
       "    'df_causal_effects': Empty DataFrame\n",
       "    Columns: [from, to, effect]\n",
       "    Index: []}]},\n",
       " 4: {'original_instance': CustomerID    15593959.00\n",
       "  A1                   0.00\n",
       "  A2                  21.75\n",
       "  A3                   1.75\n",
       "  A4                   1.00\n",
       "  A5                   5.00\n",
       "  A6                   3.00\n",
       "  A7                   0.00\n",
       "  A8                   0.00\n",
       "  A9                   0.00\n",
       "  A10                  0.00\n",
       "  A11                  0.00\n",
       "  A12                  2.00\n",
       "  A13                160.00\n",
       "  A14                  1.00\n",
       "  Name: 201, dtype: float64,\n",
       "  'causal_explain': [[[('A8', 1.0), ('A13', 8.944921040345672)]],\n",
       "   Empty DataFrame\n",
       "   Columns: [from, to, effect]\n",
       "   Index: [],\n",
       "   CustomerID    15593959.00\n",
       "   A1                   0.00\n",
       "   A2                  21.75\n",
       "   A3                   1.75\n",
       "   A4                   1.00\n",
       "   A5                   5.00\n",
       "   A6                   3.00\n",
       "   A7                   0.00\n",
       "   A8                   0.00\n",
       "   A9                   0.00\n",
       "   A10                  0.00\n",
       "   A11                  0.00\n",
       "   A12                  2.00\n",
       "   A13                160.00\n",
       "   A14                  1.00\n",
       "   Name: 201, dtype: float64],\n",
       "  'list_analyse': [[[('A8', 1.0), ('A13', 8.944921040345672)],\n",
       "    Empty DataFrame\n",
       "    Columns: [from, to, effect]\n",
       "    Index: [],\n",
       "    A8       0.0\n",
       "    A13    160.0\n",
       "    Name: 201, dtype: float64]],\n",
       "  'data_analysis': [{'df_respeita_causal': Empty DataFrame\n",
       "    Columns: [from, to, effect, causal]\n",
       "    Index: [],\n",
       "    'contrafactual_causal': [('A8', 1.0), ('A13', 8.944921040345672)],\n",
       "    'df_causal_effects': Empty DataFrame\n",
       "    Columns: [from, to, effect]\n",
       "    Index: []}]},\n",
       " 5: {'original_instance': CustomerID    1.578534e+07\n",
       "  A1            1.000000e+00\n",
       "  A2            3.525000e+01\n",
       "  A3            3.165000e+00\n",
       "  A4            2.000000e+00\n",
       "  A5            1.400000e+01\n",
       "  A6            8.000000e+00\n",
       "  A7            3.750000e+00\n",
       "  A8            1.000000e+00\n",
       "  A9            0.000000e+00\n",
       "  A10           0.000000e+00\n",
       "  A11           1.000000e+00\n",
       "  A12           2.000000e+00\n",
       "  A13           6.800000e+02\n",
       "  A14           1.000000e+00\n",
       "  Name: 175, dtype: float64,\n",
       "  'causal_explain': [[[('A8', 0.0), ('A13', 530.8560336851212)]],\n",
       "   Empty DataFrame\n",
       "   Columns: [from, to, effect]\n",
       "   Index: [],\n",
       "   CustomerID    1.578534e+07\n",
       "   A1            1.000000e+00\n",
       "   A2            3.525000e+01\n",
       "   A3            3.165000e+00\n",
       "   A4            2.000000e+00\n",
       "   A5            1.400000e+01\n",
       "   A6            8.000000e+00\n",
       "   A7            3.750000e+00\n",
       "   A8            1.000000e+00\n",
       "   A9            0.000000e+00\n",
       "   A10           0.000000e+00\n",
       "   A11           1.000000e+00\n",
       "   A12           2.000000e+00\n",
       "   A13           6.800000e+02\n",
       "   A14           1.000000e+00\n",
       "   Name: 175, dtype: float64],\n",
       "  'list_analyse': [[[('A8', 0.0), ('A13', 530.8560336851212)],\n",
       "    Empty DataFrame\n",
       "    Columns: [from, to, effect]\n",
       "    Index: [],\n",
       "    A8       1.0\n",
       "    A13    680.0\n",
       "    Name: 175, dtype: float64]],\n",
       "  'data_analysis': [{'df_respeita_causal': Empty DataFrame\n",
       "    Columns: [from, to, effect, causal]\n",
       "    Index: [],\n",
       "    'contrafactual_causal': [('A8', 0.0), ('A13', 530.8560336851212)],\n",
       "    'df_causal_effects': Empty DataFrame\n",
       "    Columns: [from, to, effect]\n",
       "    Index: []}]},\n",
       " 6: {'original_instance': CustomerID    15815040.0\n",
       "  A1                   1.0\n",
       "  A2                  19.0\n",
       "  A3                   0.0\n",
       "  A4                   1.0\n",
       "  A5                   1.0\n",
       "  A6                   1.0\n",
       "  A7                   0.0\n",
       "  A8                   0.0\n",
       "  A9                   1.0\n",
       "  A10                  4.0\n",
       "  A11                  0.0\n",
       "  A12                  2.0\n",
       "  A13                 45.0\n",
       "  A14                  2.0\n",
       "  Name: 104, dtype: float64,\n",
       "  'causal_explain': [[[('A5', 10.0), ('A8', 6.906919152993358)]],\n",
       "      from  to    effect\n",
       "   12   A5  A8  0.025258,\n",
       "   CustomerID    15815040.0\n",
       "   A1                   1.0\n",
       "   A2                  19.0\n",
       "   A3                   0.0\n",
       "   A4                   1.0\n",
       "   A5                   1.0\n",
       "   A6                   1.0\n",
       "   A7                   0.0\n",
       "   A8                   0.0\n",
       "   A9                   1.0\n",
       "   A10                  4.0\n",
       "   A11                  0.0\n",
       "   A12                  2.0\n",
       "   A13                 45.0\n",
       "   A14                  2.0\n",
       "   Name: 104, dtype: float64],\n",
       "  'list_analyse': [[[('A5', 10.0), ('A8', 6.906919152993358)],\n",
       "       from  to    effect\n",
       "    12   A5  A8  0.025258,\n",
       "    A5    1.0\n",
       "    A8    0.0\n",
       "    Name: 104, dtype: float64]],\n",
       "  'data_analysis': [{'df_respeita_causal':     from    to    effect  causal\n",
       "    12  mais  mais  0.025258    True,\n",
       "    'contrafactual_causal': [('A5', 10.0), ('A8', 6.906919152993358)],\n",
       "    'df_causal_effects':    from  to    effect\n",
       "    12   A5  A8  0.025258}]},\n",
       " 7: {'original_instance': CustomerID    15655658.00\n",
       "  A1                   1.00\n",
       "  A2                  22.58\n",
       "  A3                   1.50\n",
       "  A4                   1.00\n",
       "  A5                   6.00\n",
       "  A6                   4.00\n",
       "  A7                   0.54\n",
       "  A8                   0.00\n",
       "  A9                   0.00\n",
       "  A10                  0.00\n",
       "  A11                  1.00\n",
       "  A12                  2.00\n",
       "  A13                120.00\n",
       "  A14                 68.00\n",
       "  Name: 41, dtype: float64,\n",
       "  'causal_explain': [[[('A3', 11.40160856996935),\n",
       "     ('A8', 7.769165132716921),\n",
       "     ('A10', 8.0),\n",
       "     ('A13', -411.1573245871435)]],\n",
       "      from   to    effect\n",
       "   11   A3   A8  0.009500\n",
       "   2   A10   A3  0.199759\n",
       "   23   A3  A13 -7.625701\n",
       "   16  A10   A8  0.010143,\n",
       "   CustomerID    15655658.00\n",
       "   A1                   1.00\n",
       "   A2                  22.58\n",
       "   A3                   1.50\n",
       "   A4                   1.00\n",
       "   A5                   6.00\n",
       "   A6                   4.00\n",
       "   A7                   0.54\n",
       "   A8                   0.00\n",
       "   A9                   0.00\n",
       "   A10                  0.00\n",
       "   A11                  1.00\n",
       "   A12                  2.00\n",
       "   A13                120.00\n",
       "   A14                 68.00\n",
       "   Name: 41, dtype: float64],\n",
       "  'list_analyse': [[[('A3', 11.40160856996935),\n",
       "     ('A8', 7.769165132716921),\n",
       "     ('A10', 8.0),\n",
       "     ('A13', -411.1573245871435)],\n",
       "       from   to    effect\n",
       "    11   A3   A8  0.009500\n",
       "    2   A10   A3  0.199759\n",
       "    23   A3  A13 -7.625701\n",
       "    16  A10   A8  0.010143,\n",
       "    A3       1.5\n",
       "    A8       0.0\n",
       "    A10      0.0\n",
       "    A13    120.0\n",
       "    Name: 41, dtype: float64]],\n",
       "  'data_analysis': [{'df_respeita_causal':     from     to    effect  causal\n",
       "    11  mais   mais  0.009500    True\n",
       "    2   mais   mais  0.199759    True\n",
       "    23  mais  menos -7.625701    True\n",
       "    16  mais   mais  0.010143    True,\n",
       "    'contrafactual_causal': [('A3', 11.40160856996935),\n",
       "     ('A8', 7.769165132716921),\n",
       "     ('A10', 8.0),\n",
       "     ('A13', -411.1573245871435)],\n",
       "    'df_causal_effects':    from   to    effect\n",
       "    11   A3   A8  0.009500\n",
       "    2   A10   A3  0.199759\n",
       "    23   A3  A13 -7.625701\n",
       "    16  A10   A8  0.010143}]},\n",
       " 8: {'original_instance': CustomerID    15595010.00\n",
       "  A1                   1.00\n",
       "  A2                  34.17\n",
       "  A3                   9.17\n",
       "  A4                   2.00\n",
       "  A5                   8.00\n",
       "  A6                   4.00\n",
       "  A7                   4.50\n",
       "  A8                   1.00\n",
       "  A9                   1.00\n",
       "  A10                 12.00\n",
       "  A11                  1.00\n",
       "  A12                  2.00\n",
       "  A13                  0.00\n",
       "  A14                222.00\n",
       "  Name: 585, dtype: float64,\n",
       "  'causal_explain': [[[('A8', 0.0)]],\n",
       "   Empty DataFrame\n",
       "   Columns: [from, to, effect]\n",
       "   Index: [],\n",
       "   CustomerID    15595010.00\n",
       "   A1                   1.00\n",
       "   A2                  34.17\n",
       "   A3                   9.17\n",
       "   A4                   2.00\n",
       "   A5                   8.00\n",
       "   A6                   4.00\n",
       "   A7                   4.50\n",
       "   A8                   1.00\n",
       "   A9                   1.00\n",
       "   A10                 12.00\n",
       "   A11                  1.00\n",
       "   A12                  2.00\n",
       "   A13                  0.00\n",
       "   A14                222.00\n",
       "   Name: 585, dtype: float64],\n",
       "  'list_analyse': [[[('A8', 0.0)],\n",
       "    Empty DataFrame\n",
       "    Columns: [from, to, effect]\n",
       "    Index: [],\n",
       "    A8    1.0\n",
       "    Name: 585, dtype: float64]],\n",
       "  'data_analysis': [{'df_respeita_causal': Empty DataFrame\n",
       "    Columns: [from, to, effect, causal]\n",
       "    Index: [],\n",
       "    'contrafactual_causal': [('A8', 0.0)],\n",
       "    'df_causal_effects': Empty DataFrame\n",
       "    Columns: [from, to, effect]\n",
       "    Index: []}]},\n",
       " 9: {'original_instance': CustomerID    15723884.00\n",
       "  A1                   1.00\n",
       "  A2                  36.25\n",
       "  A3                   5.00\n",
       "  A4                   2.00\n",
       "  A5                   8.00\n",
       "  A6                   5.00\n",
       "  A7                   2.50\n",
       "  A8                   1.00\n",
       "  A9                   1.00\n",
       "  A10                  6.00\n",
       "  A11                  0.00\n",
       "  A12                  2.00\n",
       "  A13                  0.00\n",
       "  A14                368.00\n",
       "  Name: 93, dtype: float64,\n",
       "  'causal_explain': [[[('A8', 0.0)]],\n",
       "   Empty DataFrame\n",
       "   Columns: [from, to, effect]\n",
       "   Index: [],\n",
       "   CustomerID    15723884.00\n",
       "   A1                   1.00\n",
       "   A2                  36.25\n",
       "   A3                   5.00\n",
       "   A4                   2.00\n",
       "   A5                   8.00\n",
       "   A6                   5.00\n",
       "   A7                   2.50\n",
       "   A8                   1.00\n",
       "   A9                   1.00\n",
       "   A10                  6.00\n",
       "   A11                  0.00\n",
       "   A12                  2.00\n",
       "   A13                  0.00\n",
       "   A14                368.00\n",
       "   Name: 93, dtype: float64],\n",
       "  'list_analyse': [[[('A8', 0.0)],\n",
       "    Empty DataFrame\n",
       "    Columns: [from, to, effect]\n",
       "    Index: [],\n",
       "    A8    1.0\n",
       "    Name: 93, dtype: float64]],\n",
       "  'data_analysis': [{'df_respeita_causal': Empty DataFrame\n",
       "    Columns: [from, to, effect, causal]\n",
       "    Index: [],\n",
       "    'contrafactual_causal': [('A8', 0.0)],\n",
       "    'df_causal_effects': Empty DataFrame\n",
       "    Columns: [from, to, effect]\n",
       "    Index: []}]}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccsse.run_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "620a738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a47c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(val):\n",
    "            try:\n",
    "                return ast.literal_eval(val) if isinstance(val, str) and val.startswith('[') and val.endswith(']') else val\n",
    "            except (ValueError, SyntaxError):\n",
    "                return val\n",
    "            \n",
    "df = pd.read_parquet(\"datasets/df_map_inference_datasets.parquet\")\n",
    "df['path'] = df['path'].apply(convert_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf42445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map_inference_datasets.to_parquet(f\"s3://omar-testes-gerais/artigos/artifacts/df_map_inference_datasets.parquet\", engine = \"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a98f081a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult</td>\n",
       "      <td>adult/adult_processada.csv</td>\n",
       "      <td>Above/Below 50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australian</td>\n",
       "      <td>Australian/Credit_Card_Applications.csv</td>\n",
       "      <td>Class</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name                                     path           classe\n",
       "0       Adult               adult/adult_processada.csv  Above/Below 50K\n",
       "1  Australian  Australian/Credit_Card_Applications.csv            Class"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset = df_map_inference_datasets[df_map_inference_datasets['name'].isin(['Adult', 'Australian'])]\n",
    "df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68f9803d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult/adult_processada.csv moved\n",
      "Australian/Credit_Card_Applications.csv moved\n",
      "Banknote/BankNote_Authentication.csv moved\n",
      "Biodeg/qsar-biodeg.csv moved\n",
      "Breast Cancer Coimbra/breast_coimbra.csv moved\n",
      "Breast Cancer Wisconsin/breast-cancer.csv moved\n",
      "Churn/WA_Fn-UseC_-Telco-Customer-Churn_processada.csv moved\n",
      "Compas/compas-scores-two-years.csv moved\n",
      "Credit default/UCI_Credit_Card.csv moved\n",
      "Diabetes/diabetes.csv moved\n",
      "['Driving Behavior/train_motion_data.csv', 'Driving Behavior/test_motion_data.csv']\n",
      "Driving Behavior/train_motion_data.csv moved\n",
      "Driving Behavior/test_motion_data.csv moved\n",
      "EEg/EEG Eye State.csv moved\n",
      "German/german_credit.csv moved\n",
      "GiveMeSomeCredit/GiveMeSomeCredit_processada.csv moved\n",
      "Heart/heart.csv moved\n",
      "Heart/heart2.csv moved\n",
      "Heart Failure Prediction/heart_failure_clinical_records_dataset.csv moved\n",
      "HELOC/heloc_dataset_v1.csv moved\n",
      "['Hill/Hill_Valley_with_noise_Training.csv', 'Hill/Hill_Valley_with_noise_Testing.csv']\n",
      "Hill/Hill_Valley_with_noise_Training.csv moved\n",
      "Hill/Hill_Valley_with_noise_Testing.csv moved\n",
      "Horse colic/horseV2_processada.csv moved\n",
      "Indian Liver Patient Dataset/Indian Liver Patient Dataset_processada.csv moved\n",
      "Ionosfera/ionosphere.csv moved\n",
      "IRIS/Iris.csv moved\n",
      "KC2/KC2.csv moved\n",
      "liver disorders_bupa/bupa.csv moved\n",
      "Magic/telescope_data.csv moved\n",
      "mammographic_masses/mammographic_masses_cleaned.csv moved\n",
      "Mobile Price Classification/train_mobile_processada.csv moved\n",
      "['Monk/monks-1_train.csv', 'Monk/monks-1_test.csv']\n",
      "Monk/monks-1_train.csv moved\n",
      "Monk/monks-1_test.csv moved\n",
      "['Monk/monks-2_train.csv', 'Monk/monks-2_test.csv']\n",
      "Monk/monks-2_train.csv moved\n",
      "Monk/monks-2_test.csv moved\n",
      "['Monk/monks-3_train.csv', 'Monk/monks-3_test.csv']\n",
      "Monk/monks-3_train.csv moved\n",
      "Monk/monks-3_test.csv moved\n",
      "Mushrooms/mushrooms_processada.csv moved\n",
      "Musk/clean1.csv moved\n",
      "News popularity/OnlineNewsPopularity.csv moved\n",
      "no2/no2.csv moved\n",
      "OnlineNewsPopularity/OnlineNewsPopularity_processada.csv moved\n",
      "optdigits_csv/optdigits_csv.csv moved\n",
      "pc1/pc1.csv moved\n",
      "Phishing/Phishing.csv moved\n",
      "Phoneme/phoneme.csv moved\n",
      "Plasma/plasma.csv moved\n",
      "post-operative/post-operative-data.csv moved\n",
      "['price/train.csv', 'price/test.csv']\n",
      "price/train.csv moved\n",
      "price/test.csv moved\n",
      "Room Occupancy/Room Occupancy.csv moved\n",
      "seismic/seismic_processada.csv moved\n",
      "Shopping/e-shop clothing 2008.csv moved\n",
      "Sky Survey/Skyserver_SQL2_27_2018 6_51_39 PM.csv moved\n",
      "Sonar/sonar.all-data.csv moved\n",
      "Spambase/Spambase.csv moved\n",
      "Student/Students-Performance-MAT_processada.csv moved\n",
      "Tic-Tac-Toe/tic-tac-toe-endgame.csv moved\n",
      "titanic/titanic_processada.csv moved\n",
      "Tokyo/Tokyo.csv moved\n",
      "twonorm/twonorm.csv moved\n",
      "Vertebral/column_2C.csv moved\n",
      "Vertebral/column_3C.csv moved\n",
      "Votes_Congressional/house-votes-84_processada.csv moved\n",
      "wine/WineQT.csv moved\n",
      "xd6/xd6_dataset_csv.csv moved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "5     None\n",
       "6     None\n",
       "7     None\n",
       "8     None\n",
       "9     None\n",
       "10    None\n",
       "11    None\n",
       "12    None\n",
       "13    None\n",
       "14    None\n",
       "15    None\n",
       "16    None\n",
       "17    None\n",
       "18    None\n",
       "19    None\n",
       "20    None\n",
       "21    None\n",
       "22    None\n",
       "23    None\n",
       "24    None\n",
       "25    None\n",
       "26    None\n",
       "27    None\n",
       "28    None\n",
       "29    None\n",
       "30    None\n",
       "31    None\n",
       "32    None\n",
       "33    None\n",
       "34    None\n",
       "35    None\n",
       "36    None\n",
       "37    None\n",
       "38    None\n",
       "39    None\n",
       "40    None\n",
       "41    None\n",
       "42    None\n",
       "43    None\n",
       "44    None\n",
       "45    None\n",
       "46    None\n",
       "47    None\n",
       "48    None\n",
       "49    None\n",
       "50    None\n",
       "51    None\n",
       "52    None\n",
       "53    None\n",
       "54    None\n",
       "55    None\n",
       "56    None\n",
       "57    None\n",
       "58    None\n",
       "Name: path, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "s3 = boto3.client('s3')\n",
    "def move_to_s3(local_path):\n",
    "    if isinstance(local_path, list):\n",
    "        print(local_path)\n",
    "        for path in local_path:\n",
    "            s3.upload_file(f\"datasets/drive_raw/{path}\", 'omar-testes-gerais', f\"artigos/artifacts/datasets/{path}\")\n",
    "            print(f'{path} moved')\n",
    "    else:\n",
    "        s3.upload_file(f\"datasets/drive_raw/{local_path}\", 'omar-testes-gerais', f\"artigos/artifacts/datasets/{local_path}\")\n",
    "        print(f'{local_path} moved')\n",
    "    \n",
    "df['path'].apply(move_to_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c14c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "    \"grupo_1\": [\"Adult 24 Média Mista\", \"Banknote 4 Pequena Numérica\", \"KC2 21 Média Numérica\", \"Titanic 26 Média Mista\"],\n",
    "    \"grupo_2\": [\"Australian 14 Média Mista\", \"Breast Cancer Coimbra 9 Pequena Numérica\", \"Liver disorders 6 Pequena Numérica\", \"Room Occupancy 5 Pequena Numérica\"],\n",
    "    \"grupo_3\": [\"Compas 11 Pequena Mista\", \"Ionosphere 33 Grande Numérica\", \"Vertebral Column 6 Pequena Numérica\", \"Give Me Some Credit 10 Pequena Numérica\"],\n",
    "    \"grupo_4\": [\"Breast Cancer Wisconsin 29 Grande Numérica\", \"Diabetes 8 Pequena Numérica\", \"Phishing Websites 30 Grande Categórica\", \"Horse colic 27 Grande Categórica\"],\n",
    "    \"grupo_5\": [\"Churn 40 Grande Categórica\", \"Heart 13 Média Mista\", \"Mammographic masses 5 Pequena Categórica\", \"Wine 11 Média Numérica\"],\n",
    "    \"grupo_6\": [\"Default of credit card clients 23 Média Numérica\", \"Hill_Valley 100 Grande Numérica\", \"Mobile Price Classification 20 Média Numérica\", \"Monk1 6 Pequena Categórica\"],\n",
    "    \"grupo_7\": [\"EEG Eye State 14 Média Numérica\", \"German 20 Média Mista\", \"Monk2 6 Pequena Categórica\", \"Mofn-3-7-10 10 Pequena Categórica\"],\n",
    "    \"grupo_8\": [\"HELOC 23 Média Numérica\", \"Mushrooms 138 Grande Categórica\", \"QSAR biodegradation 41 Grande Numérica\", \"Sonar 60 Grande Numérica\"],\n",
    "    \"grupo_9\": [\"Monk3 6 Pequena Categórica\", \"MUSK 166 Grande Numérica\", \"Spambase 57 Grande Numérica\", \"Student Performance - MAT 43 Grande Mista\"],\n",
    "    \"grupo_10\": [\"Online news popularity 58 Grande Numérica\", \"Tokyo1 42 Grande Numérica\", \"Twonorm 20 Média Numérica\", \"Votes 16 Média Categórica\"]\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
