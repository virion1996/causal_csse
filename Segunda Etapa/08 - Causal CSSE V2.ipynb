{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a2af60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Using cached numpy-2.2.6-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\omarkrauss\\desktop\\pessoal\\tcc\\tcc\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\omarkrauss\\desktop\\pessoal\\tcc\\tcc\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Using cached numpy-2.2.6-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.2.6 pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\omarkrauss\\desktop\\pessoal\\tcc\\tcc\\.venv\\lib\\site-packages (from scikit-learn) (2.2.6)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "Using cached joblib-1.5.0-py3-none-any.whl (307 kB)\n",
      "Using cached scipy-1.15.3-cp312-cp312-win_amd64.whl (41.0 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.0 scikit-learn-1.6.1 scipy-1.15.3 threadpoolctl-3.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lingam\n",
      "  Downloading lingam-1.9.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\omarkrauss\\desktop\\pessoal\\tcc\\tcc\\.venv\\lib\\site-packages (from lingam) (2.2.6)\n",
      "Requirement already satisfied: scipy in c:\\users\\omarkrauss\\desktop\\pessoal\\tcc\\tcc\\.venv\\lib\\site-packages (from lingam) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\omarkrauss\\desktop\\pessoal\\tcc\\tcc\\.venv\\lib\\site-packages (from lingam) (1.6.1)\n",
      "Collecting graphviz (from lingam)\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting statsmodels (from lingam)\n",
      "  Downloading statsmodels-0.14.4-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting networkx (from lingam)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\omarkrauss\\desktop\\pessoal\\tcc\\tcc\\.venv\\lib\\site-packages (from lingam) (2.2.3)\n",
      "Collecting pygam (from lingam)\n",
      "  Downloading pygam-0.9.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting matplotlib (from lingam)\n",
      "  Using cached matplotlib-3.10.3-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting psy (from lingam)\n",
      "  Downloading psy-0.0.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting semopy (from lingam)\n",
      "  Downloading semopy-2.3.11.tar.gz (1.6 MB)\n",
      "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.6/1.6 MB 8.0 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->lingam)\n",
      "  Using cached contourpy-1.3.2-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->lingam)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->lingam)\n",
      "  Using cached fonttools-4.58.0-cp312-cp312-win_amd64.whl.metadata (106 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->lingam)\n",
      "  Using cached kiwisolver-1.4.8-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\omarkrauss\\desktop\\pessoal\\tcc\\tcc\\.venv\\lib\\site-packages (from matplotlib->lingam) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib->lingam)\n",
      "  Using cached pillow-11.2.1-cp312-cp312-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->lingam)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\omarkrauss\\desktop\\pessoal\\tcc\\tcc\\.venv\\lib\\site-packages (from matplotlib->lingam) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\omarkrauss\\desktop\\pessoal\\tcc\\tcc\\.venv\\lib\\site-packages (from pandas->lingam) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\omarkrauss\\desktop\\pessoal\\tcc\\tcc\\.venv\\lib\\site-packages (from pandas->lingam) (2025.2)\n",
      "Collecting progressbar2 (from psy->lingam)\n",
      "  Downloading progressbar2-4.5.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting scipy (from lingam)\n",
      "  Downloading scipy-1.11.4-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting numpy (from lingam)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\omarkrauss\\desktop\\pessoal\\tcc\\tcc\\.venv\\lib\\site-packages (from scikit-learn->lingam) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\omarkrauss\\desktop\\pessoal\\tcc\\tcc\\.venv\\lib\\site-packages (from scikit-learn->lingam) (3.6.0)\n",
      "Collecting sympy (from semopy->lingam)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting numdifftools (from semopy->lingam)\n",
      "  Downloading numdifftools-0.9.41-py2.py3-none-any.whl.metadata (39 kB)\n",
      "Collecting patsy>=0.5.6 (from statsmodels->lingam)\n",
      "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting python-utils>=3.8.1 (from progressbar2->psy->lingam)\n",
      "  Downloading python_utils-3.9.1-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\omarkrauss\\desktop\\pessoal\\tcc\\tcc\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->lingam) (1.17.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->semopy->lingam)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting typing_extensions>3.10.0.2 (from python-utils>=3.8.1->progressbar2->psy->lingam)\n",
      "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Downloading lingam-1.9.1-py3-none-any.whl (103 kB)\n",
      "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "Using cached matplotlib-3.10.3-cp312-cp312-win_amd64.whl (8.1 MB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Downloading psy-0.0.1-py2.py3-none-any.whl (38 kB)\n",
      "Downloading pygam-0.9.1-py3-none-any.whl (522 kB)\n",
      "Downloading scipy-1.11.4-cp312-cp312-win_amd64.whl (43.7 MB)\n",
      "   ---------------------------------------- 0.0/43.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 5.2/43.7 MB 45.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 12.6/43.7 MB 31.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 22.0/43.7 MB 35.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 32.5/43.7 MB 39.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 37.7/43.7 MB 36.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 43.7/43.7 MB 36.6 MB/s eta 0:00:00\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Downloading statsmodels-0.14.4-cp312-cp312-win_amd64.whl (9.8 MB)\n",
      "   ---------------------------------------- 0.0/9.8 MB ? eta -:--:--\n",
      "   ---------------------------------------  9.7/9.8 MB 54.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.8/9.8 MB 47.1 MB/s eta 0:00:00\n",
      "Using cached contourpy-1.3.2-cp312-cp312-win_amd64.whl (223 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.58.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "Using cached kiwisolver-1.4.8-cp312-cp312-win_amd64.whl (71 kB)\n",
      "Downloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Using cached pillow-11.2.1-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "Downloading progressbar2-4.5.0-py3-none-any.whl (57 kB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading numdifftools-0.9.41-py2.py3-none-any.whl (100 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.3/6.3 MB 42.8 MB/s eta 0:00:00\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading python_utils-3.9.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Building wheels for collected packages: semopy\n",
      "  Building wheel for semopy (pyproject.toml): started\n",
      "  Building wheel for semopy (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for semopy: filename=semopy-2.3.11-py3-none-any.whl size=1659795 sha256=a074d54fc30d0812840f2476c8497abb0982067d7aa7e0b5ac5493871fdc64fa\n",
      "  Stored in directory: c:\\users\\omarkrauss\\appdata\\local\\pip\\cache\\wheels\\c6\\24\\8b\\be911b059a61f490f38425eb19bf2fed470a5ead97228e8255\n",
      "Successfully built semopy\n",
      "Installing collected packages: mpmath, typing_extensions, sympy, pyparsing, pillow, numpy, networkx, kiwisolver, graphviz, fonttools, cycler, scipy, python-utils, patsy, contourpy, statsmodels, progressbar2, numdifftools, matplotlib, semopy, pygam, psy, lingam\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.15.3\n",
      "    Uninstalling scipy-1.15.3:\n",
      "      Successfully uninstalled scipy-1.15.3\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.0 graphviz-0.20.3 kiwisolver-1.4.8 lingam-1.9.1 matplotlib-3.10.3 mpmath-1.3.0 networkx-3.4.2 numdifftools-0.9.41 numpy-1.26.4 patsy-1.0.1 pillow-11.2.1 progressbar2-4.5.0 psy-0.0.1 pygam-0.9.1 pyparsing-3.2.3 python-utils-3.9.1 scipy-1.11.4 semopy-2.3.11 statsmodels-0.14.4 sympy-1.14.0 typing_extensions-4.13.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fsspec\n",
      "  Downloading fsspec-2025.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Downloading fsspec-2025.5.0-py3-none-any.whl (196 kB)\n",
      "Installing collected packages: fsspec\n",
      "Successfully installed fsspec-2025.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting s3fs\n",
      "  Downloading s3fs-2025.5.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs)\n",
      "  Downloading aiobotocore-2.22.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: fsspec==2025.5.0 in c:\\users\\omarkrauss\\desktop\\pessoal\\tcc\\tcc\\.venv\\lib\\site-packages (from s3fs) (2025.5.0)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from s3fs)\n",
      "  Downloading aiohttp-3.11.18-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs)\n",
      "  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting botocore<1.37.4,>=1.37.2 (from aiobotocore<3.0.0,>=2.5.4->s3fs)\n",
      "  Downloading botocore-1.37.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\omarkrauss\\desktop\\pessoal\\tcc\\tcc\\.venv\\lib\\site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (2.9.0.post0)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting multidict<7.0.0,>=6.0.0 (from aiobotocore<3.0.0,>=2.5.4->s3fs)\n",
      "  Downloading multidict-6.4.4-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting wrapt<2.0.0,>=1.10.10 (from aiobotocore<3.0.0,>=2.5.4->s3fs)\n",
      "  Using cached wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
      "  Downloading frozenlist-1.6.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
      "  Using cached propcache-0.3.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
      "  Downloading yarl-1.20.0-cp312-cp312-win_amd64.whl.metadata (74 kB)\n",
      "Collecting urllib3!=2.2.0,<3,>=1.25.4 (from botocore<1.37.4,>=1.37.2->aiobotocore<3.0.0,>=2.5.4->s3fs)\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\omarkrauss\\desktop\\pessoal\\tcc\\tcc\\.venv\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->aiobotocore<3.0.0,>=2.5.4->s3fs) (1.17.0)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Downloading s3fs-2025.5.0-py3-none-any.whl (30 kB)\n",
      "Downloading aiobotocore-2.22.0-py3-none-any.whl (78 kB)\n",
      "Downloading aiohttp-3.11.18-cp312-cp312-win_amd64.whl (439 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading botocore-1.37.3-py3-none-any.whl (13.3 MB)\n",
      "   ---------------------------------------- 0.0/13.3 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 9.7/13.3 MB 46.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.3/13.3 MB 39.9 MB/s eta 0:00:00\n",
      "Downloading frozenlist-1.6.0-cp312-cp312-win_amd64.whl (120 kB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading multidict-6.4.4-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Using cached propcache-0.3.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Using cached wrapt-1.17.2-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Downloading yarl-1.20.0-cp312-cp312-win_amd64.whl (92 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: wrapt, urllib3, propcache, multidict, jmespath, idna, frozenlist, attrs, aioitertools, aiohappyeyeballs, yarl, botocore, aiosignal, aiohttp, aiobotocore, s3fs\n",
      "Successfully installed aiobotocore-2.22.0 aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aioitertools-0.12.0 aiosignal-1.3.2 attrs-25.3.0 botocore-1.37.3 frozenlist-1.6.0 idna-3.10 jmespath-1.0.1 multidict-6.4.4 propcache-0.3.1 s3fs-2025.5.0 urllib3-2.4.0 wrapt-1.17.2 yarl-1.20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Using cached pyarrow-20.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Using cached pyarrow-20.0.0-cp312-cp312-win_amd64.whl (25.7 MB)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-20.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install lingam\n",
    "!pip install fsspec\n",
    "!pip install s3fs\n",
    "!pip install pyarrow\n",
    "\n",
    "!pip install ydata-profiling\n",
    "!pip install --upgrade --force-reinstall setuptools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "306163f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OmarKrauss\\Desktop\\pessoal\\tcc\\tcc\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "# os.system(\"pip install lingam\")\n",
    "# os.system(\"pip install fsspec\")\n",
    "# os.system(\"pip install s3fs\")\n",
    "# os.system(\"pip install pyarrow\")\n",
    "\n",
    "import random as rnd\n",
    "from scipy.spatial import distance\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "import sys\n",
    "import argparse\n",
    "import ast\n",
    "import time\n",
    "import json\n",
    "\n",
    "#German\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "from scipy.stats import normaltest\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "import lingam\n",
    "from lingam.utils import print_causal_directions, print_dagc, make_dot\n",
    "\n",
    "import random as rnd\n",
    "\n",
    "# from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc14207",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.system(\"pip install lingam\")\n",
    "# os.system(\"pip install fsspec\")\n",
    "# os.system(\"pip install s3fs\")\n",
    "# os.system(\"pip install pyarrow\")\n",
    "\n",
    "import random as rnd\n",
    "from scipy.spatial import distance\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "import sys\n",
    "import argparse\n",
    "import ast\n",
    "import time\n",
    "import json\n",
    "\n",
    "#German\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "from scipy.stats import normaltest\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "import lingam\n",
    "from lingam.utils import print_causal_directions, print_dagc, make_dot\n",
    "\n",
    "import random as rnd\n",
    "\n",
    "# from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# s3 = boto3.client('s3')\n",
    "\n",
    "#Used for ordering evaluations\n",
    "class individual:\n",
    "    def __init__(self, index, score, distance, num_changes, aval_norm, dist_norm, predict_proba):\n",
    "        self.index = index #Indicates the instance's position in the dataframe\n",
    "        self.score = score #Indicates the score in relation to the proximity of the class boundary\n",
    "        self.distance = distance #Indicates the distance from the original instance\n",
    "        self.num_changes = num_changes #Indicates the number of changes for class change\n",
    "        self.aval_norm = aval_norm #Indicates the final fitness with standardized metrics\n",
    "        self.dist_norm = dist_norm #Indicates the normalized distance (distance and number of changes)\n",
    "        self.predict_proba = predict_proba #Indicates de individual's class\n",
    "    def __repr__(self):\n",
    "        return repr((self.index, self.score, self.distance, self.num_changes, self.aval_norm, self.dist_norm, self.predict_proba))\n",
    "\n",
    "class counter_change:\n",
    "    def __init__(self, column, value):\n",
    "        self.column = column \n",
    "        self.value = value\n",
    "    def __eq__(self, other):\n",
    "        if self.column == other.column and self.value == other.value:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    def __repr__(self):\n",
    "        return repr((self.column, self.value))    \n",
    "\n",
    "#Used to generate a random value in the mutation operation\n",
    "class feature_range:\n",
    "    def __init__(self, column, col_type, min_value, max_value):\n",
    "        self.column = column \n",
    "        self.col_type = col_type\n",
    "        self.min_value = min_value\n",
    "        self.max_value = max_value\n",
    "\n",
    "    #Returns a random value to perform mutation operation\n",
    "    def get_random_value(self):\n",
    "        if self.col_type == 'int64' or self.col_type == 'int' or self.col_type == 'int16' or self.col_type == 'int8' or (self.col_type == 'uint8'):\n",
    "            value = rnd.randint(self.min_value, self.max_value)\n",
    "        else:  \n",
    "            value = round(rnd.uniform(self.min_value, self.max_value), 2)\n",
    "        return value\n",
    "    \n",
    "    #Checks if the attribute has only one value.\n",
    "    def unique_value(self):\n",
    "        if self.min_value != self.max_value:\n",
    "            return False\n",
    "        else:  \n",
    "            return True    \n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr((self.column, self.col_type, self.min_value, self.max_value)) \n",
    "        \n",
    "class CSSE(object):\n",
    "    \n",
    "    def __init__(self, input_dataset, model, static_list = [], K = 3, num_gen = 30, pop_size = 100, per_elit = 0.1, cros_proba = 0.8, mutation_proba = 0.1, L1 = 1, L2 = 1):\n",
    "        #User Options\n",
    "        self.static_list = static_list #List of static features\n",
    "        self.K = K #Number of counterfactuals desired\n",
    "        #Model\n",
    "        self.input_dataset = input_dataset\n",
    "        self.model = model\n",
    "        #GA Parameters\n",
    "        self.num_gen = num_gen\n",
    "        self.pop_size = pop_size\n",
    "        self.per_elit = per_elit\n",
    "        self.cros_proba = cros_proba\n",
    "        self.mutation_proba = mutation_proba\n",
    "        #Objective function parameters\n",
    "        self.L1 = L1 #weight assigned the distance to the original instance\n",
    "        self.L2 = L2 #weight assigned the number of changes needed in the original instance   \n",
    "    \n",
    "    #Get which index in the SHAP corresponding to the current class\n",
    "    def getBadClass(self):   \n",
    "        if self.current_class == self.model.classes_[0]:\n",
    "            ind_cur_class = 0\n",
    "        else:\n",
    "            ind_cur_class = 1\n",
    "        \n",
    "        return ind_cur_class\n",
    "    \n",
    "    #Gets the valid values range for each feature\n",
    "    def getFeaturesRange(self):\n",
    "        features_range = []\n",
    "       \n",
    "        for i in range (0, self.input_dataset.columns.size):\n",
    "            col_name = self.input_dataset.columns[i]\n",
    "            col_type = self.input_dataset[col_name].dtype\n",
    "            min_value = min(self.input_dataset[col_name])\n",
    "            max_value = max(self.input_dataset[col_name])\n",
    "            \n",
    "            feature_range_ind = feature_range(col_name, col_type, min_value, max_value)\n",
    "            features_range.append(feature_range_ind)\n",
    "        \n",
    "        return features_range\n",
    "       \n",
    "    def getMutationValue(self, currentValue, index, ind_feature_range):\n",
    "        new_value = ind_feature_range.get_random_value()\n",
    "        \n",
    "        while currentValue == new_value:\n",
    "            new_value = ind_feature_range.get_random_value()\n",
    "        \n",
    "        return new_value\n",
    "    \n",
    "    def equal(self, individual, population):\n",
    "        aux = 0\n",
    "        for i in range ( 1, len(population)):\n",
    "            c = population.loc[i].copy()\n",
    "            dst = distance.euclidean(individual, c)\n",
    "            if dst == 0:\n",
    "                aux = 1\n",
    "        \n",
    "        return aux\n",
    "\n",
    "    def getPopInicial (self, df, features_range): \n",
    "        #The reference individual will always be in the 0 position of the df - so that it is normalized as well (it will be used later in the distance function)\n",
    "        df.loc[0] = self.original_ind.copy()\n",
    "        \n",
    "        #Counting numbers of repeated individuals\n",
    "        number_repetitions = 0\n",
    "        \n",
    "        #One more position is used because the zero position was reserved for the reference individual\n",
    "        while len(df) < self.pop_size + 1:\n",
    "            #Draw a feature to change\n",
    "            index_a = rnd.randint( 0, self.input_dataset.columns.size - 1 )\n",
    "            while df.columns[index_a] in self.static_list:\n",
    "                index_a = rnd.randint( 0, self.input_dataset.columns.size - 1 )\n",
    "                \n",
    "            if not features_range[index_a].unique_value():\n",
    "                #Mutation\n",
    "                mutant = self.original_ind.copy()\n",
    "\n",
    "                new_value =  self.getMutationValue(mutant.iloc[index_a], index_a, features_range[index_a])\n",
    "                mutant.iloc[index_a] = new_value\n",
    "\n",
    "                ni = self.equal(mutant, df)\n",
    "                if ni == 0:\n",
    "                    df.loc[len(df)] = mutant.copy()\n",
    "                else:\n",
    "                    #Assesses whether the GA is producing too many repeated individuals.\n",
    "                    number_repetitions = number_repetitions + 1\n",
    "                    if number_repetitions == 2*self.pop_size:\n",
    "                        self.pop_size = round(self.pop_size - self.pop_size*0.1)\n",
    "                        self.mutation_proba = self.mutation_proba + 0.1\n",
    "                        #print('Adjusting population size...', self.pop_size)\n",
    "                        number_repetitions = 0\n",
    "    \n",
    "    #Complete the standardized proximity and similarity assessments for each individual\n",
    "    def getNormalEvaluation(self, evaluation, aval_norma):\n",
    "        scaler2 = preprocessing.MinMaxScaler()\n",
    "        aval_norma2 = scaler2.fit_transform(aval_norma)\n",
    "    \n",
    "        i = 0\n",
    "        while i < len(evaluation):\n",
    "            evaluation[i].aval_norm = self.L1*aval_norma2[i,0] + self.L2*aval_norma2[i,1] + aval_norma2[i,2]\n",
    "            evaluation[i].dist_norm = self.L1*aval_norma2[i,0] + self.L2*aval_norma2[i,1]\n",
    "        \n",
    "            i = i + 1\n",
    "    \n",
    "    def numChanges(self, ind_con):\n",
    "        num = 0\n",
    "        for i in range(len(self.original_ind)):\n",
    "            if self.original_ind[i] != ind_con[i]:\n",
    "                num = num + 1\n",
    "        \n",
    "        return num\n",
    "        \n",
    "    def fitness(self, population, evaluation, ind_cur_class):\n",
    "        def getProximityEvaluation (proba):\n",
    "            #Penalizes the individual who is in the negative class\n",
    "            if proba < 0.5:\n",
    "                predict_score = 0\n",
    "            else:\n",
    "                predict_score= proba\n",
    "             \n",
    "            return predict_score\n",
    "               \n",
    "        #Calculates similarity to the original instance\n",
    "        def getEvaluationDist (ind, X_train_minmax):\n",
    "            #Normalizes the data so that the different scales do not bias the distance\n",
    "            a = X_train_minmax[0]\n",
    "            b = X_train_minmax[ind]\n",
    "            dst = distance.euclidean(a, b)\n",
    "  \n",
    "            return dst\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "        \n",
    "            predict_proba = self.model.predict_proba(population)\n",
    "                    \n",
    "        #Calculating the distance between instances\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "        X_train_minmax = scaler.fit_transform(population)\n",
    "    \n",
    "        i = 0\n",
    "        aval_norma = [] \n",
    "        while i < len(population):\n",
    "            proximityEvaluation = getProximityEvaluation(predict_proba[i, ind_cur_class])\n",
    "            evaldist = getEvaluationDist(i, X_train_minmax)\n",
    "            #The original individual is in the 1st position\n",
    "            numChanges = self.numChanges(population.loc[i])\n",
    "        \n",
    "            ind = individual(i, proximityEvaluation, evaldist, numChanges, 0, 0, predict_proba[i, ind_cur_class])\n",
    "            aval_norma.append([evaldist, numChanges, proximityEvaluation])\n",
    "            evaluation.append(ind)\n",
    "            i = i + 1\n",
    "\n",
    "        self.getNormalEvaluation(evaluation, aval_norma)\n",
    "       \n",
    "    #Given a counterfactual solution returns the list of modified columns\n",
    "    def getColumns(self, counter_solution):\n",
    "        colums = []\n",
    "        for j in range (0, len(counter_solution)):\n",
    "            colums.append(counter_solution[j].column)\n",
    "        \n",
    "        return colums      \n",
    "             \n",
    "    #Checks if the new solution is contained in the solutions already found\n",
    "    def contained_solution(self, original_instance, current_list, current_column_list, new_solution, new_column_solution):\n",
    "        contained = False\n",
    "        for i in range (0, len(current_list)):              \n",
    "            if set(current_column_list[i]).issubset(new_column_solution):\n",
    "                for j in range (0, len(current_list[i])):\n",
    "                    pos = new_column_solution.index(current_list[i][j].column)\n",
    "                    distancia_a = abs(original_instance[current_list[i][j].column] - current_list[i][j].value)\n",
    "                    distancia_b = abs(original_instance[current_list[i][j].column] - new_solution[pos].value)\n",
    "                    if distancia_b >= distancia_a:\n",
    "                        contained = True\n",
    "\n",
    "        return contained\n",
    "      \n",
    "    def elitism(self, evaluation, df, parents):\n",
    "         \n",
    "        num_elit = round(self.per_elit*self.pop_size)\n",
    "        \n",
    "        aval = []\n",
    "        aval = evaluation.copy()\n",
    "        aval.sort(key=lambda individual: individual.aval_norm)\n",
    "        \n",
    "        #contrafactual_ind = pd.DataFrame(columns=self.input_dataset.columns)\n",
    "        solution_list = []\n",
    "        solution_colums_list = []\n",
    "        \n",
    "        i = 0\n",
    "        numContraf = 0\n",
    "        while i < len(aval) and numContraf <= num_elit + 1:\n",
    "            #Checks if the example belongs to the counterfactual class\n",
    "            if aval[i].predict_proba < 0.5:\n",
    "                ind_changes = []\n",
    "                ind_colums_change = []\n",
    "         \n",
    "                #Gets counterfactual example change list\n",
    "                ind_changes = self.getChanges(aval[i].index, parents)\n",
    "                #Generates the list of columns modified in the counterfactual to check if there is already a solution with that set of columns\n",
    "                ind_colums_change = self.getColumns(ind_changes)\n",
    "                \n",
    "                if ind_colums_change not in solution_colums_list:\n",
    "                    #Check if one solution is a subset of the other\n",
    "                    if not self.contained_solution(self.original_ind, solution_list, solution_colums_list, ind_changes, ind_colums_change):\n",
    "                        #Include counterfactual in the list of examples of the final solution                    \n",
    "                        df.loc[len(df)] = parents.iloc[aval[i].index].copy()                     \n",
    "                                \n",
    "                        #Add to the list of solutions (changes only)       \n",
    "                        solution_list.append(ind_changes)\n",
    "                        #Used to compare with the next counterfactuals (to ensure diversity)\n",
    "                        solution_colums_list.append(ind_colums_change)\n",
    "                                        \n",
    "                        numContraf = numContraf + 1\n",
    "                      \n",
    "            i = i + 1\n",
    "        return solution_list\n",
    "    \n",
    "    def roulette_wheel(self, evaluation):\n",
    "        summation = 0\n",
    "        #Performs roulette wheel to select parents who will undergo genetic operations\n",
    "        for i in range (1, len(evaluation)): \n",
    "            summation = summation + 1/evaluation[i].aval_norm\n",
    "    \n",
    "        roulette = rnd.uniform( 0, summation )\n",
    "    \n",
    "        roulette_score = 1/evaluation[1].aval_norm\n",
    "        i = 1\n",
    "        while roulette_score < roulette:\n",
    "            i += 1\n",
    "            roulette_score += 1/evaluation[i].aval_norm\n",
    "        \n",
    "        return i\n",
    "            \n",
    "    def crossover (self, df, parents, evaluation, number_cross_repetitions):\n",
    "        child = []\n",
    "            \n",
    "        corte = rnd.randint( 0, self.input_dataset.columns.size - 1 )\n",
    "            \n",
    "        index1 = self.roulette_wheel(evaluation)\n",
    "        index2 = self.roulette_wheel(evaluation)\n",
    "        \n",
    "        ind_a = parents.iloc[index1].copy()\n",
    "        ind_b = parents.iloc[index2].copy()\n",
    "            \n",
    "        crossover_op = rnd.random()\n",
    "        if crossover_op <= self.cros_proba:\n",
    "            child[ :corte ] = ind_a[ :corte ].copy()\n",
    "            child[ corte: ] = ind_b[ corte: ].copy()\n",
    "        else:\n",
    "            child = ind_a.copy()\n",
    "        \n",
    "        ni = self.equal(child, df)\n",
    "        if ni == 0:\n",
    "            df.loc[len(df)] = child.copy()\n",
    "        else:\n",
    "            #Assesses whether the GA is producing too many repeated individuals.\n",
    "            number_cross_repetitions = number_cross_repetitions + 1\n",
    "            if number_cross_repetitions == self.pop_size:\n",
    "                self.pop_size = round(self.pop_size - self.pop_size*0.1)\n",
    "                self.mutation_proba = self.mutation_proba + 0.1\n",
    "                #print('Adjusting population size...', self.pop_size)\n",
    "                number_cross_repetitions = 0\n",
    "        #    print('repeated')\n",
    "        return number_cross_repetitions\n",
    "                       \n",
    "    def mutation (self, df, individual_pos, features_range):\n",
    "        ni = 1\n",
    "        #Does not allow repeated individual\n",
    "        while ni == 1:\n",
    "            #Draw a feature to change\n",
    "            index_a = rnd.randint( 0, self.input_dataset.columns.size - 1 )\n",
    "            while df.columns[index_a] in self.static_list:\n",
    "                index_a = rnd.randint( 0, self.input_dataset.columns.size - 1 )\n",
    "            \n",
    "            if not features_range[index_a].unique_value():\n",
    "                #Mutation\n",
    "                mutant = df.iloc[individual_pos].copy()\n",
    "            \n",
    "                #Draw the value to be changed\n",
    "                new_value =  self.getMutationValue(mutant.iloc[index_a], index_a, features_range[index_a])  \n",
    "                mutant.iloc[index_a] = new_value\n",
    "\n",
    "                ni = self.equal(mutant, df)\n",
    "                if ni == 0:\n",
    "                    df.loc[individual_pos] = mutant.copy()\n",
    "                #else:\n",
    "                #    print('repeated')\n",
    "     \n",
    "    def getChanges(self, ind, dfComp):\n",
    "        changes = []\n",
    "        \n",
    "        for i in range (len(dfComp.iloc[ind])):\n",
    "            if self.original_ind[i] != dfComp.loc[ind][i]:\n",
    "                counter_change_ind = counter_change(dfComp.columns[i], dfComp.loc[ind][i])\n",
    "                changes.append(counter_change_ind)\n",
    "\n",
    "        return changes\n",
    "    \n",
    "    #Generates the solution from the final population\n",
    "    def getContrafactual(self, df, aval):\n",
    "        \n",
    "        contrafactual_ind = pd.DataFrame(columns=self.input_dataset.columns)\n",
    "        solution_list = []\n",
    "        solution_colums_list = []\n",
    "        \n",
    "        i = 0\n",
    "        numContraf = 0\n",
    "        while i < len(aval) and numContraf < self.K:\n",
    "            #Checks if the example belongs to the counterfactual class\n",
    "            if aval[i].predict_proba < 0.5:\n",
    "                ind_changes = []\n",
    "                ind_colums_change = []\n",
    "         \n",
    "                #Gets counterfactual example change list\n",
    "                ind_changes = self.getChanges(aval[i].index, df)\n",
    "                #Generates the list of columns modified in the counterfactual to check if there is already a solution with that set of columns\n",
    "                ind_colums_change = self.getColumns(ind_changes)\n",
    "                \n",
    "                if ind_colums_change not in solution_colums_list:\n",
    "                    #Check if one solution is a subset of the other\n",
    "                    if not self.contained_solution(self.original_ind, solution_list, solution_colums_list, ind_changes, ind_colums_change):\n",
    "                        #Include counterfactual in the list of examples of the final solution\n",
    "                        contrafactual_ind.loc[len(contrafactual_ind)] = df.iloc[aval[i].index].copy()\n",
    "                                \n",
    "                        #Add to the list of solutions (changes only)       \n",
    "                        solution_list.append(ind_changes)\n",
    "                        #Used to compare with the next counterfactuals (to ensure diversity)\n",
    "                        solution_colums_list.append(ind_colums_change)\n",
    "                                        \n",
    "                        numContraf = numContraf + 1\n",
    "                        #print('solution_list ', solution_list)\n",
    "                    #else:\n",
    "                        #print('is contained ', ind_changes)\n",
    "                #else:\n",
    "                    #print('repeated ', ind_changes)\n",
    "                      \n",
    "            i = i + 1\n",
    "\n",
    "        return contrafactual_ind, solution_list   \n",
    "    \n",
    "    def printResults(self, solution):\n",
    "        print(\"Result obtained\")\n",
    "        if len(solution) != 0:\n",
    "            for i in range(0, len(solution)): \n",
    "                print(\"\\n\")\n",
    "                print(f\"{'Counterfactual ' + str(i + 1):^34}\")\n",
    "                for j in range(0, len(solution[i])): \n",
    "                    print(f\"{str(solution[i][j].column):<29} {str(solution[i][j].value):>5}\")\n",
    "        else:\n",
    "            print('Solution not found. It may be necessary to adjust the parameters for this instance.')\n",
    "                                                 \n",
    "    def explain(self, original_ind, current_class):\n",
    "        self.original_ind = original_ind #Original instance\n",
    "        #self.ind_cur_class = ind_cur_class #Index in the shap corresponds to the original instance class\n",
    "        self.current_class = current_class #Original instance class\n",
    "        \n",
    "        ind_cur_class = self.getBadClass()\n",
    "    \n",
    "        #Gets the valid values range of each feature\n",
    "        features_range = []\n",
    "        features_range = self.getFeaturesRange()\n",
    "\n",
    "        #The DataFrame df will have the current population\n",
    "        df = pd.DataFrame(columns=self.input_dataset.columns)\n",
    "        \n",
    "        #Generates the initial population with popinitial mutants        \n",
    "        self.getPopInicial(df, features_range)\n",
    "        for g in range(self.num_gen):\n",
    "            #To use on the parents of each generation\n",
    "            parents = pd.DataFrame(columns=self.input_dataset.columns)\n",
    "    \n",
    "            #Copy parents to the next generation\n",
    "            parents = df.copy()\n",
    "            #df will contain the new population\n",
    "            df = pd.DataFrame(columns=self.input_dataset.columns)\n",
    "            \n",
    "            evaluation = []                         \n",
    "                   \n",
    "            #Assessing generation counterfactuals\n",
    "            self.fitness(parents, evaluation, ind_cur_class)\n",
    "            #The original individual will always be in the 0 position of the df - So that it is normalized too (it will be used later in the distance function)\n",
    "            df.loc[0] = self.original_ind.copy()\n",
    "            \n",
    "            #Copies to the next generation the per_elit best individuals\n",
    "            self.elitism(evaluation, df, parents)\n",
    "            number_cross_repetitions = 0\n",
    "            while len(df) < self.pop_size + 1: #+1, as the 1st position is used to store the reference individual\n",
    "                number_cross_repetitions = self.crossover(df, parents, evaluation, number_cross_repetitions)\n",
    "                \n",
    "                mutation_op = rnd.random()\n",
    "                if mutation_op <= self.mutation_proba:\n",
    "                    self.mutation(df, len(df) - 1, features_range)\n",
    "            \n",
    "            print()\n",
    "                 \n",
    "        evaluation = []\n",
    "    \n",
    "        #Evaluating the latest generation\n",
    "        self.fitness(df, evaluation, ind_cur_class)\n",
    "    \n",
    "        #Order the last generation by distance to the original instance     \n",
    "        evaluation.sort(key=lambda individual: individual.aval_norm)     \n",
    "        \n",
    "        #Getting the counterfactual set\n",
    "        contrafactual_set = pd.DataFrame(columns=self.input_dataset.columns)\n",
    "        contrafactual_set, solution_list = self.getContrafactual(df, evaluation)       \n",
    "                 \n",
    "        return contrafactual_set, solution_list\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CCSSE:\n",
    "    def __init__(self, dataset, bb_model, samples = None, K = 5, generation = 10, dataset_size = 'all'):\n",
    "        self.df_datasets = self.load_df_dataset()\n",
    "        self.dataset = dataset\n",
    "        self.samples = samples\n",
    "        self.K = K\n",
    "        self.generation = generation\n",
    "        \n",
    "#         self.x_train, self.x_test, self.y_train, self.y_test, self.dfx_full, self.dfy_full = self.get_datasets_train_test()\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test, self.dfx_full, self.dfy_full = self.get_dataset()\n",
    "\n",
    "        self.validade_dataset()\n",
    "\n",
    "        self.bb_model, self.p = self.get_bb_model(bb_model)\n",
    "        self.explainerCSSE = self.get_model_contrafactual()\n",
    "\n",
    "        self.model_causal, self.df_causal_effects, self.df_error, self.causal_order = self.get_model_causality()\n",
    "\n",
    "        self.run_dict = {}\n",
    "        self.run_non_causal_dict = {}\n",
    "        \n",
    "    def load_df_dataset(self):\n",
    "        def convert_to_list(val):\n",
    "            try:\n",
    "                return ast.literal_eval(val) if isinstance(val, str) and val.startswith('[') and val.endswith(']') else val\n",
    "            except (ValueError, SyntaxError):\n",
    "                return val\n",
    "            \n",
    "        df = pd.read_parquet(\"dfm_use.parquet\")\n",
    "        df['path'] = df['path'].apply(convert_to_list)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _search_causal_order(self, matrix):\n",
    "        \"\"\"Obtain a causal order from the given matrix strictly.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        matrix : array-like, shape (n_features, n_samples)\n",
    "            Target matrix.\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        causal_order : array, shape [n_features, ]\n",
    "            A causal order of the given matrix on success, None otherwise.\n",
    "        \"\"\"\n",
    "        \n",
    "        causal_order = []\n",
    "\n",
    "        row_num = matrix.shape[0]\n",
    "        original_index = np.arange(row_num)\n",
    "\n",
    "        while 0 < len(matrix):\n",
    "            # find a row all of which elements are zero\n",
    "            row_index_list = np.where(np.sum(np.abs(matrix), axis=1) == 0)[0]\n",
    "            if len(row_index_list) == 0:\n",
    "                break\n",
    "\n",
    "            target_index = row_index_list[0]\n",
    "\n",
    "            # append i to the end of the list\n",
    "            causal_order.append(original_index[target_index])\n",
    "            original_index = np.delete(original_index, target_index, axis=0)\n",
    "\n",
    "            # remove the i-th row and the i-th column from matrix\n",
    "            mask = np.delete(np.arange(len(matrix)), target_index, axis=0)\n",
    "            matrix = matrix[mask][:, mask]\n",
    "\n",
    "        if len(causal_order) != row_num:\n",
    "            causal_order = None\n",
    "\n",
    "        return causal_order\n",
    "\n",
    "\n",
    "    def get_dataset(self):\n",
    "        dataset_dict = self.df_datasets[self.df_datasets['name'] == self.dataset].iloc[0].to_dict()\n",
    "        \n",
    "        if isinstance(dataset_dict['path'], list):\n",
    "            if 'Column' in dataset_dict['classe']:\n",
    "                df_train = pd.read_csv(f\"datasets/drive_raw/{dataset_dict['path'][0]}\", header = None)\n",
    "                df_test = pd.read_csv(f\"datasets/drive_raw/{dataset_dict['path'][1]}\", header = None)\n",
    "                class_name = int(dataset_dict['class'].split('Column')[1]) - 1\n",
    "            else:\n",
    "                df_train = pd.read_csv(f\"datasets/drive_raw/{dataset_dict['path'][0]}\")\n",
    "                df_test = pd.read_csv(f\"datasets/drive_raw/{dataset_dict['path'][1]}\")\n",
    "                class_name = dataset_dict['classe']\n",
    "            \n",
    "            x_train = df_train.drop(columns=[class_name])\n",
    "            y_train = df_train[class_name]\n",
    "\n",
    "            # Dividindo o df_test\n",
    "            x_test = df_test.drop(columns=[class_name])\n",
    "            y_test = df_test[class_name]\n",
    "            \n",
    "            dfx_full = pd.concat([x_train, x_test])\n",
    "            dfy_full = pd.concat([y_train, y_test])\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            if 'Column' in dataset_dict['classe']:\n",
    "                df_main = pd.read_csv(f\"datasets/drive_raw/{dataset_dict['path']}\", header = None)\n",
    "                class_name = int(dataset_dict['classe'].split('Column')[1]) - 1\n",
    "            else:\n",
    "                df_main = pd.read_csv(f\"datasets/drive_raw/{dataset_dict['path']}\")\n",
    "                class_name = dataset_dict['classe']\n",
    "            \n",
    "            columns = df_main.columns\n",
    "            columns_tmp = list(columns)\n",
    "            print(f\"class_name = {class_name}\")\n",
    "            print(f\"columns_tmp = {columns_tmp}\")\n",
    "            columns_tmp.remove(class_name)\n",
    "\n",
    "            x_train, x_test, y_train, y_test = train_test_split(df_main[columns_tmp], df_main[class_name], test_size=0.1)\n",
    "\n",
    "            dfx_full = pd.concat([x_train, x_test])\n",
    "            dfy_full = pd.concat([y_train, y_test])\n",
    "            \n",
    "        return x_train, x_test, y_train, y_test, dfx_full, dfy_full\n",
    "    \n",
    "    def validade_dataset(self):\n",
    "        #validade if the dataset contains residual non gaussianity\n",
    "\n",
    "        def checking_residual_non_gaussianity(df, alpha=0.05):\n",
    "            \"\"\"\n",
    "            Testa se os resíduos das variáveis do DataFrame são gaussianos.\n",
    "            \n",
    "            Args:\n",
    "                df (pd.DataFrame): DataFrame com variáveis contínuas.\n",
    "                alpha (float): Nível de significância para o teste de normalidade (default = 0.05).\n",
    "            \n",
    "            Returns:\n",
    "                bool: True se os resíduos forem não-gaussianos (bom para LiNGAM), False se forem gaussianos.\n",
    "                dict: Resultados dos testes por variável (p-values).\n",
    "            \"\"\"\n",
    "            p_values = {}\n",
    "            non_gaussian_count = 0\n",
    "\n",
    "            for target_col in df.columns:\n",
    "                X = df.drop(columns=[target_col])\n",
    "                y = df[target_col]\n",
    "\n",
    "                # model = LinearRegression()\n",
    "                # model.fit(X, y)\n",
    "                # residuals = y - model.predict(X)\n",
    "\n",
    "                # Adiciona intercepto\n",
    "                X_with_const = sm.add_constant(X)\n",
    "                model = sm.OLS(y, X_with_const).fit()\n",
    "\n",
    "                # Obtém resíduos\n",
    "                residuals = model.resid\n",
    "\n",
    "                # Teste de normalidade (D’Agostino and Pearson’s test)\n",
    "                stat, p = normaltest(residuals)\n",
    "                p_values[target_col] = p\n",
    "\n",
    "                if p < alpha:\n",
    "                    non_gaussian_count += 1\n",
    "\n",
    "            # Se a maioria dos resíduos for não-gaussiana, retorna True\n",
    "            majority_non_gaussian = non_gaussian_count > len(df.columns) / 2\n",
    "            return majority_non_gaussian, p_values\n",
    "\n",
    "        def pode_converter_float(valor):\n",
    "            try:\n",
    "                float(valor)\n",
    "                return True\n",
    "            except (ValueError, TypeError):\n",
    "                return False\n",
    "\n",
    "        def remover_valores_invalidos_todas_colunas(df):\n",
    "            indices_para_remover = set()\n",
    "            print(f\"remover_valores_invalidos_todas_colunas\")\n",
    "            for coluna in df.columns:\n",
    "                # Ignora colunas que não são do tipo object (normalmente já são numéricas)\n",
    "                if df[coluna].dtype == 'object':\n",
    "                    # Encontra índices com valores inválidos\n",
    "                    indices_invalidos = df[~df[coluna].apply(pode_converter_float)].index\n",
    "                    if not indices_invalidos.empty:\n",
    "                        print(f\"[!] Valores inválidos encontrados na coluna '{coluna}':\")\n",
    "                        print(df.loc[indices_invalidos, coluna])\n",
    "                        indices_para_remover.update(indices_invalidos)\n",
    "\n",
    "            # Remove todas as linhas com valores inválidos\n",
    "            df_corrigido = df.drop(index=indices_para_remover).reset_index(drop=True)\n",
    "            return df_corrigido\n",
    "\n",
    "        self.dfx_full = remover_valores_invalidos_todas_colunas(self.dfx_full)\n",
    "\n",
    "        result, p_vals = checking_residual_non_gaussianity(self.dfx_full)\n",
    "\n",
    "        if not result:\n",
    "            raise(\"Resíduos gaussianos. LINGAM não pode ser aplicado.\")\n",
    "        else:\n",
    "            print(\"Resíduos não-gaussianos. LINGAM pode ser aplicado.\")\n",
    "            return True\n",
    "\n",
    "    \n",
    "\n",
    "    def get_bb_model(self, bb_model_name):\n",
    "        \n",
    "        if bb_model_name == 'rf':\n",
    "            bb_model = RandomForestClassifier()  \n",
    "            bb_model.fit(self.x_train, self.y_train)\n",
    "\n",
    "            p = bb_model.predict(self.x_test)\n",
    "\n",
    "            print(classification_report(self.y_test, p))\n",
    "\n",
    "            return bb_model, p\n",
    "        elif bb_model_name == 'rn':\n",
    "            bb_model = MLPClassifier()  \n",
    "            bb_model.fit(self.x_train, self.y_train)\n",
    "\n",
    "            p = bb_model.predict(self.x_test)\n",
    "\n",
    "            print(classification_report(self.y_test, p))\n",
    "\n",
    "            return bb_model, p\n",
    "\n",
    "    def get_model_contrafactual(self):\n",
    "        return CSSE(self.dfx_full, self.bb_model, K = self.K, num_gen = self.generation)\n",
    "    \n",
    "    def check_dataset_type(self):\n",
    "        profile = ProfileReport(self.dfx_full)\n",
    "        relatorio_json = profile.to_json()\n",
    "        dados_json = json.loads(relatorio_json)\n",
    "        # Criar a lista com 0 para Categorical e 1 para Numeric\n",
    "        list_type_order = [\n",
    "            0 if info['type'] == 'Categorical' else 1\n",
    "            for info in dados_json['variables'].values()\n",
    "        ]\n",
    "\n",
    "        if all(x == 0 for x in list_type_order):\n",
    "            if self.df_datasets[self.df_datasets['name'] == self.dataset].iloc[0].to_dict()['tipo'] == 'Categórica':\n",
    "                print(\"ProfileReport caterogico e acertou\") \n",
    "            else:\n",
    "                print(f\"ProfileReport caterogico e errou. Certo era {self.df_datasets[self.df_datasets['name'] == self.dataset].iloc[0].to_dict()['tipo']}\")\n",
    "\n",
    "        elif all(x == 1 for x in list_type_order):\n",
    "            if self.df_datasets[self.df_datasets['name'] == self.dataset].iloc[0].to_dict()['tipo'] == 'Numérica':\n",
    "                print(\"ProfileReport numerico e acertou\") \n",
    "            else:\n",
    "                print(f\"ProfileReport numerico e errou. Certo era {self.df_datasets[self.df_datasets['name'] == self.dataset].iloc[0].to_dict()['tipo']}\")\n",
    "        else:\n",
    "            if self.df_datasets[self.df_datasets['name'] == self.dataset].iloc[0].to_dict()['tipo'] == 'Mista':\n",
    "                print(\"ProfileReport misto e acertou\") \n",
    "            else:\n",
    "                print(f\"ProfileReport misto e errou. Certo era {self.df_datasets[self.df_datasets['name'] == self.dataset].iloc[0].to_dict()['tipo']}\")        \n",
    "        \n",
    "\n",
    "    def get_model_causality(self):\n",
    "        model_causal = lingam.LiM()\n",
    "        model_causal.fit(self.dfx_full.values, self.dfx_columns_type, only_global=True)\n",
    "        matrix = model_causal.adjacency_matrix_\n",
    "\n",
    "        causal_order = self._search_causal_order(matrix)\n",
    "\n",
    "        labels = [f'{i}' for i in self.dfx_full.columns]\n",
    "\n",
    "        causal_order_columns = [labels[i] for i in causal_order]\n",
    "        \n",
    "        from_list = []\n",
    "        to_list = []\n",
    "        effect_list = []\n",
    "\n",
    "        # Iteração sobre a matriz para extrair os valores e suas posições\n",
    "        for i in range(len(matrix)):\n",
    "            for j in range(len(matrix[i])):\n",
    "                if matrix[i][j] != 0:\n",
    "                    from_list.append(j)\n",
    "                    to_list.append(i)\n",
    "                    effect_list.append(matrix[i][j])\n",
    "\n",
    "        # Criando o DataFrame\n",
    "        df_causal_effects = pd.DataFrame({'from': from_list, 'to': to_list, 'effect': effect_list})\n",
    "        labels = [f'{i}' for i in self.dfx_full.columns]\n",
    "        df_causal_effects['from'] = df_causal_effects['from'].apply(lambda x : labels[x])\n",
    "        df_causal_effects['to'] = df_causal_effects['to'].apply(lambda x : labels[x])\n",
    "\n",
    "\n",
    "        matrix_error = model_causal.get_error_independence_p_values(self.dfx_full)\n",
    "        from_list = []\n",
    "        to_list = []\n",
    "        effect_list = []\n",
    "\n",
    "        # Iteração sobre a matriz para extrair os valores e suas posições\n",
    "        for i in range(len(matrix_error)):\n",
    "            for j in range(i + 1, len(matrix_error[i])):\n",
    "                if matrix_error[i][j] != 0:\n",
    "                    from_list.append(j)\n",
    "                    to_list.append(i)\n",
    "                    effect_list.append(matrix_error[i][j])\n",
    "\n",
    "        # Criando o DataFrame\n",
    "        df_error = pd.DataFrame({'from': from_list, 'to': to_list, 'effect': effect_list})\n",
    "        labels = [f'{i}' for i in self.dfx_full.columns]\n",
    "        df_error['from'] = df_error['from'].apply(lambda x : labels[x])\n",
    "        df_error['to'] = df_error['to'].apply(lambda x : labels[x])\n",
    "        df_error.fillna(0, inplace = True)\n",
    "\n",
    "        return model_causal, df_causal_effects, df_error, causal_order_columns\n",
    "        \n",
    "    \n",
    "    def print_causal_graph(self):\n",
    "        make_dot(self.model_causal.adjacency_matrix_)\n",
    "\n",
    "    def run_non_causal(self):\n",
    "        self.run_non_causal_dict = {}\n",
    "\n",
    "        if isinstance(self.samples, list):\n",
    "            self.create_run_dict(self)\n",
    "            for sample in self.samples:\n",
    "                self.run_non_causal_sample(sample)\n",
    "                \n",
    "        elif isinstance(self.samples, int):\n",
    "            for sample in range(self.samples):\n",
    "                self.run_non_causal_sample(sample)\n",
    "        \n",
    "        else: \n",
    "            for sample in range(10):\n",
    "                self.run_non_causal_sample(sample)\n",
    "                \n",
    "    def run_non_causal_sample(self, sample):\n",
    "        self.run_non_causal_dict[sample] = {}\n",
    "        original_instance = self.x_test.iloc[sample].copy()\n",
    "        contrafactual_set, solution = self.explainerCSSE.explain(original_instance, self.p[sample]) #Method returns the list of counterfactuals and the explanations generated from them\n",
    "\n",
    "        self.run_non_causal_dict[sample]['solution'] = solution\n",
    "\n",
    "    def run_causal(self):\n",
    "        start_time = time.time()\n",
    "        self.run_dict = {}\n",
    "        self.run_dict['global_numbers'] = {\n",
    "                    \"global_quant_changes\": 0,\n",
    "                    \"global_quant_causal_changes\": 0,\n",
    "                    \"global_quant_causal_rules\": 0,\n",
    "                    \"global_quant_zeros_causal\": 0,\n",
    "                    \"global_quant_full_causal\": 0,\n",
    "                    \"global_quant_causal_contrafac\": 0,\n",
    "                    \"global_quant_maioria_causal_satisfeita\": 0,\n",
    "                    \"global_quant_contrafac_unico\": 0,\n",
    "            }\n",
    "        self.global_quant_contrafac_max = 0\n",
    "        if isinstance(self.samples, list):\n",
    "            for sample in self.samples:\n",
    "                self.run_causal_sample(sample)\n",
    "                \n",
    "        elif isinstance(self.samples, int):\n",
    "            for sample in range(self.samples):\n",
    "                try:\n",
    "                    self.run_causal_sample(sample)\n",
    "                except Exception as e:\n",
    "                    print(f\"DEBUG ERRO: {e}\")\n",
    "        \n",
    "        else: \n",
    "            for sample in range(10):\n",
    "                self.run_causal_sample(sample)\n",
    "        \n",
    "        self.global_quant_contrafac_max = self.K * len(self.run_dict)\n",
    "        self.run_dict['global_numbers']['global_timing_run_causal'] = time.time() - start_time\n",
    "\n",
    "\n",
    "    def run_causal_sample(self, sample):\n",
    "        if isinstance(self.samples, list):\n",
    "            original_instance = self.dfx_full.iloc[sample]\n",
    "        else:\n",
    "            original_instance = self.x_test.iloc[sample]\n",
    "        self.run_dict[sample] = {}\n",
    "        self.run_dict[sample]['original_instance'] = original_instance\n",
    "\n",
    "#         print(f'Running original instance:\\n {display(original_instance)}')\n",
    "        print(f'Start to Running samples')\n",
    "\n",
    "        causal_explain = self.get_causal_explain(sample)\n",
    "        self.run_dict[sample]['causal_explain'] = causal_explain\n",
    "\n",
    "        list_analyse = []\n",
    "        for contrafactual in causal_explain[0]:\n",
    "            list_analyse.append(self.analyse_contrafac(contrafactual, causal_explain[1], causal_explain[2]))\n",
    "\n",
    "        self.run_dict[sample]['list_analyse'] = list_analyse\n",
    "        self.analyse_explaination(sample)\n",
    "\n",
    "    def analyse_contrafac(self, contrafac, df, original_ind):\n",
    "        columns = [x.column for x in contrafac]\n",
    "        condicao = (df['to'].isin(columns)) & (df['from'].isin(columns))\n",
    "        ind = original_ind[columns]\n",
    "        return [contrafac, df[condicao], ind]\n",
    "\n",
    "    def get_causal_explain(self, sample):\n",
    "        if isinstance(self.samples, list):\n",
    "            original_ind = self.dfx_full.iloc[sample].copy()\n",
    "        else:\n",
    "            original_ind = self.x_test.iloc[sample].copy() #Original instance\n",
    "        #self.ind_cur_class = ind_cur_class #Index in the shap corresponds to the original instance class\n",
    "        self.explainerCSSE.current_class = self.p[sample] #Original instance class\n",
    "        self.explainerCSSE.original_ind = original_ind\n",
    "        \n",
    "        ind_cur_class = self.explainerCSSE.getBadClass()\n",
    "\n",
    "        #Gets the valid values range of each feature\n",
    "        features_range = []\n",
    "        features_range = self.explainerCSSE.getFeaturesRange()\n",
    "\n",
    "        #The DataFrame df will have the current population\n",
    "        df = pd.DataFrame(columns=self.explainerCSSE.input_dataset.columns)\n",
    "\n",
    "        #Generates the initial population with popinitial mutants        \n",
    "        self.explainerCSSE.getPopInicial(df, features_range)\n",
    "        df_causal = df.copy()\n",
    "        dict_dfs = {}\n",
    "\n",
    "        # for g in tqdm(range(self.explainerCSSE.num_gen), desc= \"Processing...\"):\n",
    "        for g in range(self.generation):\n",
    "\n",
    "            #To use on the parents of each generation\n",
    "            old_parents = pd.DataFrame(columns=self.explainerCSSE.input_dataset.columns)\n",
    "\n",
    "            #Copy parents to the next generation\n",
    "            old_parents = df_causal.copy()\n",
    "            dict_dfs[g] = {}\n",
    "\n",
    "            parents_causal = self.apply_causality(old_parents)\n",
    "            dict_dfs[g]['causal_parents'] = parents_causal\n",
    "            #df will contain the new population\n",
    "            df_causal = pd.DataFrame(columns=self.explainerCSSE.input_dataset.columns)\n",
    "            evaluation_causal = []\n",
    "\n",
    "            #Assessing generation counterfactuals\n",
    "            self.explainerCSSE.fitness(dict_dfs[g]['causal_parents'], evaluation_causal, ind_cur_class)\n",
    "\n",
    "            #The original individual will always be in the 0 position of the df - So that it is normalized too (it will be used later in the distance function)\n",
    "            df_causal.loc[0] = original_ind.copy()\n",
    "\n",
    "            #Copies to the next generation the per_elit best individuals\n",
    "            self.explainerCSSE.elitism(evaluation_causal, df_causal, parents_causal)\n",
    "            number_cross_repetitions = 0\n",
    "            while len(df_causal) < self.explainerCSSE.pop_size + 1: #+1, as the 1st position is used to store the reference individual\n",
    "                number_cross_repetitions_causal = self.explainerCSSE.crossover(df_causal, parents_causal, evaluation_causal, number_cross_repetitions)\n",
    "\n",
    "                mutation_op = rnd.random()\n",
    "                if mutation_op <= self.explainerCSSE.mutation_proba:\n",
    "                    self.explainerCSSE.mutation(df_causal, len(df_causal) - 1, features_range)\n",
    "\n",
    "\n",
    "        evaluation = []\n",
    "        evaluation_causal = []\n",
    "\n",
    "        #Evaluating the latest generation\n",
    "        self.explainerCSSE.fitness(df_causal, evaluation_causal, ind_cur_class)\n",
    "\n",
    "        #Order the last generation by distance to the original instance     \n",
    "        evaluation_causal.sort(key=lambda individual: individual.aval_norm) \n",
    "\n",
    "        #Getting the counterfactual CAUSAL set\n",
    "        contrafactual_set_causal, solution_list_causal = self.explainerCSSE.getContrafactual(df_causal, evaluation_causal) \n",
    "\n",
    "        dict_dfs['contrafactual_set_causal'] = contrafactual_set_causal\n",
    "        dict_dfs['solution_list_causal'] = solution_list_causal\n",
    "        \n",
    "        df_contrafac_causal = self.get_contrafac_df_causal(solution_list_causal)\n",
    "        return [solution_list_causal, df_contrafac_causal, original_ind]\n",
    "    \n",
    "\n",
    "    def apply_causality(self, df):\n",
    "        df_apply_causal = pd.DataFrame(columns = df.columns)\n",
    "        original = df.iloc[0]\n",
    "        df_apply_causal.loc[0] = original\n",
    "        for index, df_row in df.iloc[1:].iterrows():\n",
    "            causal_ind = df_row.copy()\n",
    "            for column in self.causal_order:\n",
    "                value_diff = causal_ind[column] - original[column]\n",
    "                if value_diff != 0:\n",
    "                    tmp_effects = self.df_causal_effects[self.df_causal_effects['from'] == column]\n",
    "                    for index, row in tmp_effects.iterrows():\n",
    "    #                     prob = rnd.random()\n",
    "    #                     if row['probability'] <= prob:\n",
    "                        tmp_error = self.df_error[self.df_error['from'].isin([column, row['to']]) | self.df_error['to'].isin([column, row['to']])]\n",
    "                        error_value = tmp_error['effect'].iloc[0]\n",
    "    #                     print(f'error value = {error_value}')\n",
    "                        causal_ind[row['to']] = causal_ind[row['to']] + (value_diff * row['effect']) + tmp_error['effect'].iloc[0]\n",
    "            df_apply_causal.loc[len(df_apply_causal)] = causal_ind\n",
    "        return df_apply_causal\n",
    "\n",
    "\n",
    "    def get_contrafac_df_causal(self, solution_list_causal):\n",
    "        lista_solution_causal = [[t.column for t in sublist] for sublist in solution_list_causal]\n",
    "\n",
    "        # Inicializa uma lista para armazenar os resultados\n",
    "        resultados = []\n",
    "\n",
    "        # Loop sobre os valores na lista\n",
    "        for lista_valores in lista_solution_causal:\n",
    "            if len(lista_valores) > 1:\n",
    "                for v1 in lista_valores:\n",
    "                    for v2 in lista_valores:\n",
    "                        if v1 != v2:\n",
    "                            # Cria uma condição para cada par de valores diferentes na lista\n",
    "                            condicao = (self.df_causal_effects['to'].isin([v1, v2])) & (self.df_causal_effects['from'].isin([v1, v2]))\n",
    "                            # Realiza a busca no DataFrame usando a condição e armazena os resultados\n",
    "                            resultados.append(self.df_causal_effects[condicao])\n",
    "\n",
    "        # Concatena os resultados em um único DataFrame\n",
    "        if resultados:\n",
    "            resultado_final = pd.concat(resultados)\n",
    "            resultado_final = resultado_final.drop_duplicates()\n",
    "        else:\n",
    "            resultado_final = pd.DataFrame(columns = self.df_causal_effects.columns)\n",
    "            \n",
    "        return resultado_final\n",
    "    \n",
    "\n",
    "    def analyse_explaination(self, sample):\n",
    "        self.run_dict[sample]['data_analysis'] = []\n",
    "        for i, content in enumerate(self.run_dict[sample]['list_analyse']):\n",
    "            self.global_quant_contrafac_max += 1\n",
    "            controle = {}\n",
    "            causal = content[0]\n",
    "            df = content[1]\n",
    "            ori = content[2]\n",
    "            \n",
    "            \n",
    "            num_changes = len(causal)\n",
    "            self.run_dict['global_numbers']['global_quant_changes'] += num_changes\n",
    "            \n",
    "            num_causal_rules = len(df)\n",
    "            self.run_dict['global_numbers']['global_quant_causal_rules'] += num_causal_rules\n",
    "            \n",
    "            for attr in causal:\n",
    "                key = attr.column\n",
    "                if attr.value > ori[key]:\n",
    "                    controle[key] = 'mais'\n",
    "                else:\n",
    "                    controle[key] = 'menos'\n",
    "\n",
    "            df_temp = df.copy()\n",
    "            df_temp['from'] = df['from'].map(controle)\n",
    "            df_temp['to'] = df['to'].map(controle)\n",
    "            if len(df_temp) > 0:\n",
    "                df_temp['causal'] = df_temp.apply(lambda row: self.verificar_condicoes(row), axis = 1)\n",
    "                causal_finds = df_temp['causal'].sum()\n",
    "            else:\n",
    "                causal_finds = 0\n",
    "                \n",
    "            data_dict = {}\n",
    "\n",
    "            data_dict['df_respeita_causal'] = df_temp\n",
    "            data_dict['contrafactual_causal'] = causal\n",
    "            data_dict['df_causal_effects'] = df\n",
    "            \n",
    "            self.run_dict[sample]['data_analysis'].append(data_dict)\n",
    "\n",
    "            self.run_dict['global_numbers']['global_quant_causal_changes'] += causal_finds\n",
    "            \n",
    "            # print(f'causal = \\n{causal}\\n')\n",
    "            # print(f'original = \\n{ori}\\n')\n",
    "            # print(f'df_temp = \\n{display(df_temp)}\\n')\n",
    "            \n",
    "            if len(df_temp) > 0:\n",
    "                if causal_finds > 0:\n",
    "                    self.run_dict['global_numbers']['global_quant_causal_contrafac'] += 1\n",
    "                else:\n",
    "                    # print(f'nenhuma relaçao causal satisfeita')\n",
    "                    self.run_dict['global_numbers']['global_quant_zeros_causal'] += 1\n",
    "    #                 display(df_temp)\n",
    "    #                 print(f\"original = {ori}\")\n",
    "    #                 print(f\"causal = {causal}\")\n",
    "\n",
    "                if causal_finds == num_causal_rules:\n",
    "                    self.run_dict['global_numbers']['global_quant_full_causal'] += 1\n",
    "                    # if causal_finds > 2:\n",
    "                        # print(f'todas > 2 relaçoes causais satisfeitas')\n",
    "    #                     display(df_temp)\n",
    "    #                     print(f\"original = {ori}\")\n",
    "    #                     print(f\"causal = {causal}\")\n",
    "                    # elif causal_finds == 1:\n",
    "                        # print(f'todas = 1 relaçoes causais satisfeitas')\n",
    "                \n",
    "                if causal_finds >= (len(df_temp)/2):\n",
    "                    self.run_dict['global_numbers']['global_quant_maioria_causal_satisfeita'] += 1\n",
    "            else:\n",
    "    #             if len(causal) > 0:\n",
    "                self.run_dict['global_numbers']['global_quant_contrafac_unico'] += 1\n",
    "        \n",
    "    def verificar_condicoes(self, row):\n",
    "        if (row['from'] == 'mais' and row['to'] == 'mais' and row['effect'] > 0):\n",
    "            return True\n",
    "        elif row['from'] == 'menos' and row['to'] == 'menos' and row['effect'] > 0:\n",
    "            return True\n",
    "        elif row['from'] == 'mais' and row['to'] == 'menos' and row['effect'] < 0:\n",
    "            return True\n",
    "        elif row['from'] == 'menos' and row['to'] == 'mais' and row['effect'] < 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "            \n",
    "\n",
    "    def show_metrics(self, get_output = False):\n",
    "        \n",
    "        print(f\"Quantidade de instâncias contrafactuais = {self.global_quant_contrafac_max}\")\n",
    "        print(f'Quantidade de relações causais na base de dados = {len(self.df_causal_effects)}')\n",
    "        print(f\"Quantidade de atributos modificados = {self.run_dict['global_numbers']['global_quant_changes']}\")\n",
    "        print(f\"Quantidade de instâncias contrafactuais causais = {self.run_dict['global_numbers']['global_quant_contrafac_unico'] + self.run_dict['global_numbers']['global_quant_causal_contrafac']}\")\n",
    "        print(f\"Quantidade de relações causais analisadas = {self.run_dict['global_numbers']['global_quant_causal_rules']}\")\n",
    "        print(f\"Quantidade de relações causais satisfeitas = {self.run_dict['global_numbers']['global_quant_causal_changes']}\")\n",
    "        print(f\"Quantidade de instâncias contrafactuais com um único atributo modificado = {self.run_dict['global_numbers']['global_quant_contrafac_unico']}\")\n",
    "        print(f\"Tempo de execução = {self.run_dict['global_numbers']['global_timing_run_causal']}\")\n",
    "        \n",
    "        if get_output:\n",
    "            metrics_dict = {\n",
    "                \"Quantidade de instâncias contrafactuais\": self.global_quant_contrafac_max,\n",
    "                \"Quantidade de relações causais na base de dados\": len(self.df_causal_effects),\n",
    "                \"Quantidade de atributos modificados\": self.run_dict['global_numbers']['global_quant_changes'],\n",
    "                \"Quantidade de instâncias contrafactuais causais\": self.run_dict['global_numbers']['global_quant_contrafac_unico'] + self.run_dict['global_numbers']['global_quant_causal_contrafac'],\n",
    "                \"Quantidade de relações causais analisadas\": self.run_dict['global_numbers']['global_quant_causal_rules'],\n",
    "                \"Quantidade de relações causais satisfeitas\": self.run_dict['global_numbers']['global_quant_causal_changes'],\n",
    "                \"Quantidade de instâncias contrafactuais com um único atributo modificado\": self.run_dict['global_numbers']['global_quant_contrafac_unico'],\n",
    "                \"Tempo de execução\": self.run_dict['global_numbers']['global_timing_run_causal']\n",
    "            }\n",
    "        \n",
    "            return metrics_dict\n",
    "\n",
    "def get_causal_metrics(row, bb_model_name):\n",
    "#     try:\n",
    "    print(row)\n",
    "    ccsse = CCSSE(row['name'], samples = 10, K = 10, generation= 10, bb_model = bb_model_name)\n",
    "    # return 0\n",
    "    print(f\"criou o modelo\")\n",
    "    ccsse.run_causal()\n",
    "    print(f\"run_causal completo\")\n",
    "    dict_metricas = ccsse.show_metrics(get_output = True)\n",
    "    converted_dict_metricas = convert_np_types(dict_metricas)\n",
    "    json_data = json.dumps(converted_dict_metricas, indent=4)\n",
    "\n",
    "    s3.put_object(Bucket='omar-testes-gerais', Key=f'artigos/causal_csse/bateria_metricas/outputs/metricas_manuais/{bb_model_name}/{row[\"name\"]}.json', Body=json_data)\n",
    "    print(f\"Execução completa para {row['name']}\")\n",
    "    return json_data\n",
    "#     except Exception as e:\n",
    "#         print(f'Execução falhou - Nome da base de dados: {row[\"name\"]}')\n",
    "#         print(e)\n",
    "\n",
    "def convert_np_types(data):\n",
    "    \"\"\"Converte tipos de dados NumPy em tipos nativos do Python.\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        return {key: convert_np_types(value) for key, value in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [convert_np_types(item) for item in data]\n",
    "    elif isinstance(data, np.int64):\n",
    "        return int(data)  # Converte int64 para int\n",
    "    elif isinstance(data, np.float64):\n",
    "        return float(data)  # Converte float64 para float\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "#PJ LOCAL\n",
    "def handler(dataset, model_name):\n",
    "    \n",
    "    args = {\n",
    "        \"list_dataset_name\": dataset,\n",
    "        'bb_model_name': model_name\n",
    "    }\n",
    "    \n",
    "    dfm_use = pd.read_parquet(f\"dfm_use.parquet\")\n",
    "#     df_dataset = df_map_inference_datasets[df_map_inference_datasets['name'].isin(args[\"list_dataset_name\"])]\n",
    "\n",
    "    for idx, row in dfm_use[22:].iterrows():\n",
    "        # if row['name'] in args['list_dataset_name']:\n",
    "        json_response = get_causal_metrics(row, args[\"bb_model_name\"])\n",
    "    return 0\n",
    "            # dfm_use.loc[idx, 'metrica'] = json_response\n",
    "#     dfm_use = dfm_use['name'].isin(args[\"list_dataset_name\"]).apply(lambda x: get_causal_metrics(x, args[\"bb_model_name\"]), axis = 1)\n",
    "#     df_map_inference_datasets.to_parquet(f\"s3://omar-testes-gerais/artigos/artifacts/dfm_use.parquet\", engine = 'pyarrow')\n",
    "    \n",
    "    return dfm_use\n",
    "\n",
    "#PJ REAL\n",
    "# if __name__ == '__main__':\n",
    "    \n",
    "#     parser = argparse.ArgumentParser()\n",
    "    \n",
    "#     # Adicionando os argumentos para input e output\n",
    "#     parser.add_argument('--list_dataset_name', type=str)\n",
    "#     parser.add_argument('--bb_model_name', type=str)\n",
    "    \n",
    "#     args = parser.parse_args()\n",
    "#     list_dataset_name = ast.literal_eval(args.list_dataset_name)\n",
    "\n",
    "#     df_map_inference_datasets = pd.read_parquet(f\"s3://omar-testes-gerais/artigos/artifacts/df_map_inference_datasets.parquet\")\n",
    "#     df_dataset = df_map_inference_datasets[df_map_inference_datasets['name'].isin(list_dataset_name)]\n",
    "#     df_dataset.apply(lambda x: get_causal_metrics(x, args.bb_model_name), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a8e74a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                                                        Phishing\n",
      "path                                           Phishing/Phishing.csv\n",
      "classe                                                         Class\n",
      "metrica            {\"Quantidade de inst\\u00e2ncias contrafactuais...\n",
      "metrica_v2                                                      None\n",
      "gerou_resultado                                                    1\n",
      "tamanho                                                       Grande\n",
      "tipo                                                      Categórica\n",
      "Name: 27, dtype: object\n",
      "class_name = Class\n",
      "columns_tmp = ['having_IP_Address  ', 'URL_Length   ', 'Shortining_Service ', 'having_At_Symbol   ', 'double_slash_redirecting ', 'Prefix_Suffix  ', 'having_Sub_Domain  ', 'SSLfinal_State  ', 'Domain_registeration_length ', 'Favicon ', 'port ', 'HTTPS_token ', 'Request_URL  ', 'URL_of_Anchor ', 'Links_in_tags ', 'SFH  ', 'Submitting_to_email ', 'Abnormal_URL ', 'Redirect  ', 'on_mouseover  ', 'RightClick  ', 'popUpWidnow  ', 'Iframe ', 'age_of_domain  ', 'DNSRecord   ', 'web_traffic  ', 'Page_Rank ', 'Google_Index ', 'Links_pointing_to_page ', 'Statistical_report ', 'Class']\n",
      "remover_valores_invalidos_todas_colunas\n",
      "Resíduos não-gaussianos. LINGAM pode ser aplicado.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       496\n",
      "           1       0.95      0.97      0.96       610\n",
      "\n",
      "    accuracy                           0.96      1106\n",
      "   macro avg       0.96      0.96      0.96      1106\n",
      "weighted avg       0.96      0.96      0.96      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 1994.53it/s]00:00, 60.66it/s, Describe variable: Statistical_report ]    \n",
      "Summarize dataset: 100%|██████████| 39/39 [00:02<00:00, 18.50it/s, Completed]                             \n",
      "Render JSON: 100%|██████████| 1/1 [00:00<00:00, 49.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProfileReport caterogico e acertou\n",
      "name                                                  Room Occupancy\n",
      "path                               Room Occupancy/Room Occupancy.csv\n",
      "classe                                                     Occupancy\n",
      "metrica            {\"Quantidade de inst\\u00e2ncias contrafactuais...\n",
      "metrica_v2                                                      None\n",
      "gerou_resultado                                                    1\n",
      "tamanho                                                      Pequena\n",
      "tipo                                                        Numérica\n",
      "Name: 28, dtype: object\n",
      "class_name = Occupancy\n",
      "columns_tmp = ['Temperature', 'Humidity', 'Light', 'CO2', 'HumidityRatio', 'Occupancy']\n",
      "remover_valores_invalidos_todas_colunas\n",
      "Resíduos não-gaussianos. LINGAM pode ser aplicado.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       167\n",
      "           1       0.95      1.00      0.98       100\n",
      "\n",
      "    accuracy                           0.98       267\n",
      "   macro avg       0.98      0.99      0.98       267\n",
      "weighted avg       0.98      0.98      0.98       267\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 576.87it/s]0<?, ?it/s, Describe variable: HumidityRatio]\n",
      "Summarize dataset: 100%|██████████| 39/39 [00:01<00:00, 30.28it/s, Completed]                           \n",
      "Render JSON: 100%|██████████| 1/1 [00:00<00:00, 41.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProfileReport numerico e acertou\n",
      "name                                                           Sonar\n",
      "path                                        Sonar/sonar.all-data.csv\n",
      "classe                                                         class\n",
      "metrica            {\"Quantidade de inst\\u00e2ncias contrafactuais...\n",
      "metrica_v2                                                      None\n",
      "gerou_resultado                                                    1\n",
      "tamanho                                                       Grande\n",
      "tipo                                                        Numérica\n",
      "Name: 29, dtype: object\n",
      "class_name = class\n",
      "columns_tmp = ['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'class']\n",
      "remover_valores_invalidos_todas_colunas\n",
      "Resíduos não-gaussianos. LINGAM pode ser aplicado.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           M       0.91      1.00      0.95        10\n",
      "           R       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.95        21\n",
      "   macro avg       0.95      0.95      0.95        21\n",
      "weighted avg       0.96      0.95      0.95        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:00<00:00, 465.70it/s]<00:00, 174.17it/s, Describe variable: f60]\n",
      "Summarize dataset: 100%|██████████| 3669/3669 [03:30<00:00, 17.45it/s, Completed]               \n",
      "Render JSON: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProfileReport numerico e acertou\n",
      "name                                                        Spambase\n",
      "path                                           Spambase/Spambase.csv\n",
      "classe                                                         Class\n",
      "metrica            {\"Quantidade de inst\\u00e2ncias contrafactuais...\n",
      "metrica_v2                                                      None\n",
      "gerou_resultado                                                    1\n",
      "tamanho                                                       Grande\n",
      "tipo                                                        Numérica\n",
      "Name: 30, dtype: object\n",
      "class_name = Class\n",
      "columns_tmp = ['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10', 'F11', 'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19', 'F20', 'F21', 'F22', 'F23', 'F24', 'F25', 'F26', 'F27', 'F28', 'F29', 'F30', 'F31', 'F32', 'F33', 'F34', 'F35', 'F36', 'F37', 'F38', 'F39', 'F40', 'F41', 'F42', 'F43', 'F44', 'F45', 'F46', 'F47', 'F48', 'F49', 'F50', 'F51', 'F52', 'F53', 'F54', 'F55', 'F56', 'F57', 'Class']\n",
      "remover_valores_invalidos_todas_colunas\n",
      "Resíduos não-gaussianos. LINGAM pode ser aplicado.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       265\n",
      "           1       0.92      0.93      0.93       196\n",
      "\n",
      "    accuracy                           0.94       461\n",
      "   macro avg       0.93      0.94      0.94       461\n",
      "weighted avg       0.94      0.94      0.94       461\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [00:00<00:00, 233.40it/s]<00:00, 94.72it/s, Describe variable: F57]\n",
      "Summarize dataset: 100%|██████████| 3315/3315 [03:15<00:00, 16.92it/s, Completed]               \n",
      "Render JSON: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProfileReport numerico e acertou\n",
      "name                                                       Student\n",
      "path               Student/Students-Performance-MAT_processada.csv\n",
      "classe                                                       Class\n",
      "metrica                        array must not contain infs or NaNs\n",
      "metrica_v2                                                    None\n",
      "gerou_resultado                                                  1\n",
      "tamanho                                                     Grande\n",
      "tipo                                                         Mista\n",
      "Name: 31, dtype: object\n",
      "class_name = Class\n",
      "columns_tmp = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'Mjob=at_home', 'Mjob=health', 'Mjob=other', 'Mjob=services', 'Mjob=teacher', 'Fjob=at_home', 'Fjob=health', 'Fjob=other', 'Fjob=services', 'Fjob=teacher', 'reason=course', 'reason=home', 'reason=other', 'reason=reputation', 'guardian=father', 'guardian=mother', 'guardian=other', 'Class']\n",
      "remover_valores_invalidos_todas_colunas\n",
      "Resíduos não-gaussianos. LINGAM pode ser aplicado.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72        26\n",
      "           1       0.50      0.57      0.53        14\n",
      "\n",
      "    accuracy                           0.65        40\n",
      "   macro avg       0.62      0.63      0.63        40\n",
      "weighted avg       0.66      0.65      0.65        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:00<00:00, 435.28it/s]<00:00, 124.38it/s, Describe variable: guardian=other]\n",
      "Summarize dataset: 100%|██████████| 56/56 [00:03<00:00, 18.49it/s, Completed]                         \n",
      "Render JSON: 100%|██████████| 1/1 [00:00<00:00, 28.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProfileReport misto e acertou\n",
      "name                                                         titanic\n",
      "path                                  titanic/titanic_processada.csv\n",
      "classe                                                      Survived\n",
      "metrica            Input contains NaN, infinity or a value too la...\n",
      "metrica_v2                                                      None\n",
      "gerou_resultado                                                    1\n",
      "tamanho                                                        Média\n",
      "tipo                                                           Mista\n",
      "Name: 32, dtype: object\n",
      "class_name = Survived\n",
      "columns_tmp = ['Unnamed: 0', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked=C', 'Embarked=Q', 'Embarked=S', 'Initial= Capt', 'Initial= Col', 'Initial= Don', 'Initial= Dona', 'Initial= Dr', 'Initial= Jonkheer', 'Initial= Lady', 'Initial= Major', 'Initial= Master', 'Initial= Miss', 'Initial= Mlle', 'Initial= Mme', 'Initial= Mr', 'Initial= Mrs', 'Initial= Ms', 'Initial= Rev', 'Initial= Sir', 'Initial= the Countess', 'Survived']\n",
      "remover_valores_invalidos_todas_colunas\n",
      "Resíduos não-gaussianos. LINGAM pode ser aplicado.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87       100\n",
      "           1       0.58      0.23      0.33        31\n",
      "\n",
      "    accuracy                           0.78       131\n",
      "   macro avg       0.69      0.59      0.60       131\n",
      "weighted avg       0.75      0.78      0.74       131\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<?, ?it/s]32 [00:00<00:00, 100.71it/s, Describe variable: Initial= the Countess]\n",
      "Summarize dataset: 100%|██████████| 52/52 [00:02<00:00, 20.38it/s, Completed]                                \n",
      "Render JSON: 100%|██████████| 1/1 [00:00<00:00, 35.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProfileReport misto e acertou\n",
      "name                                                           Tokyo\n",
      "path                                                 Tokyo/Tokyo.csv\n",
      "classe                                                         class\n",
      "metrica            {\"Quantidade de inst\\u00e2ncias contrafactuais...\n",
      "metrica_v2                                                      None\n",
      "gerou_resultado                                                    1\n",
      "tamanho                                                       Grande\n",
      "tipo                                                        Numérica\n",
      "Name: 33, dtype: object\n",
      "class_name = class\n",
      "columns_tmp = ['cpu_avg_user', 'cpu_avg_sys', 'cpu_avg_busy', 'cpu_avg_wait', 'cpu_avg_idle', 'cpu_avg_waste', 'cpu_max_user', 'cpu_max_sys', 'cpu_max_busy', 'cpu_max_wait', 'cpu_max_idle', 'cpu_max_waste', 'cpu_frac_busy', 'io_iget', 'io_bread', 'io_bwrite', 'io_lread', 'io_lwrite', 'io_phread', 'io_phwrite', 'io_wcancel', 'io_namei', 'io_dirblk', 'disk_avg_active', 'disk_max_active', 'disk_frac_active', 'disk_avg_read', 'disk_avg_write', 'disk_avg_total', 'disk_max_read', 'disk_max_write', 'disk_max_total', 'disk_frac_busy', 'net_avg_read', 'net_avg_write', 'net_avg_total', 'net_max_read', 'net_max_write', 'net_max_total', 'net_frac_busy', 'mem_swap', 'mem_fault', 'mem_tlbflush', 'syscall_total', 'class']\n",
      "remover_valores_invalidos_todas_colunas\n",
      "Resíduos não-gaussianos. LINGAM pode ser aplicado.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.80      0.62        30\n",
      "           1       0.88      0.65      0.75        66\n",
      "\n",
      "    accuracy                           0.70        96\n",
      "   macro avg       0.69      0.73      0.69        96\n",
      "weighted avg       0.76      0.70      0.71        96\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [00:00<00:00, 197.92it/s]<00:00, 96.90it/s, Describe variable: syscall_total]  \n",
      "Summarize dataset: 100%|██████████| 1497/1497 [01:28<00:00, 16.89it/s, Completed]                                \n",
      "Render JSON: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProfileReport misto e errou. Certo era Numérica\n",
      "name                                                         twonorm\n",
      "path                                             twonorm/twonorm.csv\n",
      "classe                                                         class\n",
      "metrica            {\"Quantidade de inst\\u00e2ncias contrafactuais...\n",
      "metrica_v2                                                      None\n",
      "gerou_resultado                                                    1\n",
      "tamanho                                                        Média\n",
      "tipo                                                        Numérica\n",
      "Name: 34, dtype: object\n",
      "class_name = class\n",
      "columns_tmp = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'class']\n",
      "remover_valores_invalidos_todas_colunas\n",
      "Resíduos não-gaussianos. LINGAM pode ser aplicado.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.94      0.95       386\n",
      "           2       0.93      0.96      0.95       354\n",
      "\n",
      "    accuracy                           0.95       740\n",
      "   macro avg       0.95      0.95      0.95       740\n",
      "weighted avg       0.95      0.95      0.95       740\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 240.72it/s]00:01,  9.49it/s, Describe variable: V20]\n",
      "Summarize dataset: 100%|██████████| 429/429 [00:25<00:00, 17.10it/s, Completed]               \n",
      "Render JSON: 100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProfileReport numerico e acertou\n",
      "name                                                    Vertebral_2C\n",
      "path                                         Vertebral/column_2C.csv\n",
      "classe                                                         class\n",
      "metrica            {\"Quantidade de inst\\u00e2ncias contrafactuais...\n",
      "metrica_v2                                                      None\n",
      "gerou_resultado                                                    1\n",
      "tamanho                                                      Pequena\n",
      "tipo                                                        Numérica\n",
      "Name: 35, dtype: object\n",
      "class_name = class\n",
      "columns_tmp = ['pelvic_incidence', 'pelvic_tilt', 'lumbar_lordosis_angle', 'sacral_slope', 'pelvic_radius', 'degree_spondylolisthesis', 'class']\n",
      "remover_valores_invalidos_todas_colunas\n",
      "Resíduos não-gaussianos. LINGAM pode ser aplicado.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Abnormal       0.92      0.92      0.92        25\n",
      "      Normal       0.67      0.67      0.67         6\n",
      "\n",
      "    accuracy                           0.87        31\n",
      "   macro avg       0.79      0.79      0.79        31\n",
      "weighted avg       0.87      0.87      0.87        31\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<?, ?it/s]/11 [00:00<00:00, 26.73it/s, Describe variable: degree_spondylolisthesis]\n",
      "Summarize dataset: 100%|██████████| 51/51 [00:01<00:00, 29.50it/s, Completed]                                                 \n",
      "Render JSON: 100%|██████████| 1/1 [00:00<00:00, 63.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProfileReport numerico e acertou\n",
      "name                                             Votes_Congressional\n",
      "path               Votes_Congressional/house-votes-84_processada.csv\n",
      "classe                                                    Class Name\n",
      "metrica            {\"Quantidade de inst\\u00e2ncias contrafactuais...\n",
      "metrica_v2                                                      None\n",
      "gerou_resultado                                                    1\n",
      "tamanho                                                        Média\n",
      "tipo                                                      Categórica\n",
      "Name: 37, dtype: object\n",
      "class_name = Class Name\n",
      "columns_tmp = ['handicapped-infants', 'water-project-cost-sharing', 'adoption-of-the-budget-resolution', 'physician-fee-freeze', 'el-salvador-aid', 'religious-groups-in-schools', 'anti-satellite-test-ban', 'aid-to-nicaraguan-contras', 'mx-missile', 'immigration', 'synfuels-corporation-cutback', 'education-spending', 'superfund-right-to-sue', 'crime', 'duty-free-exports', 'export-administration-act-south-africa', 'Class Name']\n",
      "remover_valores_invalidos_todas_colunas\n",
      "Resíduos não-gaussianos. LINGAM pode ser aplicado.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    democrat       0.92      0.92      0.92        24\n",
      "  republican       0.90      0.90      0.90        20\n",
      "\n",
      "    accuracy                           0.91        44\n",
      "   macro avg       0.91      0.91      0.91        44\n",
      "weighted avg       0.91      0.91      0.91        44\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 16004.98it/s]0:00, 116.77it/s, Describe variable: export-administration-act-south-africa]\n",
      "Summarize dataset: 100%|██████████| 25/25 [00:00<00:00, 43.19it/s, Completed]                                                 \n",
      "Render JSON: 100%|██████████| 1/1 [00:00<00:00, 61.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProfileReport caterogico e acertou\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler(_, 'rn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab049060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>classe</th>\n",
       "      <th>metrica</th>\n",
       "      <th>metrica_v2</th>\n",
       "      <th>gerou_resultado</th>\n",
       "      <th>tamanho</th>\n",
       "      <th>tipo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australian</td>\n",
       "      <td>Australian/Credit_Card_Applications.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Média</td>\n",
       "      <td>Mista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Banknote</td>\n",
       "      <td>Banknote/BankNote_Authentication.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Pequena</td>\n",
       "      <td>Numérica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biodeg</td>\n",
       "      <td>Biodeg/qsar-biodeg.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\\n    \"Quantidade de instâncias contrafactuai...</td>\n",
       "      <td>zero metricas</td>\n",
       "      <td>1</td>\n",
       "      <td>Grande</td>\n",
       "      <td>Numérica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Coimbra</td>\n",
       "      <td>Breast Cancer Coimbra/breast_coimbra.csv</td>\n",
       "      <td>Classification</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Pequena</td>\n",
       "      <td>Numérica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Breast Cancer Wisconsin</td>\n",
       "      <td>Breast Cancer Wisconsin/breast-cancer.csv</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Grande</td>\n",
       "      <td>Numérica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name                                       path  \\\n",
       "1               Australian    Australian/Credit_Card_Applications.csv   \n",
       "2                 Banknote       Banknote/BankNote_Authentication.csv   \n",
       "3                   Biodeg                     Biodeg/qsar-biodeg.csv   \n",
       "4    Breast Cancer Coimbra   Breast Cancer Coimbra/breast_coimbra.csv   \n",
       "5  Breast Cancer Wisconsin  Breast Cancer Wisconsin/breast-cancer.csv   \n",
       "\n",
       "           classe                                            metrica  \\\n",
       "1           Class  {\"Quantidade de inst\\u00e2ncias contrafactuais...   \n",
       "2           class  {\"Quantidade de inst\\u00e2ncias contrafactuais...   \n",
       "3           Class  {\\n    \"Quantidade de instâncias contrafactuai...   \n",
       "4  Classification  {\"Quantidade de inst\\u00e2ncias contrafactuais...   \n",
       "5       diagnosis  {\"Quantidade de inst\\u00e2ncias contrafactuais...   \n",
       "\n",
       "      metrica_v2 gerou_resultado  tamanho      tipo  \n",
       "1           None               1    Média     Mista  \n",
       "2           None               1  Pequena  Numérica  \n",
       "3  zero metricas               1   Grande  Numérica  \n",
       "4           None               1  Pequena  Numérica  \n",
       "5           None               1   Grande  Numérica  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm_use = pd.read_parquet(f\"dfm_use.parquet\")\n",
    "dfm_use.head()\n",
    "\n",
    "groups = {\n",
    "    \"Australian\": [\"Australian\"],\n",
    "}\n",
    "\n",
    "for g in groups:\n",
    "    df_map_inference_datasets = handler(str(groups[g]), 'rn')\n",
    "    \n",
    "df_map_inference_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "352ecf04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m      1\u001b[39m dataset_mapping = {\n\u001b[32m      2\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mBanknote\u001b[39m\u001b[33m'\u001b[39m: {\u001b[33m'\u001b[39m\u001b[33mTamanho\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mPequena\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mTipo\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mNumérica\u001b[39m\u001b[33m'\u001b[39m},\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmammographic_masses\u001b[39m\u001b[33m'\u001b[39m: {\u001b[33m'\u001b[39m\u001b[33mTamanho\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mPequena\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mTipo\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mCategórica\u001b[39m\u001b[33m'\u001b[39m},\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mMusk\u001b[39m\u001b[33m'\u001b[39m: {\u001b[33m'\u001b[39m\u001b[33mTamanho\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mGrande\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mTipo\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mNumérica\u001b[39m\u001b[33m'\u001b[39m}\n\u001b[32m     34\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m dfm_use = \u001b[43mpd\u001b[49m.read_parquet(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdfm_use.parquet\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m dfm_use = dfm_use[dfm_use[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m].isin(dataset_mapping.keys())]\n\u001b[32m     38\u001b[39m dfm_use\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_mapping = {\n",
    "    'Banknote': {'Tamanho': 'Pequena', 'Tipo': 'Numérica'},\n",
    "    'mammographic_masses': {'Tamanho': 'Pequena', 'Tipo': 'Categórica'},\n",
    "    'Room Occupancy': {'Tamanho': 'Pequena', 'Tipo': 'Numérica'},\n",
    "    'liver disorders_bupa': {'Tamanho': 'Pequena', 'Tipo': 'Numérica'},\n",
    "    'Monk_1': {'Tamanho': 'Pequena', 'Tipo': 'Categórica'},\n",
    "    'Monk_2': {'Tamanho': 'Pequena', 'Tipo': 'Categórica'},\n",
    "    'Monk_3': {'Tamanho': 'Pequena', 'Tipo': 'Categórica'},\n",
    "    'Vertebral_2C': {'Tamanho': 'Pequena', 'Tipo': 'Numérica'},\n",
    "    'Diabetes': {'Tamanho': 'Pequena', 'Tipo': 'Numérica'},\n",
    "    'Breast Cancer Coimbra': {'Tamanho': 'Pequena', 'Tipo': 'Numérica'},\n",
    "    'Heart': {'Tamanho': 'Média', 'Tipo': 'Mista'},\n",
    "    'Heart_2': {'Tamanho': 'Média', 'Tipo': 'Mista'},\n",
    "    'EEg': {'Tamanho': 'Média', 'Tipo': 'Numérica'},\n",
    "    'Australian': {'Tamanho': 'Média', 'Tipo': 'Mista'},\n",
    "    'Votes_Congressional': {'Tamanho': 'Média', 'Tipo': 'Categórica'},\n",
    "    'German': {'Tamanho': 'Média', 'Tipo': 'Mista'},\n",
    "    'Mobile Price Classification': {'Tamanho': 'Média', 'Tipo': 'Numérica'},\n",
    "    'twonorm': {'Tamanho': 'Média', 'Tipo': 'Numérica'},\n",
    "    'KC2': {'Tamanho': 'Média', 'Tipo': 'Numérica'},\n",
    "    'HELOC': {'Tamanho': 'Média', 'Tipo': 'Numérica'},\n",
    "    'titanic': {'Tamanho': 'Média', 'Tipo': 'Mista'},\n",
    "    'Phishing': {'Tamanho': 'Grande', 'Tipo': 'Categórica'},\n",
    "    'Breast Cancer Wisconsin': {'Tamanho': 'Grande', 'Tipo': 'Numérica'},\n",
    "    'Ionosfera': {'Tamanho': 'Grande', 'Tipo': 'Numérica'},\n",
    "    'Horse colic': {'Tamanho': 'Grande', 'Tipo': 'Categórica'},\n",
    "    'Churn': {'Tamanho': 'Grande', 'Tipo': 'Categórica'},\n",
    "    'Biodeg': {'Tamanho': 'Grande', 'Tipo': 'Numérica'},\n",
    "    'Student': {'Tamanho': 'Grande', 'Tipo': 'Mista'},\n",
    "    'Tokyo': {'Tamanho': 'Grande', 'Tipo': 'Numérica'},\n",
    "    'Spambase': {'Tamanho': 'Grande', 'Tipo': 'Numérica'},\n",
    "    'Sonar': {'Tamanho': 'Grande', 'Tipo': 'Numérica'},\n",
    "    'Musk': {'Tamanho': 'Grande', 'Tipo': 'Numérica'}\n",
    "}\n",
    "\n",
    "dfm_use = pd.read_parquet(f\"dfm_use.parquet\")\n",
    "dfm_use = dfm_use[dfm_use['name'].isin(dataset_mapping.keys())]\n",
    "dfm_use\n",
    "\n",
    "dfm_use['tamanho'] = dfm_use['name'].map(lambda x: dataset_mapping[x]['Tamanho'])\n",
    "dfm_use['tipo'] = dfm_use['name'].map(lambda x: dataset_mapping[x]['Tipo'])\n",
    "dfm_use.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9e24fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22.08</td>\n",
       "      <td>11.460</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>7.000</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>29.58</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>11.500</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.17</td>\n",
       "      <td>8.170</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1</td>\n",
       "      <td>31.57</td>\n",
       "      <td>10.500</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>6.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1</td>\n",
       "      <td>20.67</td>\n",
       "      <td>0.415</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0</td>\n",
       "      <td>18.83</td>\n",
       "      <td>9.540</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0</td>\n",
       "      <td>27.42</td>\n",
       "      <td>14.500</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>3.085</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>1</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0.040</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A1     A2      A3  A4  A5  A6     A7  A8  A9  A10  A11  A12  A13   A14\n",
       "0     1  22.08  11.460   2   4   4  1.585   0   0    0    1    2  100  1213\n",
       "1     0  22.67   7.000   2   8   4  0.165   0   0    0    0    2  160     1\n",
       "2     0  29.58   1.750   1   4   4  1.250   0   0    0    1    2  280     1\n",
       "3     0  21.67  11.500   1   5   3  0.000   1   1   11    1    2    0     1\n",
       "4     1  20.17   8.170   2   6   4  1.960   1   1   14    0    2   60   159\n",
       "..   ..    ...     ...  ..  ..  ..    ...  ..  ..  ...  ...  ...  ...   ...\n",
       "685   1  31.57  10.500   2  14   4  6.500   1   0    0    0    2    0     1\n",
       "686   1  20.67   0.415   2   8   4  0.125   0   0    0    0    2    0    45\n",
       "687   0  18.83   9.540   2   6   4  0.085   1   0    0    0    2  100     1\n",
       "688   0  27.42  14.500   2  14   8  3.085   1   1    1    0    2  120    12\n",
       "689   1  41.00   0.040   2  10   4  0.040   0   1    1    0    1  560     1\n",
       "\n",
       "[690 rows x 14 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zxc = pd.read_csv(\"datasets/drive_raw/Australian/Credit_Card_Applications.csv\")\n",
    "# zxc.drop(columns = ['CustomerID'], inplace = True)\n",
    "# zxc.to_csv(\"datasets/drive_raw/Australian/Credit_Card_Applications.csv\", index = False)\n",
    "zxc.drop(columns = ['Class'], inplace = True)\n",
    "zxc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3272ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tipo_lista = [0,1,1,1,1,1,1,0,0,1,0,0,1,1]\n",
    "len(tipo_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cfc6e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A1',\n",
       " 'A11',\n",
       " 'A7',\n",
       " 'A2',\n",
       " 'A6',\n",
       " 'A14',\n",
       " 'A12',\n",
       " 'A4',\n",
       " 'A9',\n",
       " 'Class',\n",
       " 'A8',\n",
       " 'A5',\n",
       " 'A10',\n",
       " 'A3',\n",
       " 'A13']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_causal = lingam.DirectLiNGAM()\n",
    "labels = [f'{i}' for i in zxc.columns]\n",
    "model_causal.fit(zxc)\n",
    "causal_order = [labels[x] for x in model_causal.causal_order_]\n",
    "causal_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508ccd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "['A12', 'A7', 'A10', 'Class', 'A2', 'A5', 'A6', 'A4', 'A14', 'A1', 'A8', 'A9', 'A3', 'A13', 'A11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18764387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_causal_order(matrix):\n",
    "    \"\"\"Obtain a causal order from the given matrix strictly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    matrix : array-like, shape (n_features, n_samples)\n",
    "        Target matrix.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    causal_order : array, shape [n_features, ]\n",
    "        A causal order of the given matrix on success, None otherwise.\n",
    "    \"\"\"\n",
    "    causal_order = []\n",
    "\n",
    "    row_num = matrix.shape[0]\n",
    "    original_index = np.arange(row_num)\n",
    "    print(len(matrix))\n",
    "    while 0 < len(matrix):\n",
    "        # find a row all of which elements are zero\n",
    "        row_index_list = np.where(np.sum(np.abs(matrix), axis=1) == 0)[0]\n",
    "        if len(row_index_list) == 0:\n",
    "            print('break')\n",
    "            break\n",
    "\n",
    "        target_index = row_index_list[0]\n",
    "\n",
    "        # append i to the end of the list\n",
    "        causal_order.append(original_index[target_index])\n",
    "        original_index = np.delete(original_index, target_index, axis=0)\n",
    "\n",
    "        # remove the i-th row and the i-th column from matrix\n",
    "        mask = np.delete(np.arange(len(matrix)), target_index, axis=0)\n",
    "        matrix = matrix[mask][:, mask]\n",
    "    print(causal_order)\n",
    "    if len(causal_order) != row_num:\n",
    "        \n",
    "        causal_order = None\n",
    "\n",
    "    return causal_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63b486d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 13.0.0 (20250608.1624)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"242pt\" height=\"221pt\"\n",
       " viewBox=\"0.00 0.00 242.00 221.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 217)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-217 238,-217 238,4 -4,4\"/>\n",
       "<!-- x0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"149\" cy=\"-106.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"149\" y=\"-101.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x0</text>\n",
       "</g>\n",
       "<!-- x1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>x1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"123\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"123\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1</text>\n",
       "</g>\n",
       "<!-- x0&#45;&gt;x1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>x0&#45;&gt;x1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M146.16,-88.11C144.29,-78.03 141.54,-65.15 138,-54 137.17,-51.4 136.22,-48.72 135.21,-46.06\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"138.47,-44.79 131.42,-36.88 132,-47.46 138.47,-44.79\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"154.21\" y=\"-57.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3.00</text>\n",
       "</g>\n",
       "<!-- x4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>x4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"27\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x4</text>\n",
       "</g>\n",
       "<!-- x0&#45;&gt;x4 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>x0&#45;&gt;x4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M133.38,-91.48C116.99,-76.79 93.29,-55.61 91,-54 80.9,-46.89 69.21,-40.12 58.61,-34.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"60.3,-31.4 49.81,-29.9 57.08,-37.61 60.3,-31.4\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"121.7\" y=\"-57.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">8.00</text>\n",
       "</g>\n",
       "<!-- x5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>x5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"207\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"207\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x5</text>\n",
       "</g>\n",
       "<!-- x0&#45;&gt;x5 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>x0&#45;&gt;x5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M159.64,-89.63C168.14,-76.95 180.22,-58.94 190.05,-44.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"192.92,-46.28 195.59,-36.02 187.11,-42.38 192.92,-46.28\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"195.19\" y=\"-57.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4.00</text>\n",
       "</g>\n",
       "<!-- x2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>x2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"66\" cy=\"-106.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"66\" y=\"-101.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2</text>\n",
       "</g>\n",
       "<!-- x2&#45;&gt;x1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>x2&#45;&gt;x1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M62.38,-88.18C61.09,-77.64 61.18,-64.27 67,-54 72.14,-44.94 80.68,-37.91 89.56,-32.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"91.01,-35.79 98.23,-28.03 87.75,-29.59 91.01,-35.79\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"79\" y=\"-57.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2.00</text>\n",
       "</g>\n",
       "<!-- x2&#45;&gt;x4 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>x2&#45;&gt;x4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M43.41,-95.96C32.91,-90.24 21.44,-81.84 15.5,-70.5 11.53,-62.91 11.99,-54 14.18,-45.74\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"17.41,-47.08 17.47,-36.49 10.82,-44.74 17.41,-47.08\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"29.75\" y=\"-57.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">&#45;1.00</text>\n",
       "</g>\n",
       "<!-- x3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>x3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"101\" cy=\"-195\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"101\" y=\"-189.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x3</text>\n",
       "</g>\n",
       "<!-- x3&#45;&gt;x0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x3&#45;&gt;x0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M110.03,-177.73C116.93,-165.29 126.59,-147.88 134.57,-133.51\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"137.49,-135.46 139.28,-125.02 131.37,-132.07 137.49,-135.46\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"141.3\" y=\"-145.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3.00</text>\n",
       "</g>\n",
       "<!-- x3&#45;&gt;x2 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>x3&#45;&gt;x2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M94.25,-177.32C89.36,-165.24 82.64,-148.63 76.98,-134.64\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"80.29,-133.49 73.3,-125.53 73.8,-136.11 80.29,-133.49\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"98.63\" y=\"-145.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">6.00</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x150d450c5f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3 = np.random.uniform(size=1000)\n",
    "x0 = 3.0*x3 + np.random.uniform(size=1000)\n",
    "x2 = 6.0*x3 + np.random.uniform(size=1000)\n",
    "x1 = 3.0*x0 + 2.0*x2 + np.random.uniform(size=1000)\n",
    "x5 = 4.0*x0 + np.random.uniform(size=1000)\n",
    "x4 = 8.0*x0 - 1.0*x2 + np.random.uniform(size=1000)\n",
    "X = pd.DataFrame(np.array([x0, x1, x2, x3, x4, x5]).T ,columns=['x0', 'x1', 'x2', 'x3', 'x4', 'x5'])\n",
    "X.head()\n",
    "\n",
    "tipo_lista = [1,1,1,1,1,1]\n",
    "\n",
    "m = np.array([[0.0, 0.0, 0.0, 3.0, 0.0, 0.0],\n",
    "              [3.0, 0.0, 2.0, 0.0, 0.0, 0.0],\n",
    "              [0.0, 0.0, 0.0, 6.0, 0.0, 0.0],\n",
    "              [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "              [8.0, 0.0,-1.0, 0.0, 0.0, 0.0],\n",
    "              [4.0, 0.0, 0.0, 0.0, 0.0, 0.0]])\n",
    "\n",
    "make_dot(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09842501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_est (without the 2nd phase) is: \n",
      " [[ 0.          0.          0.          0.          0.          4.17705373]\n",
      " [ 0.          0.          0.          0.          0.          0.        ]\n",
      " [ 0.          2.15246658  0.          0.         -0.30903314  0.        ]\n",
      " [ 3.41614259  0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.33883259  0.          0.          0.          0.        ]\n",
      " [ 0.          0.17936398  0.4183899   0.          1.65993522  0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         4.17705373],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.        ,  2.15246658,  0.        ,  0.        , -0.30903314,\n",
       "         0.        ],\n",
       "       [ 3.41614259,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.        ,  0.33883259,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.        ,  0.17936398,  0.4183899 ,  0.        ,  1.65993522,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_causal = lingam.LiM()\n",
    "model_causal.fit(X.values, np.array([tipo_lista]), only_global=True)\n",
    "adj_matrix= model_causal._adjacency_matrix\n",
    "adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eaf9deac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[1, 4, 2, 5, 0, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 4, 2, 5, 0, 3]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asd = search_causal_order(adj_matrix)\n",
    "asd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a83391d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x1', 'x4', 'x2', 'x5', 'x0', 'x3']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [f'{i}' for i in X.columns]\n",
    "causal_order_columns = [labels[i] for i in asd]\n",
    "causal_order_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21b5dc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>effect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x5</td>\n",
       "      <td>x0</td>\n",
       "      <td>4.177054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x1</td>\n",
       "      <td>x2</td>\n",
       "      <td>2.152467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x4</td>\n",
       "      <td>x2</td>\n",
       "      <td>-0.309033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x0</td>\n",
       "      <td>x3</td>\n",
       "      <td>3.416143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x1</td>\n",
       "      <td>x4</td>\n",
       "      <td>0.338833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>x1</td>\n",
       "      <td>x5</td>\n",
       "      <td>0.179364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>x2</td>\n",
       "      <td>x5</td>\n",
       "      <td>0.418390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>x4</td>\n",
       "      <td>x5</td>\n",
       "      <td>1.659935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  from  to    effect\n",
       "0   x5  x0  4.177054\n",
       "1   x1  x2  2.152467\n",
       "2   x4  x2 -0.309033\n",
       "3   x0  x3  3.416143\n",
       "4   x1  x4  0.338833\n",
       "5   x1  x5  0.179364\n",
       "6   x2  x5  0.418390\n",
       "7   x4  x5  1.659935"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_list = []\n",
    "to_list = []\n",
    "effect_list = []\n",
    "\n",
    "for i in range(len(adj_matrix)):\n",
    "    for j in range(len(adj_matrix[i])):\n",
    "        if adj_matrix[i][j] != 0:\n",
    "            from_list.append(j)\n",
    "            to_list.append(i)\n",
    "            effect_list.append(adj_matrix[i][j])\n",
    "\n",
    "# Criando o DataFrame\n",
    "bnm = pd.DataFrame({'from': from_list, 'to': to_list, 'effect': effect_list})\n",
    "bnm['from'] = bnm['from'].apply(lambda x : labels[x])\n",
    "bnm['to'] = bnm['to'].apply(lambda x : labels[x])\n",
    "\n",
    "bnm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07c69cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.621405</td>\n",
       "      <td>11.006386</td>\n",
       "      <td>2.832953</td>\n",
       "      <td>0.399581</td>\n",
       "      <td>10.436435</td>\n",
       "      <td>6.818000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.494895</td>\n",
       "      <td>18.883925</td>\n",
       "      <td>5.478865</td>\n",
       "      <td>0.792533</td>\n",
       "      <td>15.446883</td>\n",
       "      <td>10.406998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.708232</td>\n",
       "      <td>4.204516</td>\n",
       "      <td>0.946932</td>\n",
       "      <td>0.126429</td>\n",
       "      <td>5.581730</td>\n",
       "      <td>3.723198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.708858</td>\n",
       "      <td>5.999247</td>\n",
       "      <td>1.884494</td>\n",
       "      <td>0.164753</td>\n",
       "      <td>4.231977</td>\n",
       "      <td>3.488696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.426544</td>\n",
       "      <td>23.441740</td>\n",
       "      <td>6.126420</td>\n",
       "      <td>0.947736</td>\n",
       "      <td>22.152849</td>\n",
       "      <td>13.958101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0         x1        x2        x3         x4         x5\n",
       "0  1.621405  11.006386  2.832953  0.399581  10.436435   6.818000\n",
       "1  2.494895  18.883925  5.478865  0.792533  15.446883  10.406998\n",
       "2  0.708232   4.204516  0.946932  0.126429   5.581730   3.723198\n",
       "3  0.708858   5.999247  1.884494  0.164753   4.231977   3.488696\n",
       "4  3.426544  23.441740  6.126420  0.947736  22.152849  13.958101"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3 = np.random.uniform(size=1000)\n",
    "x0 = 3.0*x3 + np.random.uniform(size=1000)\n",
    "x2 = 6.0*x3 + np.random.uniform(size=1000)\n",
    "x1 = 3.0*x0 + 2.0*x2 + np.random.uniform(size=1000)\n",
    "x5 = 4.0*x0 + np.random.uniform(size=1000)\n",
    "x4 = 8.0*x0 - 1.0*x2 + np.random.uniform(size=1000)\n",
    "X = pd.DataFrame(np.array([x0, x1, x2, x3, x4, x5]).T ,columns=['x0', 'x1', 'x2', 'x3', 'x4', 'x5'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11d7bf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 13.0.0 (20250608.1624)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"153pt\" height=\"487pt\"\n",
       " viewBox=\"0.00 0.00 153.00 487.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 482.5)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-482.5 148.57,-482.5 148.57,4 -4,4\"/>\n",
       "<!-- x0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"90\" cy=\"-106.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"90\" y=\"-101.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x0</text>\n",
       "</g>\n",
       "<!-- x3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>x3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"90\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"90\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x3</text>\n",
       "</g>\n",
       "<!-- x0&#45;&gt;x3 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>x0&#45;&gt;x3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M90,-88.41C90,-76.76 90,-61.05 90,-47.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"93.5,-47.86 90,-37.86 86.5,-47.86 93.5,-47.86\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"102\" y=\"-57.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3.42</text>\n",
       "</g>\n",
       "<!-- x1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>x1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"84\" cy=\"-460.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"84\" y=\"-455.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1</text>\n",
       "</g>\n",
       "<!-- x2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>x2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-283.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"27\" y=\"-278.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2</text>\n",
       "</g>\n",
       "<!-- x1&#45;&gt;x2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>x1&#45;&gt;x2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M67.09,-446.15C52.53,-433.49 32.56,-413.01 24,-390 14.73,-365.08 16.93,-334.51 20.58,-312.7\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"23.98,-313.55 22.41,-303.07 17.11,-312.24 23.98,-313.55\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"36\" y=\"-366.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2.15</text>\n",
       "</g>\n",
       "<!-- x4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>x4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"84\" cy=\"-372\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"84\" y=\"-366.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x4</text>\n",
       "</g>\n",
       "<!-- x1&#45;&gt;x4 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>x1&#45;&gt;x4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M84,-442.41C84,-430.76 84,-415.05 84,-401.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"87.5,-401.86 84,-391.86 80.5,-401.86 87.5,-401.86\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"96\" y=\"-411.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.34</text>\n",
       "</g>\n",
       "<!-- x5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>x5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"90\" cy=\"-195\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"90\" y=\"-189.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x5</text>\n",
       "</g>\n",
       "<!-- x1&#45;&gt;x5 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>x1&#45;&gt;x5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M98.16,-444.84C103.19,-438.92 108.47,-431.78 112,-424.5 118.86,-410.34 118.21,-405.64 120,-390 123.3,-361.17 118.06,-275.59 116,-265.5 113.05,-251.05 107.54,-235.63 102.35,-222.99\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"105.69,-221.9 98.54,-214.09 99.25,-224.66 105.69,-221.9\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"132.57\" y=\"-322.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.18</text>\n",
       "</g>\n",
       "<!-- x2&#45;&gt;x5 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>x2&#45;&gt;x5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M33.21,-265.84C37.58,-255.3 44.06,-241.69 52,-231 55.75,-225.96 60.28,-221.06 64.9,-216.6\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"66.98,-219.44 72.02,-210.13 62.27,-214.26 66.98,-219.44\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"64\" y=\"-234.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.42</text>\n",
       "</g>\n",
       "<!-- x4&#45;&gt;x2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>x4&#45;&gt;x2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M67.19,-357.65C60.39,-351.6 52.89,-344.01 47.5,-336 42.68,-328.84 38.72,-320.37 35.61,-312.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"38.93,-311.3 32.28,-303.05 32.34,-313.65 38.93,-311.3\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"61.75\" y=\"-322.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">&#45;0.31</text>\n",
       "</g>\n",
       "<!-- x4&#45;&gt;x5 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>x4&#45;&gt;x5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M84.6,-353.58C85.63,-323.44 87.76,-261.3 89.02,-224.7\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"92.51,-224.98 89.35,-214.86 85.51,-224.74 92.51,-224.98\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"99.6\" y=\"-278.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.66</text>\n",
       "</g>\n",
       "<!-- x5&#45;&gt;x0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x5&#45;&gt;x0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M90,-176.91C90,-165.26 90,-149.55 90,-136.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"93.5,-136.36 90,-126.36 86.5,-136.36 93.5,-136.36\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"102\" y=\"-145.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">4.18</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x150d475e180>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lingam.utils import make_dot\n",
    "make_dot(adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff1d87f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 13.0.0 (20250608.1624)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"184pt\" height=\"506pt\"\n",
       " viewBox=\"0.00 0.00 184.00 506.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 502)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-502 180,-502 180,4 -4,4\"/>\n",
       "<!-- x0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-195\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"27\" y=\"-189.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x0</text>\n",
       "</g>\n",
       "<!-- x1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>x1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"58\" cy=\"-106.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"58\" y=\"-101.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1</text>\n",
       "</g>\n",
       "<!-- x0&#45;&gt;x1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>x0&#45;&gt;x1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M32.98,-177.32C37.28,-165.31 43.18,-148.84 48.18,-134.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"51.35,-136.44 51.42,-125.85 44.76,-134.08 51.35,-136.44\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"57.28\" y=\"-145.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.50</text>\n",
       "</g>\n",
       "<!-- x2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>x2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"58\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"58\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2</text>\n",
       "</g>\n",
       "<!-- x1&#45;&gt;x2 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>x1&#45;&gt;x2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M58,-88.41C58,-76.76 58,-61.05 58,-47.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"61.5,-47.86 58,-37.86 54.5,-47.86 61.5,-47.86\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"70\" y=\"-57.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2.00</text>\n",
       "</g>\n",
       "<!-- x3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>x3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"30\" cy=\"-303\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"30\" y=\"-297.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x3</text>\n",
       "</g>\n",
       "<!-- x3&#45;&gt;x0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x3&#45;&gt;x0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M28.86,-284.56C28.53,-278.96 28.2,-272.72 28,-267 27.5,-253.09 27.25,-237.64 27.12,-224.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"30.62,-224.71 27.05,-214.74 23.62,-224.76 30.62,-224.71\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"40\" y=\"-243.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.80</text>\n",
       "</g>\n",
       "<!-- x4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>x4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"149\" cy=\"-391.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"149\" y=\"-386.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x4</text>\n",
       "</g>\n",
       "<!-- x5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>x5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"149\" cy=\"-303\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"149\" y=\"-297.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x5</text>\n",
       "</g>\n",
       "<!-- x4&#45;&gt;x5 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>x4&#45;&gt;x5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M149,-373.41C149,-361.76 149,-346.05 149,-332.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"152.5,-332.86 149,-322.86 145.5,-332.86 152.5,-332.86\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"161\" y=\"-342.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2.00</text>\n",
       "</g>\n",
       "<!-- x6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>x6</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"56\" cy=\"-391.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"56\" y=\"-386.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x6</text>\n",
       "</g>\n",
       "<!-- x6&#45;&gt;x3 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>x6&#45;&gt;x3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47.52,-374.09C44.81,-368.33 42,-361.73 40,-355.5 37.66,-348.21 35.78,-340.17 34.31,-332.64\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"37.78,-332.15 32.59,-322.91 30.89,-333.37 37.78,-332.15\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"52\" y=\"-342.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.20</text>\n",
       "</g>\n",
       "<!-- x7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>x7</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"88\" cy=\"-249\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"88\" y=\"-243.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x7</text>\n",
       "</g>\n",
       "<!-- x6&#45;&gt;x7 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>x6&#45;&gt;x7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.91,-373.41C61.21,-367.71 62.67,-361.33 64,-355.5 69.96,-329.35 76.74,-299.56 81.57,-278.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"84.96,-279.18 83.76,-268.65 78.13,-277.63 84.96,-279.18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"79.74\" y=\"-342.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.50</text>\n",
       "</g>\n",
       "<!-- x7&#45;&gt;x1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>x7&#45;&gt;x1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M86.93,-230.53C85.31,-209.37 81.48,-172.79 73,-142.5 72.26,-139.87 71.37,-137.17 70.4,-134.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"73.67,-133.26 66.66,-125.31 67.18,-135.89 73.67,-133.26\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"97.29\" y=\"-189.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.30</text>\n",
       "</g>\n",
       "<!-- x8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>x8</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"149\" cy=\"-480\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"149\" y=\"-474.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x8</text>\n",
       "</g>\n",
       "<!-- x8&#45;&gt;x4 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>x8&#45;&gt;x4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M149,-461.91C149,-450.26 149,-434.55 149,-421.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"152.5,-421.36 149,-411.36 145.5,-421.36 152.5,-421.36\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"161\" y=\"-430.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3.00</text>\n",
       "</g>\n",
       "<!-- x9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>x9</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"56\" cy=\"-480\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"56\" y=\"-474.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x9</text>\n",
       "</g>\n",
       "<!-- x9&#45;&gt;x6 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>x9&#45;&gt;x6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M56,-461.91C56,-450.26 56,-434.55 56,-421.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"59.5,-421.36 56,-411.36 52.5,-421.36 59.5,-421.36\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"68\" y=\"-430.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2.50</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1509420c5f0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# Variáveis raízes\n",
    "z9 = np.random.uniform(size=1000)\n",
    "z8 = np.random.uniform(size=1000)\n",
    "\n",
    "# Gerando com base na estrutura causal\n",
    "z6 = 2.5 * z9 + np.random.uniform(size=1000)\n",
    "z7 = 1.5 * z6 + np.random.uniform(size=1000)\n",
    "z4 = 3.0 * z8 + np.random.uniform(size=1000)\n",
    "\n",
    "z3 = 1.2 * z6 + np.random.uniform(size=1000)\n",
    "z5 = 2.0 * z4 + np.random.uniform(size=1000)\n",
    "\n",
    "z0 = 0.8 * z3 + np.random.uniform(size=1000)\n",
    "z1 = 1.3 * z7 + 0.5 * z0 + np.random.uniform(size=1000)\n",
    "z2 = 2.0 * z1 + np.random.uniform(size=1000)\n",
    "\n",
    "# Monta o DataFrame\n",
    "Z = pd.DataFrame(np.array([z0, z1, z2, z3, z4, z5, z6, z7, z8, z9]).T,\n",
    "                 columns=['z0', 'z1', 'z2', 'z3', 'z4', 'z5', 'z6', 'z7', 'z8', 'z9'])\n",
    "Z.head()\n",
    "\n",
    "adj_matrix = np.array([\n",
    "#  z0  z1   z2  z3  z4  z5  z6  z7  z8  z9\n",
    "   [0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],  # z0 ← z3\n",
    "   [0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.3, 0.0, 0.0],  # z1 ← z0, z7\n",
    "   [0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],  # z2 ← z1\n",
    "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.2, 0.0, 0.0, 0.0],  # z3 ← z6\n",
    "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0],  # z4 ← z8\n",
    "   [0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0],  # z5 ← z4\n",
    "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5],  # z6 ← z9\n",
    "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.5, 0.0, 0.0, 0.0],  # z7 ← z6\n",
    "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],  # z8 ← raiz\n",
    "   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],  # z9 ← raiz\n",
    "])\n",
    "\n",
    "adj_df = pd.DataFrame(adj_matrix,\n",
    "                      columns=['z0', 'z1', 'z2', 'z3', 'z4', 'z5', 'z6', 'z7', 'z8', 'z9'],\n",
    "                      index=['z0', 'z1', 'z2', 'z3', 'z4', 'z5', 'z6', 'z7', 'z8', 'z9'])\n",
    "adj_df\n",
    "\n",
    "make_dot(adj_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90ed45e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_est (without the 2nd phase) is: \n",
      " [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         2.05545152 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.12198812 0.         0.         0.21467633 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.39999042 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         2.18272874\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.31093336 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         1.57219681 0.         0.        ]\n",
      " [0.         1.7379242  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         3.14368617 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "model_causal = lingam.LiM()\n",
    "model_causal.fit(Z.values, np.array([[1]*10]), only_global=False)\n",
    "adj_matrix= model_causal._adjacency_matrix\n",
    "# adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70913dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[3, 8, 4, 5, 9, 6, 7, 1, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "asd = search_causal_order(adj_matrix)\n",
    "# asd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a6e330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [f'{i}' for i in Z.columns]\n",
    "causal_order_columns = [labels[i] for i in asd]\n",
    "# causal_order_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eaf0603a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>effect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z2</td>\n",
       "      <td>z0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z3</td>\n",
       "      <td>z0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z7</td>\n",
       "      <td>z1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z1</td>\n",
       "      <td>z2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z3</td>\n",
       "      <td>z2</td>\n",
       "      <td>0.214676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>z8</td>\n",
       "      <td>z4</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>z4</td>\n",
       "      <td>z5</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>z5</td>\n",
       "      <td>z6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>z9</td>\n",
       "      <td>z6</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>z6</td>\n",
       "      <td>z7</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  from  to    effect\n",
       "0   z2  z0  1.000000\n",
       "1   z3  z0  1.000000\n",
       "2   z7  z1  1.000000\n",
       "3   z1  z2  1.000000\n",
       "4   z3  z2  0.214676\n",
       "5   z8  z4  1.000000\n",
       "6   z4  z5  1.000000\n",
       "7   z5  z6  1.000000\n",
       "8   z9  z6  1.000000\n",
       "9   z6  z7  1.000000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_list = []\n",
    "to_list = []\n",
    "effect_list = []\n",
    "\n",
    "for i in range(len(adj_matrix)):\n",
    "    for j in range(len(adj_matrix[i])):\n",
    "        if adj_matrix[i][j] != 0:\n",
    "            from_list.append(j)\n",
    "            to_list.append(i)\n",
    "            effect_list.append(adj_matrix[i][j])\n",
    "\n",
    "# Criando o DataFrame\n",
    "bnm = pd.DataFrame({'from': from_list, 'to': to_list, 'effect': effect_list})\n",
    "bnm['from'] = bnm['from'].apply(lambda x : labels[x])\n",
    "bnm['to'] = bnm['to'].apply(lambda x : labels[x])\n",
    "\n",
    "bnm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4d2ae28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 13.0.0 (20250608.1624)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"177pt\" height=\"664pt\"\n",
       " viewBox=\"0.00 0.00 177.00 664.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 659.5)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-659.5 173,-659.5 173,4 -4,4\"/>\n",
       "<!-- x0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"117\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"117\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x0</text>\n",
       "</g>\n",
       "<!-- x1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>x1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-195\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"63\" y=\"-189.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1</text>\n",
       "</g>\n",
       "<!-- x2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>x2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"86\" cy=\"-106.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"86\" y=\"-101.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2</text>\n",
       "</g>\n",
       "<!-- x1&#45;&gt;x2 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>x1&#45;&gt;x2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M61.07,-176.95C60.47,-166.75 60.67,-153.64 64,-142.5 65,-139.17 66.4,-135.85 68.03,-132.65\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"70.89,-134.68 72.97,-124.29 64.86,-131.12 70.89,-134.68\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"76\" y=\"-145.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.00</text>\n",
       "</g>\n",
       "<!-- x2&#45;&gt;x0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x2&#45;&gt;x0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M91.98,-88.82C96.28,-76.81 102.18,-60.34 107.18,-46.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110.35,-47.94 110.42,-37.35 103.76,-45.58 110.35,-47.94\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"116.28\" y=\"-57.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.00</text>\n",
       "</g>\n",
       "<!-- x3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>x3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"142\" cy=\"-195\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"142\" y=\"-189.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x3</text>\n",
       "</g>\n",
       "<!-- x3&#45;&gt;x0 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>x3&#45;&gt;x0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M142.59,-176.91C143.11,-150.25 142.52,-97.33 132,-54 131.36,-51.34 130.53,-48.63 129.59,-45.95\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"132.87,-44.73 125.91,-36.75 126.38,-47.33 132.87,-44.73\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"153.54\" y=\"-101.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.00</text>\n",
       "</g>\n",
       "<!-- x3&#45;&gt;x2 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>x3&#45;&gt;x2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127.46,-179.4C121.91,-173.39 115.78,-166.16 111,-159 105.99,-151.5 101.4,-142.84 97.54,-134.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.75,-133.39 93.42,-125.74 94.38,-136.29 100.75,-133.39\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"123\" y=\"-145.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.21</text>\n",
       "</g>\n",
       "<!-- x4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>x4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-549\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"27\" y=\"-543.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x4</text>\n",
       "</g>\n",
       "<!-- x5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>x5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-460.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"27\" y=\"-455.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x5</text>\n",
       "</g>\n",
       "<!-- x4&#45;&gt;x5 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>x4&#45;&gt;x5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M27,-530.91C27,-519.26 27,-503.55 27,-490.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"30.5,-490.36 27,-480.36 23.5,-490.36 30.5,-490.36\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"39\" y=\"-499.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.00</text>\n",
       "</g>\n",
       "<!-- x6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>x6</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-372\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"63\" y=\"-366.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x6</text>\n",
       "</g>\n",
       "<!-- x5&#45;&gt;x6 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>x5&#45;&gt;x6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M33.94,-442.82C38.97,-430.74 45.88,-414.13 51.7,-400.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54.89,-401.6 55.5,-391.02 48.42,-398.91 54.89,-401.6\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"60.22\" y=\"-411.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.00</text>\n",
       "</g>\n",
       "<!-- x7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>x7</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-283.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"63\" y=\"-278.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x7</text>\n",
       "</g>\n",
       "<!-- x6&#45;&gt;x7 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>x6&#45;&gt;x7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63,-353.91C63,-342.26 63,-326.55 63,-313.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"66.5,-313.36 63,-303.36 59.5,-313.36 66.5,-313.36\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"75\" y=\"-322.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.00</text>\n",
       "</g>\n",
       "<!-- x7&#45;&gt;x1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>x7&#45;&gt;x1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M63,-265.41C63,-253.76 63,-238.05 63,-224.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"66.5,-224.86 63,-214.86 59.5,-224.86 66.5,-224.86\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"75\" y=\"-234.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.00</text>\n",
       "</g>\n",
       "<!-- x8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>x8</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-637.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"27\" y=\"-632.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x8</text>\n",
       "</g>\n",
       "<!-- x8&#45;&gt;x4 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>x8&#45;&gt;x4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M27,-619.41C27,-607.76 27,-592.05 27,-578.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"30.5,-578.86 27,-568.86 23.5,-578.86 30.5,-578.86\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"39\" y=\"-588.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.00</text>\n",
       "</g>\n",
       "<!-- x9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>x9</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-460.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"99\" y=\"-455.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x9</text>\n",
       "</g>\n",
       "<!-- x9&#45;&gt;x6 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>x9&#45;&gt;x6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M92.06,-442.82C87.03,-430.74 80.12,-414.13 74.3,-400.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"77.58,-398.91 70.5,-391.02 71.11,-401.6 77.58,-398.91\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"96.22\" y=\"-411.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.00</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x150d89a1b50>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lingam.utils import make_dot\n",
    "make_dot(adj_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8552c982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 13.0.0 (20250608.1624)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"184pt\" height=\"506pt\"\n",
       " viewBox=\"0.00 0.00 184.00 506.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 502)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-502 180,-502 180,4 -4,4\"/>\n",
       "<!-- x0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-195\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"27\" y=\"-189.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x0</text>\n",
       "</g>\n",
       "<!-- x1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>x1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"58\" cy=\"-106.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"58\" y=\"-101.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x1</text>\n",
       "</g>\n",
       "<!-- x0&#45;&gt;x1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>x0&#45;&gt;x1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M32.98,-177.32C37.28,-165.31 43.18,-148.84 48.18,-134.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"51.35,-136.44 51.42,-125.85 44.76,-134.08 51.35,-136.44\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"57.28\" y=\"-145.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.52</text>\n",
       "</g>\n",
       "<!-- x2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>x2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"58\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"58\" y=\"-12.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x2</text>\n",
       "</g>\n",
       "<!-- x1&#45;&gt;x2 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>x1&#45;&gt;x2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M58,-88.41C58,-76.76 58,-61.05 58,-47.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"61.5,-47.86 58,-37.86 54.5,-47.86 61.5,-47.86\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"70\" y=\"-57.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2.00</text>\n",
       "</g>\n",
       "<!-- x3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>x3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"30\" cy=\"-303\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"30\" y=\"-297.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x3</text>\n",
       "</g>\n",
       "<!-- x3&#45;&gt;x0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x3&#45;&gt;x0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M28.86,-284.56C28.53,-278.96 28.2,-272.72 28,-267 27.5,-253.09 27.25,-237.64 27.12,-224.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"30.62,-224.71 27.05,-214.74 23.62,-224.76 30.62,-224.71\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"40\" y=\"-243.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">0.80</text>\n",
       "</g>\n",
       "<!-- x4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>x4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"149\" cy=\"-391.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"149\" y=\"-386.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x4</text>\n",
       "</g>\n",
       "<!-- x5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>x5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"149\" cy=\"-303\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"149\" y=\"-297.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x5</text>\n",
       "</g>\n",
       "<!-- x4&#45;&gt;x5 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>x4&#45;&gt;x5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M149,-373.41C149,-361.76 149,-346.05 149,-332.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"152.5,-332.86 149,-322.86 145.5,-332.86 152.5,-332.86\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"161\" y=\"-342.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.98</text>\n",
       "</g>\n",
       "<!-- x6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>x6</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"56\" cy=\"-391.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"56\" y=\"-386.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x6</text>\n",
       "</g>\n",
       "<!-- x6&#45;&gt;x3 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>x6&#45;&gt;x3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47.52,-374.09C44.81,-368.33 42,-361.73 40,-355.5 37.66,-348.21 35.78,-340.17 34.31,-332.64\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"37.78,-332.15 32.59,-322.91 30.89,-333.37 37.78,-332.15\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"52\" y=\"-342.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.18</text>\n",
       "</g>\n",
       "<!-- x7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>x7</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"88\" cy=\"-249\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"88\" y=\"-243.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x7</text>\n",
       "</g>\n",
       "<!-- x6&#45;&gt;x7 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>x6&#45;&gt;x7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.91,-373.41C61.21,-367.71 62.67,-361.33 64,-355.5 69.96,-329.35 76.74,-299.56 81.57,-278.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"84.96,-279.18 83.76,-268.65 78.13,-277.63 84.96,-279.18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"79.74\" y=\"-342.2\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.50</text>\n",
       "</g>\n",
       "<!-- x7&#45;&gt;x1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>x7&#45;&gt;x1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M86.93,-230.53C85.31,-209.37 81.48,-172.79 73,-142.5 72.26,-139.87 71.37,-137.17 70.4,-134.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"73.67,-133.26 66.66,-125.31 67.18,-135.89 73.67,-133.26\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"97.29\" y=\"-189.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">1.28</text>\n",
       "</g>\n",
       "<!-- x8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>x8</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"149\" cy=\"-480\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"149\" y=\"-474.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x8</text>\n",
       "</g>\n",
       "<!-- x8&#45;&gt;x4 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>x8&#45;&gt;x4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M149,-461.91C149,-450.26 149,-434.55 149,-421.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"152.5,-421.36 149,-411.36 145.5,-421.36 152.5,-421.36\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"161\" y=\"-430.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3.02</text>\n",
       "</g>\n",
       "<!-- x9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>x9</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"56\" cy=\"-480\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"56\" y=\"-474.95\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x9</text>\n",
       "</g>\n",
       "<!-- x9&#45;&gt;x6 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>x9&#45;&gt;x6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M56,-461.91C56,-450.26 56,-434.55 56,-421.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"59.5,-421.36 56,-411.36 52.5,-421.36 59.5,-421.36\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"68\" y=\"-430.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">2.54</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x150d44e7770>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_causal = lingam.DirectLiNGAM()\n",
    "labels = [f'{i}' for i in Z.columns]\n",
    "model_causal.fit(Z)\n",
    "causal_order = [labels[x] for x in model_causal.causal_order_]\n",
    "causal_order\n",
    "make_dot(model_causal._adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e63b153a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                                                 Australian\n",
      "path                    Australian/Credit_Card_Applications.csv\n",
      "classe                                                    Class\n",
      "metrica       {\"Quantidade de inst\\u00e2ncias contrafactuais...\n",
      "metrica_v2                                                 None\n",
      "Name: 1, dtype: object\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.66        34\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.49        69\n",
      "   macro avg       0.25      0.50      0.33        69\n",
      "weighted avg       0.24      0.49      0.33        69\n",
      "\n",
      "criou o modelo\n",
      "Start to Running samples\n",
      "Start to Running samples\n",
      "Start to Running samples\n",
      "Start to Running samples\n",
      "Start to Running samples\n",
      "Start to Running samples\n",
      "Start to Running samples\n",
      "Start to Running samples\n",
      "Start to Running samples\n",
      "Start to Running samples\n",
      "run_causal completo\n",
      "Quantidade de instâncias contrafactuais = 110\n",
      "Quantidade de relações causais na base de dados = 25\n",
      "Quantidade de atributos modificados = 215\n",
      "Quantidade de instâncias contrafactuais causais = 32\n",
      "Quantidade de relações causais analisadas = 209\n",
      "Quantidade de relações causais satisfeitas = 193\n",
      "Quantidade de instâncias contrafactuais com um único atributo modificado = 0\n",
      "Tempo de execução = 158.21856141090393\n",
      "Execução completa para Australian\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>classe</th>\n",
       "      <th>metrica</th>\n",
       "      <th>metrica_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult</td>\n",
       "      <td>adult/adult_processada.csv</td>\n",
       "      <td>Above/Below 50K</td>\n",
       "      <td>memoria 18gb</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australian</td>\n",
       "      <td>Australian/Credit_Card_Applications.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\\n    \"Quantidade de inst\\u00e2ncias contrafa...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Banknote</td>\n",
       "      <td>Banknote/BankNote_Authentication.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biodeg</td>\n",
       "      <td>Biodeg/qsar-biodeg.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\\n    \"Quantidade de instâncias contrafactuai...</td>\n",
       "      <td>zero metricas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breast Cancer Coimbra</td>\n",
       "      <td>Breast Cancer Coimbra/breast_coimbra.csv</td>\n",
       "      <td>Classification</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Breast Cancer Wisconsin</td>\n",
       "      <td>Breast Cancer Wisconsin/breast-cancer.csv</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Churn</td>\n",
       "      <td>Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...</td>\n",
       "      <td>Churn</td>\n",
       "      <td>Input contains NaN, infinity or a value too la...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Compas</td>\n",
       "      <td>Compas/compas-scores-two-years.csv</td>\n",
       "      <td>two_year_recid</td>\n",
       "      <td>base de dados nao processada</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Credit default</td>\n",
       "      <td>Credit default/UCI_Credit_Card.csv</td>\n",
       "      <td>default.payment.next.month</td>\n",
       "      <td>memoria</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Diabetes/diabetes.csv</td>\n",
       "      <td>Outcome</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EEg</td>\n",
       "      <td>EEg/EEG Eye State.csv</td>\n",
       "      <td>Column15</td>\n",
       "      <td>memoria</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>German</td>\n",
       "      <td>German/german_credit.csv</td>\n",
       "      <td>default</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GiveMeSomeCredit</td>\n",
       "      <td>GiveMeSomeCredit/GiveMeSomeCredit_processada.csv</td>\n",
       "      <td>SeriousDlqin2yrs</td>\n",
       "      <td>memoria</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Heart</td>\n",
       "      <td>Heart/heart.csv</td>\n",
       "      <td>output</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Heart_2</td>\n",
       "      <td>Heart/heart2.csv</td>\n",
       "      <td>num</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HELOC</td>\n",
       "      <td>HELOC/heloc_dataset_v1.csv</td>\n",
       "      <td>RiskPerformance</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Horse colic</td>\n",
       "      <td>Horse colic/horseV2_processada.csv</td>\n",
       "      <td>surgery</td>\n",
       "      <td>array must not contain infs or NaNs</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ionosfera</td>\n",
       "      <td>Ionosfera/ionosphere.csv</td>\n",
       "      <td>target</td>\n",
       "      <td>array must not contain infs or NaNs</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KC2</td>\n",
       "      <td>KC2/KC2.csv</td>\n",
       "      <td>defects</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>liver disorders_bupa</td>\n",
       "      <td>liver disorders_bupa/bupa.csv</td>\n",
       "      <td>selector</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mammographic_masses</td>\n",
       "      <td>mammographic_masses/mammographic_masses_cleane...</td>\n",
       "      <td>Severity</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mobile Price Classification</td>\n",
       "      <td>Mobile Price Classification/train_mobile_proce...</td>\n",
       "      <td>range</td>\n",
       "      <td>{\\n    \"Quantidade de instâncias contrafactuai...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Monk_1</td>\n",
       "      <td>['Monk/monks-1_train.csv', 'Monk/monks-1_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Monk_2</td>\n",
       "      <td>['Monk/monks-2_train.csv', 'Monk/monks-2_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Monk_3</td>\n",
       "      <td>['Monk/monks-3_train.csv', 'Monk/monks-3_test....</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Musk</td>\n",
       "      <td>Musk/clean1.csv</td>\n",
       "      <td>Column165</td>\n",
       "      <td>fica dando erro de coluna</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>OnlineNewsPopularity</td>\n",
       "      <td>OnlineNewsPopularity/OnlineNewsPopularity_proc...</td>\n",
       "      <td>class</td>\n",
       "      <td>memoria</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Phishing</td>\n",
       "      <td>Phishing/Phishing.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Room Occupancy</td>\n",
       "      <td>Room Occupancy/Room Occupancy.csv</td>\n",
       "      <td>Occupancy</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sonar</td>\n",
       "      <td>Sonar/sonar.all-data.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Spambase</td>\n",
       "      <td>Spambase/Spambase.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Student</td>\n",
       "      <td>Student/Students-Performance-MAT_processada.csv</td>\n",
       "      <td>Class</td>\n",
       "      <td>array must not contain infs or NaNs</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>titanic</td>\n",
       "      <td>titanic/titanic_processada.csv</td>\n",
       "      <td>Survived</td>\n",
       "      <td>Input contains NaN, infinity or a value too la...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo/Tokyo.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>twonorm</td>\n",
       "      <td>twonorm/twonorm.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Vertebral_2C</td>\n",
       "      <td>Vertebral/column_2C.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Vertebral_3C</td>\n",
       "      <td>Vertebral/column_3C.csv</td>\n",
       "      <td>class</td>\n",
       "      <td>{}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Votes_Congressional</td>\n",
       "      <td>Votes_Congressional/house-votes-84_processada.csv</td>\n",
       "      <td>Class Name</td>\n",
       "      <td>{\"Quantidade de inst\\u00e2ncias contrafactuais...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>wine</td>\n",
       "      <td>wine/WineQT.csv</td>\n",
       "      <td>quality</td>\n",
       "      <td>demorou demais</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Hill</td>\n",
       "      <td>['Hill/Hill_Valley_with_noise_Training.csv', '...</td>\n",
       "      <td>class</td>\n",
       "      <td>{\\n    \"Quantidade de instâncias contrafactuai...</td>\n",
       "      <td>zero metricas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  \\\n",
       "0                         Adult   \n",
       "1                    Australian   \n",
       "2                      Banknote   \n",
       "3                        Biodeg   \n",
       "4         Breast Cancer Coimbra   \n",
       "5       Breast Cancer Wisconsin   \n",
       "6                         Churn   \n",
       "7                        Compas   \n",
       "8                Credit default   \n",
       "9                      Diabetes   \n",
       "10                          EEg   \n",
       "11                       German   \n",
       "12             GiveMeSomeCredit   \n",
       "13                        Heart   \n",
       "14                      Heart_2   \n",
       "15                        HELOC   \n",
       "16                  Horse colic   \n",
       "17                    Ionosfera   \n",
       "18                          KC2   \n",
       "19         liver disorders_bupa   \n",
       "20          mammographic_masses   \n",
       "21  Mobile Price Classification   \n",
       "22                       Monk_1   \n",
       "23                       Monk_2   \n",
       "24                       Monk_3   \n",
       "25                         Musk   \n",
       "26         OnlineNewsPopularity   \n",
       "27                     Phishing   \n",
       "28               Room Occupancy   \n",
       "29                        Sonar   \n",
       "30                     Spambase   \n",
       "31                      Student   \n",
       "32                      titanic   \n",
       "33                        Tokyo   \n",
       "34                      twonorm   \n",
       "35                 Vertebral_2C   \n",
       "36                 Vertebral_3C   \n",
       "37          Votes_Congressional   \n",
       "38                         wine   \n",
       "39                         Hill   \n",
       "\n",
       "                                                 path  \\\n",
       "0                          adult/adult_processada.csv   \n",
       "1             Australian/Credit_Card_Applications.csv   \n",
       "2                Banknote/BankNote_Authentication.csv   \n",
       "3                              Biodeg/qsar-biodeg.csv   \n",
       "4            Breast Cancer Coimbra/breast_coimbra.csv   \n",
       "5           Breast Cancer Wisconsin/breast-cancer.csv   \n",
       "6   Churn/WA_Fn-UseC_-Telco-Customer-Churn_process...   \n",
       "7                  Compas/compas-scores-two-years.csv   \n",
       "8                  Credit default/UCI_Credit_Card.csv   \n",
       "9                               Diabetes/diabetes.csv   \n",
       "10                              EEg/EEG Eye State.csv   \n",
       "11                           German/german_credit.csv   \n",
       "12   GiveMeSomeCredit/GiveMeSomeCredit_processada.csv   \n",
       "13                                    Heart/heart.csv   \n",
       "14                                   Heart/heart2.csv   \n",
       "15                         HELOC/heloc_dataset_v1.csv   \n",
       "16                 Horse colic/horseV2_processada.csv   \n",
       "17                           Ionosfera/ionosphere.csv   \n",
       "18                                        KC2/KC2.csv   \n",
       "19                      liver disorders_bupa/bupa.csv   \n",
       "20  mammographic_masses/mammographic_masses_cleane...   \n",
       "21  Mobile Price Classification/train_mobile_proce...   \n",
       "22  ['Monk/monks-1_train.csv', 'Monk/monks-1_test....   \n",
       "23  ['Monk/monks-2_train.csv', 'Monk/monks-2_test....   \n",
       "24  ['Monk/monks-3_train.csv', 'Monk/monks-3_test....   \n",
       "25                                    Musk/clean1.csv   \n",
       "26  OnlineNewsPopularity/OnlineNewsPopularity_proc...   \n",
       "27                              Phishing/Phishing.csv   \n",
       "28                  Room Occupancy/Room Occupancy.csv   \n",
       "29                           Sonar/sonar.all-data.csv   \n",
       "30                              Spambase/Spambase.csv   \n",
       "31    Student/Students-Performance-MAT_processada.csv   \n",
       "32                     titanic/titanic_processada.csv   \n",
       "33                                    Tokyo/Tokyo.csv   \n",
       "34                                twonorm/twonorm.csv   \n",
       "35                            Vertebral/column_2C.csv   \n",
       "36                            Vertebral/column_3C.csv   \n",
       "37  Votes_Congressional/house-votes-84_processada.csv   \n",
       "38                                    wine/WineQT.csv   \n",
       "39  ['Hill/Hill_Valley_with_noise_Training.csv', '...   \n",
       "\n",
       "                        classe  \\\n",
       "0              Above/Below 50K   \n",
       "1                        Class   \n",
       "2                        class   \n",
       "3                        Class   \n",
       "4               Classification   \n",
       "5                    diagnosis   \n",
       "6                        Churn   \n",
       "7               two_year_recid   \n",
       "8   default.payment.next.month   \n",
       "9                      Outcome   \n",
       "10                    Column15   \n",
       "11                     default   \n",
       "12            SeriousDlqin2yrs   \n",
       "13                      output   \n",
       "14                         num   \n",
       "15             RiskPerformance   \n",
       "16                     surgery   \n",
       "17                      target   \n",
       "18                     defects   \n",
       "19                    selector   \n",
       "20                    Severity   \n",
       "21                       range   \n",
       "22                       Class   \n",
       "23                       Class   \n",
       "24                       Class   \n",
       "25                   Column165   \n",
       "26                       class   \n",
       "27                       Class   \n",
       "28                   Occupancy   \n",
       "29                       class   \n",
       "30                       Class   \n",
       "31                       Class   \n",
       "32                    Survived   \n",
       "33                       class   \n",
       "34                       class   \n",
       "35                       class   \n",
       "36                       class   \n",
       "37                  Class Name   \n",
       "38                     quality   \n",
       "39                       class   \n",
       "\n",
       "                                              metrica     metrica_v2  \n",
       "0                                        memoria 18gb           None  \n",
       "1   {\\n    \"Quantidade de inst\\u00e2ncias contrafa...           None  \n",
       "2   {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "3   {\\n    \"Quantidade de instâncias contrafactuai...  zero metricas  \n",
       "4   {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "5   {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "6   Input contains NaN, infinity or a value too la...           None  \n",
       "7                        base de dados nao processada           None  \n",
       "8                                             memoria           None  \n",
       "9   {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "10                                            memoria           None  \n",
       "11  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "12                                            memoria           None  \n",
       "13  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "14  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "15  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "16                array must not contain infs or NaNs           None  \n",
       "17                array must not contain infs or NaNs           None  \n",
       "18  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "19  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "20  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "21  {\\n    \"Quantidade de instâncias contrafactuai...           None  \n",
       "22  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "23  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "24  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "25                          fica dando erro de coluna           None  \n",
       "26                                            memoria           None  \n",
       "27  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "28  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "29  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "30  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "31                array must not contain infs or NaNs           None  \n",
       "32  Input contains NaN, infinity or a value too la...           None  \n",
       "33  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "34  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "35  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "36                                                 {}           None  \n",
       "37  {\"Quantidade de inst\\u00e2ncias contrafactuais...           None  \n",
       "38                                     demorou demais           None  \n",
       "39  {\\n    \"Quantidade de instâncias contrafactuai...  zero metricas  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = {\n",
    "    \"Australian\": [\"Australian\"],\n",
    "}\n",
    "\n",
    "for g in groups:\n",
    "    df_map_inference_datasets = handler(str(groups[g]), 'rn')\n",
    "    \n",
    "df_map_inference_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bc0f391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>as</th>\n",
       "      <th>ac</th>\n",
       "      <th>at</th>\n",
       "      <th>ap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_0</th>\n",
       "      <td>96</td>\n",
       "      <td>206</td>\n",
       "      <td>577</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_1</th>\n",
       "      <td>62</td>\n",
       "      <td>136</td>\n",
       "      <td>438</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_2</th>\n",
       "      <td>59</td>\n",
       "      <td>181</td>\n",
       "      <td>537</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_3</th>\n",
       "      <td>76</td>\n",
       "      <td>196</td>\n",
       "      <td>603</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_4</th>\n",
       "      <td>12</td>\n",
       "      <td>41</td>\n",
       "      <td>191</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     as   ac   at  ap\n",
       "x_0  96  206  577  93\n",
       "x_1  62  136  438  77\n",
       "x_2  59  181  537  24\n",
       "x_3  76  196  603   3\n",
       "x_4  12   41  191  79"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dados\n",
    "data = {\n",
    "    \"x_0\": [96, 206, 577, 93],\n",
    "    \"x_1\": [62, 136, 438, 77],\n",
    "    \"x_2\": [59, 181, 537, 24],\n",
    "    \"x_3\": [76, 196, 603, 3],\n",
    "    \"x_4\": [12, 41, 191, 79]\n",
    "}\n",
    "\n",
    "# Transpor para deixar cada $x_i$ como linha\n",
    "df = pd.DataFrame(data, index=[\"as\", \"ac\", \"at\", \"ap\"]).T\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b6c2ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_est (without the 2nd phase) is: \n",
      " [[ 0.          2.21185572 -1.23763873  2.29213625]\n",
      " [ 0.          0.          3.25509843 -0.61611709]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.91046437  0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  2.21185572, -1.23763873,  2.29213625],\n",
       "       [ 0.        ,  0.        ,  3.25509843, -0.61611709],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.91046437,  0.        ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_causal = lingam.LiM()\n",
    "model_causal.fit(df.values, np.array([[1,1,1,1]]), only_global=True)\n",
    "model_causal._adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9e92fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[2, 3, 1, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 3, 1, 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search_causal_order(matrix):\n",
    "    \"\"\"Obtain a causal order from the given matrix strictly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    matrix : array-like, shape (n_features, n_samples)\n",
    "        Target matrix.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    causal_order : array, shape [n_features, ]\n",
    "        A causal order of the given matrix on success, None otherwise.\n",
    "    \"\"\"\n",
    "    causal_order = []\n",
    "\n",
    "    row_num = matrix.shape[0]\n",
    "    original_index = np.arange(row_num)\n",
    "    print(len(matrix))\n",
    "    while 0 < len(matrix):\n",
    "        # find a row all of which elements are zero\n",
    "        row_index_list = np.where(np.sum(np.abs(matrix), axis=1) == 0)[0]\n",
    "        if len(row_index_list) == 0:\n",
    "            print('break')\n",
    "            break\n",
    "\n",
    "        target_index = row_index_list[0]\n",
    "\n",
    "        # append i to the end of the list\n",
    "        causal_order.append(original_index[target_index])\n",
    "        original_index = np.delete(original_index, target_index, axis=0)\n",
    "\n",
    "        # remove the i-th row and the i-th column from matrix\n",
    "        mask = np.delete(np.arange(len(matrix)), target_index, axis=0)\n",
    "        matrix = matrix[mask][:, mask]\n",
    "    print(causal_order)\n",
    "    if len(causal_order) != row_num:\n",
    "        \n",
    "        causal_order = None\n",
    "\n",
    "    return causal_order\n",
    "\n",
    "asd = search_causal_order(model_causal._adjacency_matrix)\n",
    "asd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06d34855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x1', 'x4', 'x2', 'x5', 'x0', 'x3']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [f'{i}' for i in X.columns]\n",
    "\n",
    "causal_order_columns = [labels[i] for i in asd]\n",
    "causal_order_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "457934d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>effect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x0</td>\n",
       "      <td>x5</td>\n",
       "      <td>4.183060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x2</td>\n",
       "      <td>x1</td>\n",
       "      <td>2.174203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x2</td>\n",
       "      <td>x4</td>\n",
       "      <td>-0.285400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x3</td>\n",
       "      <td>x0</td>\n",
       "      <td>3.413356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x4</td>\n",
       "      <td>x1</td>\n",
       "      <td>0.329998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>x5</td>\n",
       "      <td>x1</td>\n",
       "      <td>0.184035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>x5</td>\n",
       "      <td>x2</td>\n",
       "      <td>0.417841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>x5</td>\n",
       "      <td>x4</td>\n",
       "      <td>1.646828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  from  to    effect\n",
       "0   x0  x5  4.183060\n",
       "1   x2  x1  2.174203\n",
       "2   x2  x4 -0.285400\n",
       "3   x3  x0  3.413356\n",
       "4   x4  x1  0.329998\n",
       "5   x5  x1  0.184035\n",
       "6   x5  x2  0.417841\n",
       "7   x5  x4  1.646828"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = model_causal._adjacency_matrix\n",
    "from_list = []\n",
    "to_list = []\n",
    "effect_list = []\n",
    "\n",
    "for i in range(len(matrix)):\n",
    "    for j in range(len(matrix[i])):\n",
    "        if matrix[i][j] != 0:\n",
    "            from_list.append(j)\n",
    "            to_list.append(i)\n",
    "            effect_list.append(matrix[i][j])\n",
    "\n",
    "# Criando o DataFrame\n",
    "bnm = pd.DataFrame({'from': to_list, 'to': from_list, 'effect': effect_list})\n",
    "labels = [f'{i}' for i in X.columns]\n",
    "bnm['from'] = bnm['from'].apply(lambda x : labels[x])\n",
    "bnm['to'] = bnm['to'].apply(lambda x : labels[x])\n",
    "\n",
    "bnm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c341cedb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\OmarKrauss\\Desktop\\pessoal\\tcc\\tcc\\.venv\\Lib\\site-packages\\graphviz\\backend\\execute.py:76\u001b[39m, in \u001b[36mrun_check\u001b[39m\u001b[34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m         kwargs[\u001b[33m'\u001b[39m\u001b[33mstdout\u001b[39m\u001b[33m'\u001b[39m] = kwargs[\u001b[33m'\u001b[39m\u001b[33mstderr\u001b[39m\u001b[33m'\u001b[39m] = subprocess.PIPE\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     proc = \u001b[43m_run_input_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_lines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\OmarKrauss\\Desktop\\pessoal\\tcc\\tcc\\.venv\\Lib\\site-packages\\graphviz\\backend\\execute.py:96\u001b[39m, in \u001b[36m_run_input_lines\u001b[39m\u001b[34m(cmd, input_lines, kwargs)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_input_lines\u001b[39m(cmd, input_lines, *, kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     popen = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdin\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m     stdin_write = popen.stdin.write\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py:1028\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1025\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1026\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1037\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1038\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py:1540\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[39m\n\u001b[32m   1539\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m     hp, ht, pid, tid = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1541\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[32m   1542\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1543\u001b[39m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1544\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1545\u001b[39m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1546\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1547\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1548\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1549\u001b[39m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[32m   1550\u001b[39m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1553\u001b[39m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[32m   1554\u001b[39m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 2] O sistema não pode encontrar o arquivo especificado",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mExecutableNotFound\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\OmarKrauss\\Desktop\\pessoal\\tcc\\tcc\\.venv\\Lib\\site-packages\\IPython\\core\\formatters.py:1036\u001b[39m, in \u001b[36mMimeBundleFormatter.__call__\u001b[39m\u001b[34m(self, obj, include, exclude)\u001b[39m\n\u001b[32m   1033\u001b[39m     method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n\u001b[32m   1035\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1036\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\OmarKrauss\\Desktop\\pessoal\\tcc\\tcc\\.venv\\Lib\\site-packages\\graphviz\\jupyter_integration.py:98\u001b[39m, in \u001b[36mJupyterIntegration._repr_mimebundle_\u001b[39m\u001b[34m(self, include, exclude, **_)\u001b[39m\n\u001b[32m     96\u001b[39m include = \u001b[38;5;28mset\u001b[39m(include) \u001b[38;5;28;01mif\u001b[39;00m include \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {\u001b[38;5;28mself\u001b[39m._jupyter_mimetype}\n\u001b[32m     97\u001b[39m include -= \u001b[38;5;28mset\u001b[39m(exclude \u001b[38;5;129;01mor\u001b[39;00m [])\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {mimetype: \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m mimetype, method_name \u001b[38;5;129;01min\u001b[39;00m MIME_TYPES.items()\n\u001b[32m    100\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m mimetype \u001b[38;5;129;01min\u001b[39;00m include}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\OmarKrauss\\Desktop\\pessoal\\tcc\\tcc\\.venv\\Lib\\site-packages\\graphviz\\jupyter_integration.py:112\u001b[39m, in \u001b[36mJupyterIntegration._repr_image_svg_xml\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_repr_image_svg_xml\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    111\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the rendered graph as SVG string.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msvg\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSVG_ENCODING\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\OmarKrauss\\Desktop\\pessoal\\tcc\\tcc\\.venv\\Lib\\site-packages\\graphviz\\piping.py:104\u001b[39m, in \u001b[36mPipe.pipe\u001b[39m\u001b[34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpipe\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[32m     56\u001b[39m          \u001b[38;5;28mformat\u001b[39m: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     57\u001b[39m          renderer: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m          engine: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     62\u001b[39m          encoding: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> typing.Union[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the source piped through the Graphviz layout command.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    102\u001b[39m \u001b[33;03m        '<?xml version='\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pipe_legacy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\OmarKrauss\\Desktop\\pessoal\\tcc\\tcc\\.venv\\Lib\\site-packages\\graphviz\\_tools.py:171\u001b[39m, in \u001b[36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    162\u001b[39m     wanted = \u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    163\u001b[39m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated.items())\n\u001b[32m    164\u001b[39m     warnings.warn(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m will be reduced\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    165\u001b[39m                   \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m positional args\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    166\u001b[39m                   \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    167\u001b[39m                   \u001b[33m'\u001b[39m\u001b[33m as keyword arg(s)\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    168\u001b[39m                   stacklevel=stacklevel,\n\u001b[32m    169\u001b[39m                   category=category)\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\OmarKrauss\\Desktop\\pessoal\\tcc\\tcc\\.venv\\Lib\\site-packages\\graphviz\\piping.py:121\u001b[39m, in \u001b[36mPipe._pipe_legacy\u001b[39m\u001b[34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;129m@_tools\u001b[39m.deprecate_positional_args(supported_number=\u001b[32m2\u001b[39m)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_pipe_legacy\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    114\u001b[39m                  \u001b[38;5;28mformat\u001b[39m: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    119\u001b[39m                  engine: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    120\u001b[39m                  encoding: typing.Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m) -> typing.Union[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pipe_future\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneato_no_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\OmarKrauss\\Desktop\\pessoal\\tcc\\tcc\\.venv\\Lib\\site-packages\\graphviz\\piping.py:149\u001b[39m, in \u001b[36mPipe._pipe_future\u001b[39m\u001b[34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m codecs.lookup(encoding) \u001b[38;5;129;01mis\u001b[39;00m codecs.lookup(\u001b[38;5;28mself\u001b[39m.encoding):\n\u001b[32m    148\u001b[39m         \u001b[38;5;66;03m# common case: both stdin and stdout need the same encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pipe_lines_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    151\u001b[39m         raw = \u001b[38;5;28mself\u001b[39m._pipe_lines(*args, input_encoding=\u001b[38;5;28mself\u001b[39m.encoding, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\OmarKrauss\\Desktop\\pessoal\\tcc\\tcc\\.venv\\Lib\\site-packages\\graphviz\\backend\\piping.py:212\u001b[39m, in \u001b[36mpipe_lines_string\u001b[39m\u001b[34m(engine, format, input_lines, encoding, renderer, formatter, neato_no_op, quiet)\u001b[39m\n\u001b[32m    206\u001b[39m cmd = dot_command.command(engine, \u001b[38;5;28mformat\u001b[39m,\n\u001b[32m    207\u001b[39m                           renderer=renderer,\n\u001b[32m    208\u001b[39m                           formatter=formatter,\n\u001b[32m    209\u001b[39m                           neato_no_op=neato_no_op)\n\u001b[32m    210\u001b[39m kwargs = {\u001b[33m'\u001b[39m\u001b[33minput_lines\u001b[39m\u001b[33m'\u001b[39m: input_lines, \u001b[33m'\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m'\u001b[39m: encoding}\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m proc = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m proc.stdout\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\OmarKrauss\\Desktop\\pessoal\\tcc\\tcc\\.venv\\Lib\\site-packages\\graphviz\\backend\\execute.py:81\u001b[39m, in \u001b[36mrun_check\u001b[39m\u001b[34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.errno == errno.ENOENT:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet \u001b[38;5;129;01mand\u001b[39;00m proc.stderr:\n",
      "\u001b[31mExecutableNotFound\u001b[39m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x22ecfdfe0c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c3c14b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
