{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f5cf5a8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lingam in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.8.3)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (1.4.1.post1)\n",
      "Requirement already satisfied: graphviz in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (0.20.3)\n",
      "Requirement already satisfied: statsmodels in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (0.14.1)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (3.2.1)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (2.2.0)\n",
      "Requirement already satisfied: pygam in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (0.9.1)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (3.8.3)\n",
      "Requirement already satisfied: psy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (0.0.1)\n",
      "Requirement already satisfied: semopy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from lingam) (2.3.11)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->lingam) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->lingam) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->lingam) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->lingam) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->lingam) (21.3)\n",
      "Requirement already satisfied: pillow>=8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->lingam) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->lingam) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib->lingam) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->lingam) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->lingam) (2024.1)\n",
      "Requirement already satisfied: progressbar2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from psy->lingam) (4.4.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn->lingam) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from scikit-learn->lingam) (3.3.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from semopy->lingam) (1.12)\n",
      "Requirement already satisfied: numdifftools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from semopy->lingam) (0.9.41)\n",
      "Requirement already satisfied: patsy>=0.5.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from statsmodels->lingam) (0.5.6)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from patsy>=0.5.4->statsmodels->lingam) (1.16.0)\n",
      "Requirement already satisfied: python-utils>=3.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from progressbar2->psy->lingam) (3.8.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->semopy->lingam) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>3.10.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-utils>=3.8.1->progressbar2->psy->lingam) (4.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lingam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37b54b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#German\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from csse import CSSE\n",
    "from prepare_dataset import *\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "import lingam\n",
    "from lingam.utils import print_causal_directions, print_dagc, make_dot\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random as rnd\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b7584be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#German\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from csse import CSSE\n",
    "from prepare_dataset import *\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "import lingam\n",
    "from lingam.utils import print_causal_directions, print_dagc, make_dot\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random as rnd\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "class CCSSE:\n",
    "    def __init__(self, dataset, samples = None, K = 5, generation = 10):\n",
    "        self.dataset = dataset\n",
    "        self.samples = samples\n",
    "        self.K = K\n",
    "        self.generation = generation\n",
    "        \n",
    "        self.x_train, self.x_test, self.y_train, self.y_test, self.dfx_full, self.dfy_full = self.get_datasets_train_test()\n",
    "\n",
    "        self.bb_model, self.p = self.get_bb_model()\n",
    "        self.explainerCSSE = self.get_model_contrafactual()\n",
    "        self.model_causal, self.df_causal_effects, self.df_error, self.causal_order = self.get_model_causality()\n",
    "    \n",
    "        self.run_dict = {}\n",
    "        self.run_non_causal_dict = {}\n",
    "    \n",
    "    def get_datasets_train_test(self):\n",
    "        if self.dataset == \"german_short\":\n",
    "            map_columns = {\n",
    "                'Unnamed: 0': 'index',\n",
    "                'x0': 'Sex',\n",
    "                'x1': 'Age',\n",
    "                'x2': 'Credit',\n",
    "                'x3': 'LoanDuration',\n",
    "            }\n",
    "            x_train = pd.read_csv(\"data/algrec_german/X_train_short.csv\").rename(columns = map_columns)\n",
    "            x_test = pd.read_csv(\"data/algrec_german/X_test_short.csv\").rename(columns = map_columns)\n",
    "            y_train = pd.read_csv(\"data/algrec_german/y_train_short.csv\").rename(columns={'Unnamed: 0': 'index'})\n",
    "            y_test = pd.read_csv(\"data/algrec_german/y_test_short.csv\").rename(columns={'Unnamed: 0': 'index'})\n",
    "            x_train = x_train.set_index('index')\n",
    "            x_test = x_test.set_index('index')\n",
    "            y_train = y_train.set_index('index')\n",
    "            y_test = y_test.set_index('index')\n",
    "            dfx_full = pd.concat([x_train, x_test])\n",
    "            dfy_full = pd.concat([y_train, y_test])\n",
    "\n",
    "        elif self.dataset == \"german_medium\":\n",
    "            map_columns = {\n",
    "                'Unnamed: 0': 'index',\n",
    "                'x0': 'Sex',\n",
    "                'x1': 'Age',\n",
    "                'x2': 'Credit',\n",
    "                'x3': 'LoanDuration',\n",
    "                'x4': 'CheckingAccountBalance',\n",
    "                'x5':'SavingsAccountBalance',\n",
    "                'x6':'HousingStatus'\n",
    "            }\n",
    "            x_train = pd.read_csv(\"data/algrec_german/X_train.csv\").rename(columns = map_columns)\n",
    "            x_test = pd.read_csv(\"data/algrec_german/X_train.csv\").rename(columns = map_columns)\n",
    "            y_train = pd.read_csv(\"data/algrec_german/X_train.csv\").rename(columns={'Unnamed: 0': 'index'})\n",
    "            y_test = pd.read_csv(\"data/algrec_german/X_train.csv\").rename(columns={'Unnamed: 0': 'index'})\n",
    "            x_train = x_train.set_index('index')\n",
    "            x_test = x_test.set_index('index')\n",
    "            y_train = y_train.set_index('index')\n",
    "            y_test = y_test.set_index('index')\n",
    "            dfx_full = pd.concat([x_train, x_test])\n",
    "            dfy_full = pd.concat([y_train, y_test])\n",
    "\n",
    "        elif self.dataset == \"german_full\":\n",
    "            df_main = prepare_german_dataset(\"german_credit.csv\", \"data/\")\n",
    "            columns = df_main.columns\n",
    "            class_name = 'default' # default = 0 = \"Good class\" / default = 1 = \"Bad class\" \n",
    "            columns_tmp = list(columns)\n",
    "            columns_tmp.remove(class_name)\n",
    "\n",
    "            x_train, x_test, y_train, y_test = train_test_split(df_main[columns_tmp], df_main[class_name], test_size=0.1)\n",
    "\n",
    "            dfx_full = pd.concat([x_train, x_test])\n",
    "            dfy_full = pd.concat([y_train, y_test])\n",
    "\n",
    "        else:\n",
    "            x_train = pd.DataFrame()\n",
    "            x_test = pd.DataFrame()\n",
    "            y_train = pd.DataFrame()\n",
    "            y_test = pd.DataFrame()\n",
    "            dfx_full = pd.DataFrame()\n",
    "            dfy_full = pd.DataFrame()\n",
    "\n",
    "        return x_train, x_test, y_train, y_test, dfx_full, dfy_full\n",
    "    \n",
    "\n",
    "    def get_bb_model(self):\n",
    "        bb_model = RandomForestClassifier()  \n",
    "        bb_model.fit(self.x_train, self.y_train)\n",
    "\n",
    "        p = bb_model.predict(self.x_test)\n",
    "\n",
    "        print(classification_report(self.y_test, p))\n",
    "\n",
    "        return bb_model, p\n",
    "\n",
    "    def get_model_contrafactual(self):\n",
    "        return CSSE(self.dfx_full, self.bb_model, K = self.K, num_gen = self.generation)\n",
    "\n",
    "    def get_model_causality(self):\n",
    "        model_causal = lingam.DirectLiNGAM()\n",
    "        model_causal.fit(self.dfx_full)\n",
    "            \n",
    "        labels = [f'{i}' for i in self.dfx_full.columns]\n",
    "        causal_order = [labels[x] for x in model_causal.causal_order_]\n",
    "        \n",
    "        matrix = model_causal.adjacency_matrix_\n",
    "        from_list = []\n",
    "        to_list = []\n",
    "        effect_list = []\n",
    "\n",
    "        # Iteração sobre a matriz para extrair os valores e suas posições\n",
    "        for i in range(len(matrix)):\n",
    "            for j in range(len(matrix[i])):\n",
    "                if matrix[i][j] != 0:\n",
    "                    from_list.append(j)\n",
    "                    to_list.append(i)\n",
    "                    effect_list.append(matrix[i][j])\n",
    "\n",
    "        # Criando o DataFrame\n",
    "        df_causal_effects = pd.DataFrame({'from': from_list, 'to': to_list, 'effect': effect_list})\n",
    "        labels = [f'{i}' for i in self.dfx_full.columns]\n",
    "        df_causal_effects['from'] = df_causal_effects['from'].apply(lambda x : labels[x])\n",
    "        df_causal_effects['to'] = df_causal_effects['to'].apply(lambda x : labels[x])\n",
    "\n",
    "\n",
    "        matrix_error = model_causal.get_error_independence_p_values(self.dfx_full)\n",
    "        from_list = []\n",
    "        to_list = []\n",
    "        effect_list = []\n",
    "\n",
    "        # Iteração sobre a matriz para extrair os valores e suas posições\n",
    "        for i in range(len(matrix_error)):\n",
    "            for j in range(i + 1, len(matrix_error[i])):\n",
    "                if matrix_error[i][j] != 0:\n",
    "                    from_list.append(j)\n",
    "                    to_list.append(i)\n",
    "                    effect_list.append(matrix_error[i][j])\n",
    "\n",
    "        # Criando o DataFrame\n",
    "        df_error = pd.DataFrame({'from': from_list, 'to': to_list, 'effect': effect_list})\n",
    "        labels = [f'{i}' for i in self.dfx_full.columns]\n",
    "        df_error['from'] = df_error['from'].apply(lambda x : labels[x])\n",
    "        df_error['to'] = df_error['to'].apply(lambda x : labels[x])\n",
    "        \n",
    "\n",
    "        return model_causal, df_causal_effects, df_error, causal_order\n",
    "        \n",
    "    \n",
    "    def print_causal_graph(self):\n",
    "        make_dot(self.model_causal.adjacency_matrix_)\n",
    "\n",
    "    def run_non_causal(self):\n",
    "        self.run_non_causal_dict = {}\n",
    "\n",
    "        if isinstance(self.samples, list):\n",
    "            self.create_run_dict(self)\n",
    "            for sample in self.samples:\n",
    "                self.run_non_causal_sample(sample)\n",
    "                \n",
    "        elif isinstance(self.samples, int):\n",
    "            for sample in range(self.samples):\n",
    "                self.run_non_causal_sample(sample)\n",
    "        \n",
    "        else: \n",
    "            for sample in range(10):\n",
    "                self.run_non_causal_sample(sample)\n",
    "                \n",
    "    def run_non_causal_sample(self, sample):\n",
    "        self.run_non_causal_dict[sample] = {}\n",
    "        original_instance = self.x_test.iloc[sample].copy()\n",
    "        contrafactual_set, solution = self.explainerCSSE.explain(original_instance, self.p[sample]) #Method returns the list of counterfactuals and the explanations generated from them\n",
    "\n",
    "        self.run_non_causal_dict[sample]['solution'] = solution\n",
    "\n",
    "    def run_causal(self):\n",
    "        self.run_dict = {}\n",
    "        self.run_dict['global_numbers'] = {\n",
    "                    \"global_quant_changes\": 0,\n",
    "                    \"global_quant_causal_changes\": 0,\n",
    "                    \"global_quant_causal_rules\": 0,\n",
    "                    \"global_quant_zeros_causal\": 0,\n",
    "                    \"global_quant_full_causal\": 0,\n",
    "                    \"global_quant_causal_contrafac\": 0,\n",
    "                    \"global_quant_maioria_causal_satisfeita\": 0,\n",
    "                    \"global_quant_contrafac_unico\": 0\n",
    "            }\n",
    "        self.global_quant_contrafac_max = 0\n",
    "        if isinstance(self.samples, list):\n",
    "            self.create_run_dict(self)\n",
    "            for sample in self.samples:\n",
    "                self.run_causal_sample(sample)\n",
    "                \n",
    "        elif isinstance(self.samples, int):\n",
    "            for sample in range(self.samples):\n",
    "                self.run_causal_sample(sample)\n",
    "        \n",
    "        else: \n",
    "            for sample in range(10):\n",
    "                self.run_causal_sample(sample)\n",
    "        \n",
    "        self.global_quant_contrafac_max = self.K * len(self.run_dict)\n",
    "\n",
    "\n",
    "    def run_causal_sample(self, sample):\n",
    "        original_instance = self.x_test.iloc[sample]\n",
    "        self.run_dict[sample] = {}\n",
    "        self.run_dict[sample]['original_instance'] = original_instance\n",
    "\n",
    "        print(f'Running original instance:\\n {display(original_instance)}')\n",
    "\n",
    "        causal_explain = self.get_causal_explain(sample)\n",
    "        self.run_dict[sample]['causal_explain'] = causal_explain\n",
    "\n",
    "        list_analyse = []\n",
    "        for contrafactual in causal_explain[0]:\n",
    "            list_analyse.append(self.analyse_contrafac(contrafactual, causal_explain[1], causal_explain[2]))\n",
    "\n",
    "        self.run_dict[sample]['list_analyse'] = list_analyse\n",
    "        self.analyse_explaination(sample)\n",
    "\n",
    "    def analyse_contrafac(self, contrafac, df, original_ind):\n",
    "        columns = [x.column for x in contrafac]\n",
    "        condicao = (df['to'].isin(columns)) & (df['from'].isin(columns))\n",
    "        ind = original_ind[columns]\n",
    "        return [contrafac, df[condicao], ind]\n",
    "\n",
    "    def get_causal_explain(self, sample):\n",
    "        original_ind = self.x_test.iloc[sample].copy() #Original instance\n",
    "        #self.ind_cur_class = ind_cur_class #Index in the shap corresponds to the original instance class\n",
    "        self.explainerCSSE.current_class = self.p[sample] #Original instance class\n",
    "        self.explainerCSSE.original_ind = original_ind\n",
    "        \n",
    "        ind_cur_class = self.explainerCSSE.getBadClass()\n",
    "\n",
    "        #Gets the valid values range of each feature\n",
    "        features_range = []\n",
    "        features_range = self.explainerCSSE.getFeaturesRange()\n",
    "\n",
    "        #The DataFrame df will have the current population\n",
    "        df = pd.DataFrame(columns=self.explainerCSSE.input_dataset.columns)\n",
    "\n",
    "        #Generates the initial population with popinitial mutants        \n",
    "        self.explainerCSSE.getPopInicial(df, features_range)\n",
    "        df_causal = df.copy()\n",
    "        dict_dfs = {}\n",
    "\n",
    "        # for g in tqdm(range(self.explainerCSSE.num_gen), desc= \"Processing...\"):\n",
    "        for g in tqdm(range(self.generation), desc= \"Processing...\"):\n",
    "\n",
    "            #To use on the parents of each generation\n",
    "            old_parents = pd.DataFrame(columns=self.explainerCSSE.input_dataset.columns)\n",
    "\n",
    "            #Copy parents to the next generation\n",
    "            old_parents = df_causal.copy()\n",
    "            dict_dfs[g] = {}\n",
    "\n",
    "            parents_causal = self.apply_causality(old_parents)\n",
    "            dict_dfs[g]['causal_parents'] = parents_causal\n",
    "            #df will contain the new population\n",
    "            df_causal = pd.DataFrame(columns=self.explainerCSSE.input_dataset.columns)\n",
    "            evaluation_causal = []\n",
    "\n",
    "            #Assessing generation counterfactuals\n",
    "            self.explainerCSSE.fitness(dict_dfs[g]['causal_parents'], evaluation_causal, ind_cur_class)\n",
    "\n",
    "            #The original individual will always be in the 0 position of the df - So that it is normalized too (it will be used later in the distance function)\n",
    "            df_causal.loc[0] = original_ind.copy()\n",
    "\n",
    "            #Copies to the next generation the per_elit best individuals\n",
    "            self.explainerCSSE.elitism(evaluation_causal, df_causal, parents_causal)\n",
    "            number_cross_repetitions = 0\n",
    "            while len(df_causal) < self.explainerCSSE.pop_size + 1: #+1, as the 1st position is used to store the reference individual\n",
    "                number_cross_repetitions_causal = self.explainerCSSE.crossover(df_causal, parents_causal, evaluation_causal, number_cross_repetitions)\n",
    "\n",
    "                mutation_op = rnd.random()\n",
    "                if mutation_op <= self.explainerCSSE.mutation_proba:\n",
    "                    self.explainerCSSE.mutation(df_causal, len(df_causal) - 1, features_range)\n",
    "\n",
    "\n",
    "        evaluation = []\n",
    "        evaluation_causal = []\n",
    "\n",
    "        #Evaluating the latest generation\n",
    "        self.explainerCSSE.fitness(df_causal, evaluation_causal, ind_cur_class)\n",
    "\n",
    "        #Order the last generation by distance to the original instance     \n",
    "        evaluation_causal.sort(key=lambda individual: individual.aval_norm) \n",
    "\n",
    "        #Getting the counterfactual CAUSAL set\n",
    "        contrafactual_set_causal, solution_list_causal = self.explainerCSSE.getContrafactual(df_causal, evaluation_causal) \n",
    "\n",
    "        dict_dfs['contrafactual_set_causal'] = contrafactual_set_causal\n",
    "        dict_dfs['solution_list_causal'] = solution_list_causal\n",
    "        \n",
    "        df_contrafac_causal = self.get_contrafac_df_causal(solution_list_causal)\n",
    "        return [solution_list_causal, df_contrafac_causal, original_ind]\n",
    "    \n",
    "\n",
    "    def apply_causality(self, df):\n",
    "        df_apply_causal = pd.DataFrame(columns = df.columns)\n",
    "        original = df.iloc[0]\n",
    "        df_apply_causal.loc[0] = original\n",
    "        for index, df_row in df.iloc[1:].iterrows():\n",
    "            causal_ind = df_row.copy()\n",
    "            for column in self.causal_order:\n",
    "                value_diff = causal_ind[column] - original[column]\n",
    "                if value_diff != 0:\n",
    "                    tmp_effects = self.df_causal_effects[self.df_causal_effects['from'] == column]\n",
    "                    for index, row in tmp_effects.iterrows():\n",
    "    #                     prob = rnd.random()\n",
    "    #                     if row['probability'] <= prob:\n",
    "                        tmp_error = self.df_error[self.df_error['from'].isin([column, row['to']]) | self.df_error['to'].isin([column, row['to']])]\n",
    "                        error_value = tmp_error['effect'].iloc[0]\n",
    "    #                     print(f'error value = {error_value}')\n",
    "                        causal_ind[row['to']] = causal_ind[row['to']] + (value_diff * row['effect']) + tmp_error['effect'].iloc[0]\n",
    "            df_apply_causal.loc[len(df_apply_causal)] = causal_ind\n",
    "        return df_apply_causal\n",
    "\n",
    "\n",
    "    def get_contrafac_df_causal(self, solution_list_causal):\n",
    "        lista_solution_causal = [[t.column for t in sublist] for sublist in solution_list_causal]\n",
    "\n",
    "        # Inicializa uma lista para armazenar os resultados\n",
    "        resultados = []\n",
    "\n",
    "        # Loop sobre os valores na lista\n",
    "        for lista_valores in lista_solution_causal:\n",
    "            if len(lista_valores) > 1:\n",
    "                for v1 in lista_valores:\n",
    "                    for v2 in lista_valores:\n",
    "                        if v1 != v2:\n",
    "                            # Cria uma condição para cada par de valores diferentes na lista\n",
    "                            condicao = (self.df_causal_effects['to'].isin([v1, v2])) & (self.df_causal_effects['from'].isin([v1, v2]))\n",
    "                            # Realiza a busca no DataFrame usando a condição e armazena os resultados\n",
    "                            resultados.append(self.df_causal_effects[condicao])\n",
    "\n",
    "        # Concatena os resultados em um único DataFrame\n",
    "        if resultados:\n",
    "            resultado_final = pd.concat(resultados)\n",
    "            resultado_final = resultado_final.drop_duplicates()\n",
    "        else:\n",
    "            resultado_final = pd.DataFrame(columns = self.df_causal_effects.columns)\n",
    "            \n",
    "        return resultado_final\n",
    "    \n",
    "\n",
    "    def analyse_explaination(self, sample):\n",
    "        self.run_dict[sample]['data_analysis'] = []\n",
    "        for i, content in enumerate(self.run_dict[sample]['list_analyse']):\n",
    "            self.global_quant_contrafac_max += 1\n",
    "            controle = {}\n",
    "            causal = content[0]\n",
    "            df = content[1]\n",
    "            ori = content[2]\n",
    "            \n",
    "            \n",
    "            num_changes = len(causal)\n",
    "            self.run_dict['global_numbers']['global_quant_changes'] += num_changes\n",
    "            \n",
    "            num_causal_rules = len(df)\n",
    "            self.run_dict['global_numbers']['global_quant_causal_rules'] += num_causal_rules\n",
    "            \n",
    "            for attr in causal:\n",
    "                key = attr.column\n",
    "                if attr.value > ori[key]:\n",
    "                    controle[key] = 'mais'\n",
    "                else:\n",
    "                    controle[key] = 'menos'\n",
    "\n",
    "            df_temp = df.copy()\n",
    "            df_temp['from'] = df['from'].map(controle)\n",
    "            df_temp['to'] = df['to'].map(controle)\n",
    "            df_temp['causal'] = df_temp.apply(self.verificar_condicoes, axis = 1)\n",
    "            data_dict = {}\n",
    "\n",
    "            data_dict['df_respeita_causal'] = df_temp\n",
    "            data_dict['contrafactual_causal'] = causal\n",
    "            data_dict['df_causal_effects'] = df\n",
    "            \n",
    "            self.run_dict[sample]['data_analysis'].append(data_dict)\n",
    "\n",
    "\n",
    "            causal_finds = df_temp['causal'].sum()\n",
    "            self.run_dict['global_numbers']['global_quant_causal_changes'] += causal_finds\n",
    "            \n",
    "            # print(f'causal = \\n{causal}\\n')\n",
    "            # print(f'original = \\n{ori}\\n')\n",
    "            # print(f'df_temp = \\n{display(df_temp)}\\n')\n",
    "            \n",
    "            if len(df_temp) > 0:\n",
    "                if causal_finds > 0:\n",
    "                    self.run_dict['global_numbers']['global_quant_causal_contrafac'] += 1\n",
    "                else:\n",
    "                    # print(f'nenhuma relaçao causal satisfeita')\n",
    "                    self.run_dict['global_numbers']['global_quant_zeros_causal'] += 1\n",
    "    #                 display(df_temp)\n",
    "    #                 print(f\"original = {ori}\")\n",
    "    #                 print(f\"causal = {causal}\")\n",
    "\n",
    "                if causal_finds == num_causal_rules:\n",
    "                    self.run_dict['global_numbers']['global_quant_full_causal'] += 1\n",
    "                    # if causal_finds > 2:\n",
    "                        # print(f'todas > 2 relaçoes causais satisfeitas')\n",
    "    #                     display(df_temp)\n",
    "    #                     print(f\"original = {ori}\")\n",
    "    #                     print(f\"causal = {causal}\")\n",
    "                    # elif causal_finds == 1:\n",
    "                        # print(f'todas = 1 relaçoes causais satisfeitas')\n",
    "                \n",
    "                if causal_finds >= (len(df_temp)/2):\n",
    "                    self.run_dict['global_numbers']['global_quant_maioria_causal_satisfeita'] += 1\n",
    "            else:\n",
    "    #             if len(causal) > 0:\n",
    "                self.run_dict['global_numbers']['global_quant_contrafac_unico'] += 1\n",
    "        \n",
    "    def verificar_condicoes(self, row):\n",
    "        if (row['from'] == 'mais' and row['to'] == 'mais' and row['effect'] > 0):\n",
    "            return True\n",
    "        elif row['from'] == 'menos' and row['to'] == 'menos' and row['effect'] > 0:\n",
    "            return True\n",
    "        elif row['from'] == 'mais' and row['to'] == 'menos' and row['effect'] < 0:\n",
    "            return True\n",
    "        elif row['from'] == 'menos' and row['to'] == 'mais' and row['effect'] < 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "\n",
    "    def show_metrics(self):\n",
    "        \n",
    "        for i, sample in self.run_dict.items():\n",
    "            print(f\"quantas instancias contrafactuais encontradas = {self.global_quant_contrafac_max}\")\n",
    "            print(f\"quantidade de mudanças totais = {self.run_dict['global_numbers']['global_quant_changes']}\")\n",
    "\n",
    "            print(f\"quantas instancias tiveram pelo menos uma relação causal satisfeita = {self.run_dict['global_numbers']['global_quant_causal_contrafac']}/{self.global_quant_contrafac_max}\")\n",
    "\n",
    "            print(f\"quantas relações causais foram encontradas = {self.run_dict['global_numbers']['global_quant_causal_rules']}\")\n",
    "\n",
    "            print(f\"quantas relações causais foram satisfeitas = {self.run_dict['global_numbers']['global_quant_causal_changes']}/{self.run_dict['global_numbers']['global_quant_causal_rules']}\")\n",
    "\n",
    "            print(f\"quantas instâncias não tiveram nenhuma relação causal satisfeita = {self.run_dict['global_numbers']['global_quant_zeros_causal']}/{self.global_quant_contrafac_max}\")\n",
    "            print(f\"quantas instâncias tiveram TODAS as relaçoes causais satisfeitas = {self.run_dict['global_numbers']['global_quant_full_causal']}/{self.run_dict['global_numbers']['global_quant_causal_contrafac']}\")\n",
    "\n",
    "            print(f\"quantas instancias causais teveram a maioria das relacoes causais satisfeitas = {self.run_dict['global_numbers']['global_quant_maioria_causal_satisfeita']}/{self.global_quant_contrafac_max}\")\n",
    "            print(f\"quantas instancias tiveram um unico atributo modificado = {self.run_dict['global_numbers']['global_quant_contrafac_unico']}/{self.global_quant_contrafac_max}\")\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7683e329",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass-multioutput is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ccsse \u001b[38;5;241m=\u001b[39m \u001b[43mCCSSE\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgerman_medium\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 38\u001b[0m, in \u001b[0;36mCCSSE.__init__\u001b[0;34m(self, dataset, samples, K, generation)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration \u001b[38;5;241m=\u001b[39m generation\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdfx_full, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdfy_full \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_datasets_train_test()\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbb_model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bb_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainerCSSE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_contrafactual()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_causal, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_causal_effects, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_error, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcausal_order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_causality()\n",
      "Cell \u001b[0;32mIn[4], line 116\u001b[0m, in \u001b[0;36mCCSSE.get_bb_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m bb_model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train)\n\u001b[1;32m    114\u001b[0m p \u001b[38;5;241m=\u001b[39m bb_model\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_test)\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bb_model, p\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2604\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2469\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   2470\u001b[0m     {\n\u001b[1;32m   2471\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2495\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2496\u001b[0m ):\n\u001b[1;32m   2497\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2498\u001b[0m \n\u001b[1;32m   2499\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2601\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2602\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2604\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2606\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2607\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:105\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# No metrics support \"multiclass-multioutput\" format\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    108\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass-multioutput is not supported"
     ]
    }
   ],
   "source": [
    "ccsse = CCSSE('german_medium', samples = 1, K = 10, generation= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e480085c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ccsse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mccsse\u001b[49m\u001b[38;5;241m.\u001b[39my_train\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ccsse' is not defined"
     ]
    }
   ],
   "source": [
    "ccsse.y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39e75089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex                0.0\n",
       "Age               37.0\n",
       "Credit          1274.0\n",
       "LoanDuration      12.0\n",
       "Name: 747, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running original instance:\n",
      " None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...: 100%|██████████| 10/10 [00:17<00:00,  1.73s/it]\n"
     ]
    }
   ],
   "source": [
    "ccsse.run_causal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6900cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantas instancias contrafactuais encontradas = 20\n",
      "quantidade de mudanças totais = 4\n",
      "quantas instancias tiveram pelo menos uma relação causal satisfeita = 0/20\n",
      "quantas relações causais foram encontradas = 0\n",
      "quantas relações causais foram satisfeitas = 0.0/0\n",
      "quantas instâncias não tiveram nenhuma relação causal satisfeita = 0/20\n",
      "quantas instâncias tiveram TODAS as relaçoes causais satisfeitas = 0/0\n",
      "quantas instancias causais teveram a maioria das relacoes causais satisfeitas = 0/20\n",
      "quantas instancias tiveram um unico atributo modificado = 3/20\n",
      "quantas instancias contrafactuais encontradas = 20\n",
      "quantidade de mudanças totais = 4\n",
      "quantas instancias tiveram pelo menos uma relação causal satisfeita = 0/20\n",
      "quantas relações causais foram encontradas = 0\n",
      "quantas relações causais foram satisfeitas = 0.0/0\n",
      "quantas instâncias não tiveram nenhuma relação causal satisfeita = 0/20\n",
      "quantas instâncias tiveram TODAS as relaçoes causais satisfeitas = 0/0\n",
      "quantas instancias causais teveram a maioria das relacoes causais satisfeitas = 0/20\n",
      "quantas instancias tiveram um unico atributo modificado = 3/20\n"
     ]
    }
   ],
   "source": [
    "ccsse.show_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571d1086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9f1554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
